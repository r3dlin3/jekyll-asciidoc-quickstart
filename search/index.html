<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>Search | A bit of everything</title>
	<meta name="description" content="A bit of everything">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- CSS -->
	<link rel="stylesheet" href="/assets/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="/search/">

	<!-- RSS -->
	<link type="application/atom+xml" rel="alternate" href="https://r3dlin3.github.io/feed.xml" title="A bit of everything" />
	<!-- SEO -->
	<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Search | A bit of everything</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Search" />
<meta name="author" content="r3dLiN3" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A bit of everything" />
<meta property="og:description" content="A bit of everything" />
<link rel="canonical" href="https://r3dlin3.github.io/search/" />
<meta property="og:url" content="https://r3dlin3.github.io/search/" />
<meta property="og:site_name" content="A bit of everything" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"r3dLiN3"},"headline":"Search","description":"A bit of everything","@type":"WebPage","url":"https://r3dlin3.github.io/search/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


	<!-- Font Awesome -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	

	<!-- Google Analytics -->
	
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/">
			<img class="avatar" src="/assets/img/avatar.png" alt="avatar"/>
		</a>
		
		<h1 class="site-title">
			<a href="/">A bit of everything</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
			
			
			
			
			<li>
				<a class="page-link" href="/about/">
					A propos
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			<li>
				<a class="page-link" href="/tags/">
					tags
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled  -->
			
			
            
            <!-- Search bar -->
            
		</ul>
	</nav>
    
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/')">
    <h1 class="title">Search</h1>
    
  </header>
  <section class="post-content"><div class="search">
    <div id="search-results"></div>
    <p id="not-found" style="display: none">
        Aucun r√©sultat trouv√©.
    </p>
</div>


<script>
  window.store = {
    
      "2021-03-11-postman-dynamic-content": {
        "title": "Requ√™tes dynamiques avec Postman",
        "tags": "rest",
        "date": "March 11, 2021",
        "author": "",
        "category": "",
        "content": "IntroductionPostman est un excellent outil pour tester des API REST.L&#8217;utilisation des environnements permet d√©j√† d&#8217;apporter une certaine dynamicit√© en regroupant certaines variables propres un environnement justement&nbsp;: URL, login et mot de passe, etc.En utilisant les variables entre double accolade (ex&nbsp;: {{base_url}}), il est alors possible de r√©utiliser ces variables dans l&#8217;URL, dans le contenu de la requ√™te ou autre.Postman permet de faire des pr√©traitements en JavaScript.C&#8217;est ce que nous allons exploiter.Les scripts de pr√©requ√™tesIl est possible d&#8217;ajouter du JavaScript √† 2 moments&nbsp;:Avant d&#8217;envoyer la requ√™te&nbsp;: le contenu du script est dans l&#8217;onglet \"Pre-request Script\"Apr√®s avoir re√ßu la r√©ponse&nbsp;: le contenu du script est dans l&#8217;onglet \"Tests\"Il est √† noter qu&#8217;on peut positionner des scripts √† plusieurs niveaux&nbsp;:Au niveau de la collectionAu niveau du r√©pertoireAu niveau de la requ√™teUn premier scriptL&#8217;exemple ci-dessous permet de cr√©er 2 variables&nbsp;: startTime et endTime.var now = new Date().getTime();console.log(now);(1)var startTime = new Date(now + 60*1000);var endTime = new Date(now + 5*60*1000);console.log(startTime);pm.environment.set('startTime', startTime.toISOString()); (2)pm.environment.set('endTime', endTime.toISOString());1Il est possible de logguer, ce qui est tr√®s appr√©ciable.2Les variables sont rendues disponibles gr√¢ce √† cette commande.La console d√©veloppeur avec les logs est disponible dans le menu View&#160; Show Postman ConsoleUtilisation des variablesL&#8217;exemple montre l&#8217;utilisation des variables dans le corps du message.{    \"startTime\": \"{{startTime}}\",    \"endTime\": \"{{endTime}}\"}ConclusionIl n&#8217;est pas rare que l&#8217;on veuille tester avec des valeurs al√©atoires ou d√©pendantes du temps.L&#8217;utilisation de script permet de rendre plus dynamique les requ√™tes.",
        "url": "//2021/03/11/postman-dynamic-content/"
      }
      ,
    
      "2021-01-05-logic-app-azure-media-services": {
        "title": "Logic App, API Azure et Media Services",
        "tags": "azure, logic-app",
        "date": "January 5, 2021",
        "author": "",
        "category": "",
        "content": "IntroductionLogic App dispose d&#8217;ores-et-d√©j√† de nombreux connecteurs pour piloter des ressources Azure&nbsp;:L&#8217;arr√™t/relance d&#8217;instance App ServiceLa gestion des cl√©s ou des secrets dans Azure Key VaultSi le connecteur n&#8217;existe pas, l&#8217;utilisation du connecteur REST et des identit√©s manag√©s permettent de rapidement arriver √† ses fins.Ainsi, dans mon cas, je voulais pouvoir arr√™ter un Streaming Endpoint sur un Azure Media Services.En effet, un Streaming Endpoint est factur√© mais peut √™tre arr√™t√©. Et dans mon environnement de bac √† sable, je n&#8217;en ai pas besoin en permanence.Cr√©ation de la Logic AppLa cr√©ation d&#8217;une Logic App se fait assez simplement dans le portail.Identit√© manag√©eUne fois cr√©√©e, il faut activer l&#8217;identit√© manag√©e, qui est d√©sactiv√©e par d√©faut.Pour ce faire, il faut simplement aller dans la blade Identity&nbsp;:Le bouton \"Attributions de r√¥le Azure\" permet d&#8217;attribuer des droits sur le Media Services.Malheureusement, par ce biais, il n&#8217;est possible, pour le moment, que d&#8217;attribuer des droits au niveau d&#8217;une souscription ou d&#8217;un groupe de ressources ou des ressources comme SQL, compte de stockage ou Key Vault, mais pas sur un media services.Il n&#8217;existe pas de r√¥le sp√©cifique √† Media Services.Nous allons devoir recourir au r√¥le \"Contributeur\" si l&#8217;on ne veut pas avoir de r√¥le personnalis√©, ce qui est mon cas, car je veux garder les choses simples.Pour autant, pour √©viter d&#8217;attribuer trop de droits, je pr√©conise d&#8217;attribuer le r√¥le \"Contributeur\" directement sur l&#8217;instance Media Services.API REST et connecteur Logic AppAzure Media Services dispose d&#8217;une API REST et donc d&#8217;une m√©thode sp√©cifique pour arr√™ter un Streaming Endpoint.Il s&#8217;agit d&#8217;une simple requ√™te POST sur L&#8217;URL https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Media/mediaservices/{accountName}/streamingEndpoints/{streamingEndpointName}/stop?api-version=2020-05-01Une fois les valeurs remplac√©es dans l&#8217;URL ci-dessus, on peut utiliser simplement un connecteur HTTP en activant l&#8217;authentification par identit√© manag√©e&nbsp;:Le d√©ploiement automatis√© par ARM templateJ&#8217;ai pr√©par√© un ARM template qui va&nbsp;:D√©ployer la Logic App et configurer l&#8217;URLAttribuer le droit \"Contributeur\" sur Media ServicesJe fais l&#8217;hypoth√®se que la Logic App est d√©ploy√©e dans le m√™me groupe de ressources que l&#8217;Azure Media Services.Comme d&#8217;habitude, il existe plusieurs fa√ßon de le d√©ployer, comme par exemple&nbsp;:En 1 clic&nbsp;:En PowerShellNew-AzResourceGroupDeployment -ResourceGroupName \"mon-rg\" -TemplateParameterFile .\\parameters.json -TemplateFile .\\template.json -VerboseConclusionEn quelques clics, il est possible d&#8217;automatiser des t√¢ches dans Azure avec Logic App, m√™me si le connecteur n&#8217;est pas disponible.L&#8217;√©conomie peut √™tre substantielle alors que le co√ªt de mise en ≈ìuvre est ridicule.",
        "url": "//2021/01/05/logic-app-azure-media-services/"
      }
      ,
    
      "2020-12-21-php-app-service": {
        "title": "PHP sur Azure App Service : Windows ou Linux ?",
        "tags": "azure, php, app-service",
        "date": "December 21, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionPHP est support√© sur App Service. Bien avant l&#8217;av√®nement des App Services sous Linux, il √©tait possible de faire tourner un Wordpress sur un App Service Windows.App Service sur Linux permet de faire tourner son application parmi les piles d&#8217;application support√©es ou faire tourner son propre container.Pour mes tests, j&#8217;ai utilis√© phpOIDC comme base de r√©f√©rence et Locust comme injecteur.Le sc√©nario de test comprend&nbsp;:L&#8217;interrogation de l&#8217;URL de m√©tadonn√©esL&#8217;interrogation de l&#8217;URL de webfingerL&#8217;authentification et la r√©cup√©ration d&#8217;un tokenLa r√©cup√©ration des informations de l&#8217;utilisateur (userinfo)La validation du jetonWindowsLes graphiques suivants pr√©sentent les r√©sultats pour un App Service plan B1 sous Windows.Le nombre de requ√™tes est relativement erratique&#8201;&#8212;&#8201;entre 2 et 6 requ√™tes/s&#8201;&#8212;&#8201;avec une moyenne d&#8217;environ 3 requ√™tes/s.LinuxPlan B1Les graphiques suivants pr√©sentent les r√©sultats pour un App Service plan B1 sous Linux.Le nombre de requ√™tes est relativement plus stable que pour Windows avec une moyenne d&#8217;environ 3 requ√™tes/s.Plan B3.Au moment de la r√©daction de cet article, les plans Linux sont beaucoup moins cher que Windows.Ainsi en d√©cembre 2020 pour France Central&nbsp;:OSTailleCoresM√©moirePrixWindowsB111,75 GB~‚Ç¨57.868/moisLinuxB111,75 GB~‚Ç¨11.081/moisLinuxB347 GB~‚Ç¨43.093/moisOn voit ainsi que l&#8217;on peut avoir beaucoup plus de ressources avec un plan Linux B3 qu&#8217;un plan Windows B1.Comparons ce qui est comparable et voyons les r√©sultats pour un plan Linux B3&nbsp;:Cette fois-ci, avec un peu de stress, on arrive √† 12 requ√™tes par secondes.OPcache √† la rescousseOPcache am√©liore les performances de PHP en stockant le bytecode desscripts pr√©compil√©s en m√©moire partag√©e, faisant ainsi qu&#8217;il n&#8217;estplus n√©cessaire √† PHP de charger et d&#8217;analyser les scripts √† chaquedemande.Il est inclus par d√©faut depuis PHP 5.5.Les graphiques suivants pr√©sentent les r√©sultats pour un App Service plan B1 sous Linux avec OPcache activ√© dans l&#8217;image Docker&nbsp;:Le nombre de requ√™tes est relativement erratique&#8201;&#8212;&#8201;entre 6 et 10 requ√™tes/s&#8201;&#8212;&#8201;avec une moyenne d&#8217;environ 8 requ√™tes/s.ConclusionLes tests de performance de phpOIDC n&#8217;ont pas du tout √©t√© impressionnant (sic.).Je n&#8217;ai pas jou√© avec le cache local sur App Service sur Windows.C&#8217;est une option int√©ressante en termes de performance.Cela √©tant, on a pu voir qu&#8217;√† prix √©quivalent, il est pr√©f√©rable d&#8217;utiliser un plan Linux.L&#8217;utilisation d&#8217;OPcache permet √©galement de grandement am√©liorer les performances. Seule une image personnalis√©e permet d&#8217;avoir OPcache activ√©, donc un plan Linux.Il n&#8217;existe pas de r√©ponse absolue quand on parle de tests de performance&nbsp;: Cela d√©pend fortement de l&#8217;application, des acc√®s en lecture/√©criture, etc.On peut voir que l&#8217;utilisation de plan sur Linux permet d&#8217;√™tre plus efficace et devrait √™tre favoris√©.",
        "url": "//2020/12/21/php-app-service/"
      }
      ,
    
      "2020-09-24-azure-cli-powershell": {
        "title": "Transformer des commandes Bash Azure CLI pour PowerShell",
        "tags": "azure, az-cli, powershell",
        "date": "September 24, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionLa plupart des exemples pour Azure CLI sont donn√©es pour Bash.Pour autant, on peut √™tre sous Windows, sans sous-syst√®me Linux.On aura cependant toujours PowerShell&nbsp;!Voyons comment transformer les commandes Bash pour √™tre ex√©cut√©es sous PowerShell.Les variablesLes variables s&#8217;utilisent de la m√™me fa√ßon gr√¢ce au symbole $.Ainsi la commande suivante s&#8217;ex√©cute sous Bash ou PowerShell&nbsp;:echo $mavariableecho est un alias pour Write-Output en PowerShell.Par contre, la d√©claration est bien diff√©rente&nbsp;:BashPowerShellmavariable=toto$mavariable=\"toto\"Passage √† la lignePour des raisons lisibilit√©s √©videntes, les longues commandes Bash sont le plus souvent d√©coup√©es pour passer √† la ligne.Le caract√®re \\ suivi d&#8217;une nouvelle ligne est compris comme une continuation de ligne.BashPowerShellaz storage account create \\        --name $sa \\        -g $rg \\        --access-tier Hot \\        --sku Standard_LRSaz storage account create `        --name $sa `        -g $rg `        --access-tier Hot `        --sku Standard_LRSR√©cup√©ration de la sortie d&#8217;une commandeEn mettant simplement entre  `, il est possible de r√©cup√©rer le r√©sultat d&#8217;une commande pour la mettre dans une variable.Finalement, ce n&#8217;est pas si compliqu√© en PowerShell.BashPowerShellstreaming_endpoint_hostname=`az ams streaming-endpoint show -g $rg -a $ams -n default`$streaming_endpoint_hostname = az ams streaming-endpoint show -g $rg -a $ams -n defaultConclusionVoici quelques exemples pour adapter les commandes sur PowerShell.Il resterait beaucoup √† dire&nbsp;:Gestion des erreursTransformation en objet PowerShell (ex: az aks list | ConvertFrom-Json)Conversion de fonction plus avanc√©es comme&nbsp;:Les bouclesLes pipesL&#8217;utilisation de fonction sp√©cifiques non pr√©sentes par d√©faut comme jqEtc.Je mettrai √† jour cette page en fonction des cas que je rencontre.",
        "url": "//2020/09/24/azure-cli-powershell/"
      }
      ,
    
      "2020-09-23-lab-data-factory": {
        "title": "Pr√©parer rapidement un lab Data Factory en Azure CLI",
        "tags": "azure, az-cli, data-factory",
        "date": "September 23, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionLe tutorial de copie de donn√©es d&#8217;un compte destockage vers Azure SQL n√©cessite quelques pr√©requis.R√©cemment, j&#8217;ai voulu √©galement tester les points de terminaison priv√©s (Private Endpoint) avec Data Factory avec le tutorial de Microsoft  qui a les m√™mes pr√©requis que le pr√©c√©dent tutorial.J&#8217;ai donc √©crit les quelques lignes n√©cessaires en Azure CLI (pour varier les plaisirs avec les gabarits ARM).Il n&#8217;est pas n√©cessaire d&#8217;installer Azure CLI sur son poste pour ex√©cuter les commandes. On peut utiliser le Bash d&#8217;Azure Cloud Shell.Les commandes sont donn√©es pour du Bash. Elles sont √† adapter si vous utilisez PowerShell.Les variablesLes commandes suivantes s&#8217;appuient sur des variables pour contextualiser la cr√©ation des ressources.Certains noms de ressource doivent √™tre global unique&#8201;&#8212;&#8201;c&#8217;est-√†-dire unique sur l&#8217;ensemble des clients Microsoft&#8201;&#8212;&#8201;comme le nom du compte de stockage et le nom du serveur SQL.D&#8217;autres, comme le nom de la base sont plus flexibles.# Nom du groupe de ressourcesrg=\"rg-dfy\"# Localisation du groupe de ressources et des ressources associ√©eslocation=\"francecentral\"# Compte de stockagesa=\"monstorage\"# Data Factorydfy=\"mondfy\"# Nom du serveur SQLsqlserver=\"monserveur\"# Mot de passe du serveur SQLsqlpwd=\"MonMotdePasseComplexe!\"# Nom de la base de donn√©essqldb=\"mydb\"Et tout commen√ßa&#8230;&#8203; par un groupe de ressourcesaz group create -n $rg -l francecentralCr√©ation des ressourcesServeur SQLOn cr√©e ici une base en ¬´&nbsp;Basic&nbsp;¬ª. Il faudra adapter en fonction de la taille souhait√©e.az sql server create -l $location -g $rg -n $sqlserver -u myadminuser -p $sqlpwdaz sql db create -g $rg -s $sqlserver -n mydb --service-objective BasicCompte de stockage et conteneursLes commandes ci-dessous permettent de cr√©er le compte de stockage et le conteneur.az storage account create --name $sa \\                          -g $rg \\                          --access-tier Hot \\                          --sku Standard_LRScn=`az storage account show-connection-string -g $rg -n $sa -o tsv`az storage container create \\    --account-name $sa \\    --name data \\    --public-access off \\    --connection-string $cnData Factoryaz extension add --name datafactoryaz datafactory factory create --name $dfy \\                              --resource-group $rgConclusionUne fois les variables d√©finies, il est possible de contruire le lab en moins de 2min30.On voit √† quel point Azure CLI est performant dans la cr√©ation d&#8217;un environnement, bien plus quePowerShell dont les cmdlets sont puissantes mais tr√®s proches de l&#8217;impl√©mentation ARM et donc assez complexe.A ma connaissance, il n&#8217;est pas possible de cr√©er une VM en une ligne avec PowerShell alors que c&#8217;est possible en Azure CLI.Personnellement, pour des petits projets, je vais favoriser Azure CLI √† ARM, qui malgr√© tout, reste assez co√ªteux √† √©crire et tester.",
        "url": "//2020/09/23/lab-data-factory/"
      }
      ,
    
      "2020-09-21-sql-server-sur-docker": {
        "title": "SQL Server sur docker et cr√©ation de base",
        "tags": "docker, sql-server, kubernetes, acr",
        "date": "September 21, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionIl est possible d&#8217;ex√©cuter des images de conteneur SQL Server avec Docker.Malheureusement, cette image ne permet pas cr√©er de base de donn√©es par d√©faut.Au contraire, MySQL, par le truchement de la variable MYSQL_DATABASE, permet de cr√©er une base de donn√©es au d√©marrage.C&#8217;est un point qui a √©t√© relev√© assez puisque ce point est trac√© dans le ticket n¬∞2 du projet GitHub.La seule solution possible est donc de passer par la personnalisation de l&#8217;image. Les scripts ont √©t√© pris du ticket GitHub.Le DockerfileLe Dockerfile va se charger de modifier la commande de d√©marrage afin de pouvoir initialiser la base de donn√©es.Dockerfile# Choose exact tag (not 'latest'), to be sure that new version will not break creating imageFROM mcr.microsoft.com/mssql/server:2019-latest# Copy initialization scriptsCOPY *.sh ./USER root (1)RUN chmod +x *.shUSER mssql# Set environment variables, not to have to write them with docker run commandENV ACCEPT_EULA YENV MSSQL_PID Developer# Run Microsoft SQl Server and initialization script (at the same time)# Note: If you want to start MsSQL only (without initialization script) you can comment bellow line out, CMD entry from base image will be takenCMD /bin/bash ./entrypoint.sh1Par d√©faut, l&#8217;image s&#8217;ex√©cute avec un utilisateur non root. De fait, dans la construction de l&#8217;image, je bascule temporairement en tant que root. A noter que sudo n&#8217;est pas disponible dans l&#8217;image de base.Le script entrypoint.sh lance init-db.sh en t√¢che de fond (d&#8217;o√π le &amp;) et d√©marre le serveur.entrypoint.sh# Run Microsoft SQl Server and initialization script (at the same time)./init-db.sh &amp; /opt/mssql/bin/sqlservrLe script init-db.sh va attendre le d√©marrage du serveur en scrutant les logs.init-db.sh#!/bin/bash# (see https://github.com/microsoft/mssql-docker/issues/2 )echo \"Container initialization: waiting for the server to come up\"while [ ! -f /var/opt/mssql/log/errorlog ]do  sleep 1doneFOUND=0i=0while [[ $FOUND -ne 1 ]] &amp;&amp; [[ $i -lt 60 ]]; do  i=$i+1  FOUND=$(grep -cim1 \"Service Broker manager has started\" /var/opt/mssql/log/errorlog)  if [[ $FOUND -ne 1 ]]; then    sleep 1  fidoneif [[ $FOUND -ne 1 ]]; then  echo \"Container initialization: Error: waited for more than 60 seconds for the server to start. Trying to create the database now...\"fisleep 10echo \"Container initialization: creating the database if needed\"/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P $SA_PASSWORD -Q \"CREATE DATABASE $DB_NAME\"echo \"Container initialization: done\"TestPas de surprise sur la construction de l&#8217;image&nbsp;:docker build -t mssql:latest .Il est ensuite possible de lancer l&#8217;imagedocker run --rm -e SA_PASSWORD=yourStrong(!)Password -e DB_NAME=mydb -p 1444:1433 mssql:latestJ&#8217;utilise ici un prompt Windows. Les variables d&#8217;environnement ne doivent pas √™tre encadr√©es d&#8217;apostrophe comme d√©crit dans les exemples de la page DockerHub de SQL Server. Egalement, le prompt Windows accepte sans broncher les points d&#8217;exclamation&nbsp;!Puisque l&#8217;option -d n&#8217;a pas √©t√© utilis√©e, les logs apparaissent dans la console.On peut alors voir √† la fin le message suivant, indiquant la cr√©ation de la base&nbsp;:2020-09-21 16:44:53.70 spid51      Starting up database 'mydb'.2020-09-21 16:44:53.94 spid51      Parallel redo is started for database 'mydb' with worker pool size [4].2020-09-21 16:44:53.98 spid51      Parallel redo is shutdown for database 'mydb' with worker pool size [4].Container initialization: doneGr√¢ce au mapping de port, il est alors possible d&#8217;utiliser son outil pr√©f√©r√© pour se connecter √† la base.Par exemple, avec Azure Data Studio, il est possible de pr√©ciser les param√®tres suivants&nbsp;:Connection Type: Microsoft SQL ServerServer Name: localhost, 1444 (dans ma commande docker, j&#8217;ai utilis√© un mapping du port 1444 vers le port 1433 du serveur)Authentication Type: SQL LoginUser name: saPassword: yourStrong(!)PasswordOn peut alors v√©rifier la version de SQL Server ou v√©rifier que la base a bien √©t√© cr√©√©e en listant les bases de donn√©es&nbsp;:ConclusionM√™me si l&#8217;on peut regretter que l&#8217;image Docker de SQL Server ne cr√©e pas automatiquement une base de donn√©es au d√©marrage, force est de constater qu&#8217;il est tr√®s facile de cr√©er une base, que le support de SQL Server est excellent.Cela ouvre donc la porte √† des sc√©narios int√©ressants de d√©veloppement avec une forte r√©duction des contraintes sur le poste du d√©veloppeur car m√™me la base peut √™tre ¬´&nbsp;dockeris√©e&nbsp;¬ª.Finalement, on notera que Microsoft documente m√™me un d√©ploiement sur Kubernetes.",
        "url": "//2020/09/21/sql-server-sur-docker/"
      }
      ,
    
      "2020-09-18-form-recognizer-powershell": {
        "title": "Fun avec PowerShell et Azure Form Recognizer",
        "tags": "powershell, azure",
        "date": "September 18, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionAzure Form Recognizer est un service cognitif permettant d&#8217;extraire du texte d&#8217;images.C&#8217;est un service assez jeune d&#8217;Azure et ne dispose pas d&#8217;interface comme un Custom Vision hormis un client qu&#8217;on peut d√©ployer soi-m√™me.Azure Form Recognizer propose aujourd&#8217;hui des SDK pour .NET, Python, Java et JavaScript ainsi qu&#8217;une API REST.Pour le fun, j&#8217;ai donc utilis√© PowerShell pour faire des appels √† l&#8217;API REST.Param√®tres d&#8217;acc√®sDans le portail Azure, il est possible de r√©cup√©rer les informations dont on a besoin pour acc√©der au service dans la section ¬´&nbsp;Cl√©s et point de terminaison&nbsp;¬ª de l&#8217;instance Form Recognizer&nbsp;:2 cl√©s d&#8217;acc√®sL&#8217;URL d&#8217;acc√®sUne fois, ces valeurs r√©cup√©r√©es, on peut initialiser les variables&nbsp;:# One of the key as defined in the \"Keys and Endpoint\" blade of Form Recognizer$key=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"# Endpoint as defined in the \"Keys and Endpoint\" blade of Form Recognizer# Must start with https:// and must end with a trailing \"/\"$endpoint = \"https://&lt;Instance Form Recognizer&gt;.cognitiveservices.azure.com/\"Lister les mod√®lesChaque entrainement de Form Recognizer va cr√©er un nouveau mod√®le.Comment retrouver le mod√®le&nbsp;?Voici comment lister les mod√®les disponibles&nbsp;:$url = \"{0}formrecognizer/v2.0/custom/models\" -f $endpoint$headers = @{    \"Content-Type\" = \"application/json\"    \"Ocp-Apim-Subscription-Key\" = $key} (1)$res = Invoke-RestMethod -Method Get -Uri $url -Headers $headers (2)Write-Host \"Number of models:\", $res.modelList.Count$res.modelList | sort lastUpdatedDateTime (3)1On pr√©pare les ent√™tes √† passer dans un simple tableau associatif (hashtable) pour passer en outre la cl√©. Les utilisateurs d&#8217;Azure API Management auront reconnu l&#8217;ent√™te Ocp-Apim-Subscription-Key.2Pas de subtilit√© ici&nbsp;: on utilise la m√©thode Invoke-RestMethod qui se chargera de d√©s√©rialis√© le contenu retourn√© en JSON en un objet PowerShell.3Il est alors possible d&#8217;afficher la liste des mod√®les, ranger par date de derni√®re mise √† jour par exemple.Exemple de sortie&nbsp;:Number of models: 23modelId                              status createdDateTime      lastUpdatedDateTime-------                              ------ ---------------      -------------------7147e795-7780-4dc6-85b6-e9da78cf0134 ready  2020-09-08T11:28:47Z 2020-09-08T11:28:49Z18f5dde0-f7bf-42fb-abb7-daed423d374e ready  2020-09-08T11:40:07Z 2020-09-08T11:40:07Zbbdce3a1-3768-4f27-8bca-a2ec15b85331 ready  2020-09-08T11:41:47Z 2020-09-08T11:41:47Z8124abd3-93b0-413f-b6d6-af1695ed9571 ready  2020-09-08T12:09:08Z 2020-09-08T12:09:10Zbecc3c6c-d161-4121-b79d-177c6359529c ready  2020-09-08T12:14:10Z 2020-09-08T12:14:12Z...Faire une analyse d&#8217;un mod√®le personnalis√©Il existe des mod√®les int√©gr√©s au service pour les cartes de visite ou des tickets de caisse.Il est cependant possible d&#8217;entrainer son propre mod√®le. Pour l&#8217;√©valuation du mod√®le, nous aurons besoin de l&#8217;identifiant du mod√®le que l&#8217;on aura pu r√©cup√©rer √† l&#8217;√©tape pr√©c√©dente.Nous allons voir ici comment faire l&#8217;analyse d&#8217;une image.L&#8217;image peut √™tre disponible sur Internet, typiquement sur un compte de stockage. Dans l&#8217;exemple ci-dessous, nous allons directement transf√©rer l&#8217;image pr√©sente sur le disque. L&#8217;image peut √™tre un JPEG, un PNG, un TIFF ou un PDF.Dans l&#8217;exemple, il s&#8217;agira d&#8217;une image JPEG (cf. le Content-Type √† image/jpeg).L&#8217;analyse d&#8217;une image se fait en 2 temps&nbsp;:On soumet l&#8217;image.On r√©cup√®re l&#8217;analyse de l&#8217;image.# Id of the model (GUID)$modelId = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"$url = \"{0}formrecognizer/v2.0/custom/models/{1}/analyze\" -f $endpoint, $modelId$imagePath = \"...\\XXX.jpeg\"$webRequest = [System.Net.HttpWebRequest]::Create($url) (1)$webRequest.Method = \"POST\"$webRequest.ContentType = \"image/jpeg\"$webrequest.Headers.Add(\"Ocp-Apim-Subscription-Key\", $key)$requestStream = $webRequest.GetRequestStream()$buffer = [System.IO.File]::ReadAllBytes($imagePath)  (2)$requestStream = $webRequest.GetRequestStream()$requestStream.Write($buffer, 0, $buffer.Length)$requestStream.Flush()$requestStream.Close()[System.Net.HttpWebResponse] $webResponse = $webRequest.GetResponse()$nextUrl = $webResponse.Headers[\"Operation-Location\"] (3)Start-Sleep -s 4 (4)$res = Invoke-RestMethod -Method Get -Headers @{\"Ocp-Apim-Subscription-Key\" = $key} -Uri $nextUrl (5)$res.analyzeResult.documentResults[0].fields1Afin de r√©cup√©rer les ent√™tes de la r√©ponse, nous allons utiliser un objet .NET de type WebRequest. La cmdlet Invoke-RestMethod dispose d&#8217;un param√®tre ResponseHeadersVariable mais qui n&#8217;est disponible qu&#8217;√† partir de PowerShell 6 qui n&#8217;est pas la version disponible par d√©faut.2Ici, on ne fait pas dans la dentelle. On lit toute l&#8217;image et on pousse dans la requ√™te. Pas d&#8217;optimisation de la m√©moire car l&#8217;image est assez petite.3On soumet la requ√™te pour r√©cup√©rer un objet r√©ponse. C&#8217;est l&#8217;ent√™te Operation-Location qui contient le lien pour r√©cup√©rer le r√©sultat de l&#8217;analyse.4L&#8217;analyse prend plus de 3 secondes. On attend 4s.5La m√©thode Invoke-RestMethod est parfaite pour r√©cup√©rer le r√©sultat de l&#8217;analyse.Exemple de sortie&nbsp;:MonChamps------------@{type=string; valueString=XXX; text=XXX; page=1; boundingBox=System.Object[]; confidence=1,0; elements=System.Object[]}ConclusionPowerShell est disponible sur tous les postes Windows 10.En utilisant PowerShell, il est possible de facilement interroger les services d&#8217;Azure Form Recognizer sans d√©pendance √† Python ou d√©veloppement de programme en .NET ou m√™me installer le client fourni par MS.Ultimement, on peut envisager le d√©veloppement d&#8217;une Azure Function en PowerShell, s&#8217;il est n√©cessaire de surfacer l&#8217;API d&#8217;Azure Form Recognizer avec sa propre API (pour des raisons de s√©curit√©, de d√©couplage ou autre).Cet exercice est laiss√© √† la discr√©tion du lecteur üòâ.",
        "url": "//2020/09/18/form-recognizer-powershell/"
      }
      ,
    
      "2020-07-23-creer-arm-template": {
        "title": "Trucs et astuces pour la cr√©ation d&amp;#8217;ARM template",
        "tags": "arm, azure, trucs",
        "date": "July 23, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionL'ARM template est l&#8217;arme de choix dans l&#8217;arsenal d'Infrastructure as Code pour Azure.De mani√®re g√©n√©rale, il ne faut pas n√©gliger le temps n√©cessaire pour la cr√©ation des scripts, des fichiers de configuration pour l'Infrastructure as Code.Pour autant, gr√¢ce √† la r√©p√©tabilit√©, vous gagnerez du temps pourla cr√©ation des environnements (passage en prod √† l&#8217;arrache&nbsp;?),en documentation, en qualit√© et en confiance (chaque mise √† jour ne g√©n√©rera pas un stress car le r√©sultat est connu d&#8217;avance)Comme on va le voir, il existe plusieurs fa√ßons de cr√©er des ARM templates. Chacune a ses avantages et inconv√©nients.Il sera donc parfois n√©cessaire de les combiner pour arriver √† vos fins.Table des mati√®resIntroductionAutomatisation dans le portailCr√©ation dans le portailQuickstart templatesLa r√©f√©renceExploration des ressourcesD√©ploiementPowerShellBonus&nbsp;: ARMTemplateGeneratorConclusionAutomatisation dans le portailLes gens me posent souvent la question&nbsp;: &laquo;&nbsp;Une fois que l&#8217;on a cr√©√© les ressources dans le portail, il n&#8217;est pas possible de faire un copi√©/coll√© pour cr√©er un nouvel environnement&nbsp;?&nbsp;&raquo;Oui et non.En effet, le portail a une fonction proche&nbsp;:&laquo;&nbsp;Exporter le mod√®le&nbsp;&raquo;.Cette fonctionnalit√© est pr√©sente au niveau d&#8217;un groupe de ressources ou au niveau de la plupart des ressources.Dans le portail&nbsp;:Puis, le contenu g√©n√©r√©&nbsp;:Avantages&nbsp;:Solution simple.La qualit√© des ARM templates s&#8217;am√©liorent.Le portail g√©n√®re √©galement le fichier de param√®tres.Inconv√©nients&nbsp;:Comme on peut le voir sur la copie d&#8217;√©cran ci-dessus, toutes les ressources ne sont pas exportables.Il n&#8217;est pas rare que des param√®tres soient omis.En r√©alit√©, les ARM templates ainsi produits sont de qualit√© assez m√©diocre&nbsp;:Le nom des param√®tres utilise le nom des ressources. Comme l&#8217;objectif est souvent de pouvoir cr√©er plusieurs environnements, il est pr√©f√©rable de g√©n√©raliser le nom des param√®tres. Par exemple, pour un compte de stockage, le param√®tre va √™tre storageAccounts_nomducomptedestockage_name. Il est recommand√© de le renommer storageAccountName par exemple pour le g√©n√©raliser et conserver une convention de nommage en camelCase.Il n&#8217;y a pas d&#8217;intelligence dans ces templates. Il peut √™tre int√©ressant de pr√©voir des boucles ou d&#8217;autres logiques.Cr√©ation dans le portailLors de la cr√©ation d&#8217;une ressource, il est possible, juste avant la cr√©ationd&#8217;exporter un ARM template.Avantages&nbsp;:Solution simple.ARM template plus propre que lors de l&#8217;export.Le portail g√©n√®re √©galement le fichier de param√®tres.Inconv√©nients&nbsp;:Les ARM templates ainsi g√©n√©r√©s peuvent plus complexe que n√©cessaire et inclure un param√©trage non n√©cessaire.Ainsi, lors de la cr√©ation d&#8217;une base, l'ARM template g√©n√©r√© int√®gre la cr√©ation d&#8217;un serveur SQL alors qu&#8217;il s&#8217;agissait de la cr√©ation d&#8217;une base uniquement. Sans parler de toute la configuration r√©seau ou de s√©curit√© avanc√©e&#8230;&#8203;Les ARM templates ainsi g√©n√©r√©s sont parfois si complexe qu&#8217;ils ne sont pas valides (j&#8217;ai d√©j√† eu le cas&nbsp;!).Quickstart templatesMicrosoft met √† disposition des exemples pour la cr√©ation de nombreuses ressources sur GitHub.On peut y retrouver des exemples de base (pr√©fix√©s en 101) jusqu&#8217;√† des architectures complexes (ferme RDS, infrastructure SAP, etc.).Avantages&nbsp;:Bon point de d√©part pour des cas de la vie r√©elle comme le chiffrement de disque de VM ou sa sauvegarde, des applications Web, etc.Pas mal d&#8217;astuces √† reprendre pour l&#8217;√©criture d'ARM templates sur les conditions, les boucles, le jeu des nested templates, etc.De nombreux template sur des composants non-Microsoft (Chef, SAP, Jenkins, Drupal, etc.).Inconv√©nients&nbsp;:Certains template ne sont pas mis √† jour alors que le service √©volue.Ainsi, certains templates utilisent des vieilles versions d&#8217;API.Je pense notamment aux App Services dont la gestion des piles technologies a √©volu√©e et pour laquelle je n&#8217;ai pas trouv√© d&#8217;exemple viableCela manque de coh√©rence&nbsp;:Sur le nommage des param√®tres. Un r√©seau virtuel peut s&#8217;appeler vnet ou virtualNetworkName, ce qui n√©cessite un travail pour mettre en coh√©rence.La gestion de la localisation de la ressource: dans le cas g√©n√©ral, comme ici, la localisation est trait√©e comme un param√®tre qui a une valeur par d√©faut √† celle du groupe de ressource, ici c&#8217;est une variable.La r√©f√©renceMicrosoft publie la documentation des ressources disponibles, pour les diff√©rentes versions d&#8217;API.Malheureusement, ces pages ne sont pas irr√©prochables.Ainsi, le nommage est proche de l&#8217;impl√©mentation et l&#8217;on va avoir quelques bizarreries comme par exemple pour les App Services&nbsp;: pour avoir la r√©f√©rence, inutile de chercher &laquo;&nbsp;App Service&nbsp;&raquo;. Il faut aller sur &laquo;&nbsp;Web&nbsp;&raquo; car le provider est Microsoft.Web.Ne cherchez pas non plus &laquo;&nbsp;App Insights&nbsp;&raquo;, etc.Vous voil√† pr√©venu&nbsp;!Mais le principal reproche est que les valeurs sont rarement document√©es.Par exemple, le param√®tre type de la configuration git d&#8217;un DataFactory n&#8217;a pas de valeur d√©criteAvantages&nbsp;:Liste en th√©orie tous les param√®tres disponiblesInconv√©nients&nbsp;:Il n&#8217;est pas rare qu&#8217;il manque des param√®tresLes valeurs des enums sont souvent manquantesLe parcours du site n&#8217;est pas toujours ais√© du fait d&#8217;une recherche m√©diocreExploration des ressourcesMicrosoft met √† disposition une interface Web qui permet de parcourir les ressources de sa souscription en ARM&nbsp;: https://resources.azure.com.Cet outil est tr√®s utile pour justement r√©cup√©rer les valeurs que la r√©f√©rence n&#8217;aura pu nous donner.Cela √©tant, comme il n&#8217;affiche pas un ARM template, il y a un travail certain pour convertir l&#8217;information dans un ARM template.A utiliser en dernier recours donc&nbsp;!Cet outil permet de parcourir les diff√©rentes souscriptions rattach√©es √† diff√©rents tenants Azure AD.Avantages&nbsp;:Permet d&#8217;afficher les valeurs. Cela est int√©ressant quand on joue dans le portail pour voir les effets en ARM.Inconv√©nients&nbsp;:Ne fournit pas un ARM template √† proprement parler.Il est n√©cessaire de faire le tri en les param√®tres que l&#8217;on peut fixer et ceux qui sont des attributs syst√®mes, accessibles en lecture seule par exemple.Toutes les ressources ne sont pas affichages par ce biais.Tous les param√®tres ne sont pas affich√©s, notamment les secrets.D√©ploiementChaque d√©ploiement dans un groupe de ressources est trac√©.C&#8217;est un bon moyen parfois pour avoir des d√©tails sur les erreurs.Mais il est possible de r√©cup√©rer l'ARM template utilis√© lors de l&#8217;export.Dans le portail, il suffit d&#8217;aller dans le menu &laquo;&nbsp;D√©ploiement&nbsp;&raquo;&nbsp;:Il est alors possible d&#8217;acc√©der aux param√®tres d&#8217;entr√©e, au template utilis√©&nbsp;:Le template affich√© ici est diff√©rent de l&#8217;export propos√© √† la cr√©ation.Avantages&nbsp;:R√©cup√©ration d'ARM template fonctionnel (d√®s lors que le d√©ploiement est en succ√®s).Tr√®s bonne m√©thode pour faire du reverse engineering si les templates ont √©t√© perdu.Inconv√©nients&nbsp;:Comme pour les autres m√©thodes √† partir du portail Azure, la qualit√© du template n&#8217;est pas toujours excellente.PowerShellC&#8217;est une critique que l&#8217;on peut faire aux cmdlets PowerShell d&#8217;Azure&nbsp;: je trouve qu&#8217;on est souvent trop proche de l&#8217;impl√©mentation ARM. Essayez de cr√©er une VM en PowerShell&nbsp;! En Az cli, cela peut se faire en une ligne, pas en PowerShell.Pour autant, ici cela peut √™tre un avantage.Je me suis servi de cette technique pour automatiser la cr√©ation d&#8217;alerte. Il est facile de cr√©er ou modifier une alerte ou un groupe d&#8217;actions dans le portail mais il n&#8217;existe pas les moyens de l&#8217;exporter.Les alertes sont aussi absentes d'Azure Resource Explorer.J&#8217;ai donc travaill√© avec la cmdlet Get-AzMetricAlertRuleV2 qui m&#8217;a permis d&#8217;aller dans le d√©tail des param√®tresExemple pour avoir l&#8217;identifiant du groupe d&#8217;action&nbsp;:$alertes = Get-AzMetricAlertRuleV2$alerte = $alertes[0]$alerte.Actions[0].ActionGroupIdAvantages&nbsp;:Permet parfois d&#8217;acc√©der √† des valeurs qui sont inaccessibles de l'explorateur de ressources.Inconv√©nients&nbsp;:Comme pour l'explorateur de ressources, cette m√©thode ne permet pas d&#8217;obtenir un ARM template directement exploitable.Cette m√©thode ne va pas fonctionner sur toutes les ressources car cela d√©pend √† quel point la cmdlet est proche de l&#8217;impl√©mentation ARMBonus&nbsp;: ARMTemplateGeneratorAfin de pallier les d√©fauts rencontr√©s dans la cr√©ation d'ARM templates, j&#8217;ai cr√©√© un outil permettant la cr√©ation d'ARM templates &laquo;&nbsp;propre&nbsp;&raquo;&nbsp;: https://github.com/r3dlin3/ARMTemplateGenerator.Cet outil permet de&nbsp;:Assurer une coh√©rence dans le nommage des param√®tresG√©n√©rer un template en fonction de son besoin&nbsp;: ainsi, lors de la cr√©ation d&#8217;une base, le template g√©n√©r√© contiendra la cr√©ation d&#8217;un serveur que si cela est n√©cessaire.N&#8217;h√©sitez pas √† contribuer pour ajouter des ressources ou des nouveaux param√®tres, mettre √† jour les API, etc.Avantages&nbsp;:Coh√©rence dans le nommage des param√®tresTemplate adapt√© √† son besoinInconv√©nients&nbsp;:Peu de ressources disponiblesConclusionL&#8217;√©criture d'ARM templates n&#8217;est pas toujours compliqu√© heureusement.Parfois, cependant, pour arriver √† ses fins, il peut √™tre n√©cessairement d&#8217;ouvrir le truc au pied de biche, mais cela vaut souvent le coup.Chacune des techniques cit√©es plus haut vous permettra d&#8217;arriver √† vos fins, si tant est que soit possible.On se souvient par exemple qu&#8217;√† l&#8217;√©poque, il n&#8217;√©tait pas possible de cr√©er un container sur un compte de stockage.Aujourd&#8217;hui, c&#8217;est possible de le faire en ARM template.",
        "url": "//2020/07/23/creer-arm-template/"
      }
      ,
    
      "2020-06-10-filtrer-sql-app-service": {
        "title": "Configurer automatiquement le firewall SQL/MySQL/PostgreSQL pour un App Service",
        "tags": "arm, azure, app-service, sql",
        "date": "June 10, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionApp Service et Azure SQL sont deux composants PaaS publiques. Cela veut dire qu&#8217;ils disposent d&#8217;adresses IP publiques.Azure SQL ou Azure Database pour MySQL ou Azure Database pour PostgreSQL dispose d&#8217;un m√©canisme de firewall qui permet de filtrer les connexions entrantes.Ce firewall dispose d&#8217;une case √† cocher permettant d&#8217;autoriser ou non le trafic Azure.Malheureusement, ce trafic Azure ne se limite pas au trafic de sa souscription.Ainsi n&#8217;importe quelle VM ou App service sera autoris√©e.Pour autant, App Service dispose d&#8217;une liste d&#8217;IP de sortie que l&#8217;on pourra utiliser pour restreindre l&#8217;acc√®s √† la base sans aller vers de l&#8217;App Service Environment.Autant il est possible de manuellement r√©cup√©rer cette liste d&#8217;IP dans le portail Azure et ajouter ces IP au firewall de la base, autant on va essayer  d&#8217;automatiser au mieux la solution par l&#8217;utilisation d&#8217;ARM template.Il ne s&#8217;agit pas ici de se focaliser uniquement sur le firewall comme moyen unique de protection. Mais autant le configurer correctement pour agir comme premi√®re barri√®re.Organisation de l&#8217;ARM templateNous allons ici utiliser le m√©canisme de mod√®le imbriqu√© ou nested templates.Ainsi, la cr√©ation et la configuration des ressources vont se passer en 3 √©tapes comme montr√© sur la figure ci-dessous&nbsp;Les adresses IP d&#8217;un App ServiceIl est possible de r√©cup√©rer les adresses IP d&#8217;un App Service et de les rendre disponible dans l'`output` de l'ARM Template comme suit&nbsp;:\"outputs\": {    \"possibleOutboundIps\": {        \"type\": \"array\",        \"value\": \"[split(reference(parameters('siteName'), variables('apiVersion')).possibleOutboundIpAddresses, ',')]\"    }}Gr√¢ce √† la fonction split, on r√©cup√®re directement un tableau des adresses IP.On peut aussi noter l&#8217;utilisation possibleOutboundIpAddresses, ce qui donne une liste assez large mais qui va emp√™cher des arr√™ts de service si l&#8217;App Service doit changer d&#8217;infrastructure pour une raison ou pour une autre.Formatage des r√®glesLa liste des IP peut √™tre r√©cup√©rer √† partir du template parent gr√¢ce √† la syntaxe suivante, avec appserviceNestedDeployment le nom du d√©ploiement du nested template pour l&#8217;App Service&nbsp;:[reference('appserviceNestedDeployment').outputs.possibleOutboundIps.value]L&#8217;objectif de l&#8217;√©tape de formatage va √™tre cr√©er un nouveau tableau d&#8217;objet pr√™t √† l&#8217;emploi pour la derni√®re √©tape. On va donc parcourir le tableau d&#8217;IP gr√¢ce √† une boucle et cr√©er un tableau d&#8217;objet avec le nom de la r√®gle (sur la base d&#8217;un incr√©ment) et une des IP (startIpAddress et endIpAddress sont √©gaux).{    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"inputArray\": {            \"type\": \"array\",            \"metadata\": {                \"description\": \"string array of ip addresses\"            }        },        \"ruleNamePrefix\": {            \"type\": \"string\",            \"maxLength\": 26,            \"metadata\": {                \"description\": \"prefix to use in the name of the rule\"            }        }    },    \"variables\": {        \"outputArray\": {            \"copy\": [                {                    \"name\": \"items\",                    \"count\": \"[length(parameters('inputArray'))]\",                    \"input\": {                        \"startIpAddress\": \"[parameters('inputArray')[copyIndex('items')]]\",                        \"endIpAddress\": \"[parameters('inputArray')[copyIndex('items')]]\",                        \"name\": \"[concat(parameters('ruleNamePrefix'), copyIndex('items'))]\"                    }                }            ]        }    },    \"resources\": [],    \"outputs\": {        \"firewallRules\": {            \"value\": \"[variables('outputArray').items]\",            \"type\": \"array\"        }    }}Le tableau ainsi g√©n√©r√© est plac√© dans l'output pour √™tre r√©cup√©rer dans l&#8217;√©tape finale.Configuration du firewallDans le cas de MySQL (le cas est similaire pour Azure SQL), on va donc parcourir le tableau d&#8217;objet pr√©c√©demment cr√©√© pour cr√©er la r√®gle de firewall.{    \"name\": \"[concat(parameters('mysqlServerName'),'/',parameters('firewallrules')[copyIndex()].name)]\",    \"type\": \"Microsoft.DBforMySQL/servers/firewallRules\",    \"apiVersion\": \"2017-12-01\",    \"location\": \"[parameters('location')]\",    \"dependsOn\": [        \"[concat('Microsoft.DBforMySQL/servers/', parameters('mysqlServerName'))]\"    ],    \"copy\": {        \"name\": \"firewallRulesCopy\",        \"count\": \"[length(parameters('firewallrules'))]\"    },    \"properties\": {        \"StartIpAddress\": \"[parameters('firewallrules')[copyIndex()].startIpAddress]\",        \"EndIpAddress\": \"[parameters('firewallrules')[copyIndex()].endIpAddress]\"    }}ARM templatesCette m√©canique a √©t√© utilis√©e pour les templates de phpOIDC.On peut donc retrouver un exemple complet sur GitHub.Il existe certainement plein de fa√ßons d&#8217;arriver au m√™me r√©sultat.L&#8217;utilisation des nested templates permet d&#8217;assurer une certaine flexibilit√©.Ainsi, la liste des IP aurait pu √™tre concat√©n√©e avec une autre liste, gr√¢ce √† la fonction union.√âgalement, cette m√©thode peut √™tre conserv√©e pour Azure SQL ou Azure Database pour MySQL ou Azure Database pour PostgreSQL.Je recommande l&#8217;utilisation du script deploy.ps1 qui facilite grandement l&#8217;utilisation des mod√®les imbriqu√©s.Il permet de&nbsp;:Cr√©er un compte de stockage s&#8217;il n&#8217;existe pasCopier les ARM templates.G√©n√©rer un token SASD√©ployer l&#8217;ARM",
        "url": "//2020/06/10/filtrer-sql-app-service/"
      }
      ,
    
      "2020-05-29-aci-grafana-influxdb-en": {
        "title": "Grafana and InfluxDB on Azure Container Instances",
        "tags": "docker, aci, azure, influxdb, grafana, english, arm",
        "date": "May 29, 2020",
        "author": "",
        "category": "",
        "content": "This the translation of a previous articlepublished in French.Azure Container Instances (ACI) is one of many ways to run containers on Azure. One of the advantages of ACI over App Service (presented in a previous article (in French)) is the ability to expose multiple ports.So we&#8217;re going to expose a Grafana instance and an InfluxDB database.Grafana is an open source solution for creating dashboard. InfluxDB is its companion of choice for time series storage.In this article, for simplicity sake, I will not expose Grafana over HTTPS.You will have to refer to my previous article Certificat Let&#8217;s Encrypt sur Azure Container Instances et NGINX (in French) for the implementation of HTTPS.The solutionAs mentioned, the solution will run on Azure Container Instances.Grafana needs a database for its configuration. Grafana supports  3 kind of databases:SqliteMysqlPostgresqlTo avoid losing the configuration if the container restarts, the data is persistently stored on Azure Files.Unfortunately, due to some limitations, it was not possible to persist on Azure Files the SQLite database (embarked by default in Grafana) (a dark story about locks) or to use the Docker image provided by PostgreSQL (a dark  story about files and their owner).We will therefore use MySQL and its Docker image.MySQL will not be published on the Internet.Grafana data sourcesIt is  possible to provide a list of data sources per YAML file.We will use this mechanism to automatically set up InfluxDB as a data source.So, the configuration of the data source in YAML will be:influxdb.yamlapiVersion: 1deleteDatasources:  - name: InfluxDB    orgId: 1datasources:  - name: InfluxDB    type: influxdb    access: proxy    orgId: 1    database: PERF    user: influxadmin    password: influxadmin    url: http://localhost:8086This file will be passed as a secret. The base64 function of ARM template will be used to encode the content and pass it as a secret.Note about container groups in Azure Container InstancesAzure Container Instances use a \"proprietary\" format that is neither Docker Compose nor a Kubernetes deployment file.The important point to keep in mind is that we will declare each port expose by a container, and then which of them are exposed by the container group. It is not possible to translate ports, as recall in the FAQ.Also, beware that communication between containers is not using the name of the container (as in Docker Compose) but localhost!Thus, Grafana will point in its configuration to localhost:3036 for its database and localhost:8086 for the case of InfluxDB.Automated deploiementIt is possible to use YAML or ARM template. As mentioned in my previous article (in French),I highly recommend the use of ARM template that will allow to have some dynamic settings that can be changed during deployment.However, I will limit the number of parameters.Environment variablesThe environment variables we will use are described below.Table 1. MySQLNameDescriptionMYSQL_DATABASEThe name of a database to be created on image startup.MYSQL_USER, MYSQL_PASSWORDUsername and password of a user created that has superuser permissions on the databaseMYSQL_RANDOM_ROOT_PASSWORDWill generate a random password for the root userOther environment variables are available and are described on MySQL&#8217;s Docker image page.Table 2. InfluxDBNameDescriptionINFLUXDB_DBThe name of a database to be created on image startup.INFLUXDB_ADMIN_USER, INFLUXDB_ADMIN_PASSWORDUsername and password of database admin.Other environment variables are available and are described on InfluxDB&#8217;s Docker image page.Grafana has a very extensible mechanism that allows to define any parameter from environment variables.We will use the following environment variable.Table 3. GrafanaNameDescriptionGF_DATABASE_URLConnection URL to MySQLGF_SECURITY_ADMIN_PASSWORDPassword for admin (this will avoid going through the configuration assistant)In my previous article, I also used the variable GF_SERVER_DOMAIN to set up Grafana behind NGINX.ARM templateThe ARM template and settings are shown below.grafana.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"type\": \"securestring\",            \"metadata\": {                \"description\": \"Password for Grafana admin.\"            }        },        \"containerGroupName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Container Group name.\"            }        },        \"dnsLabel\": {            \"type\": \"string\",            \"defaultValue\": \"\",            \"metadata\": {                \"description\": \"DNS label used to by the container group. The FQDN is &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io\"            }        },        \"storageAccountName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Name of the Storage Account\"            }        },        \"storageAccountType\": {            \"type\": \"string\",            \"defaultValue\": \"Standard_LRS\",            \"allowedValues\": [                \"Standard_LRS\",                \"Standard_GRS\",                \"Standard_ZRS\",                \"Premium_LRS\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"accessTier\": {            \"type\": \"string\",            \"defaultValue\": \"Hot\",            \"allowedValues\": [                \"Hot\",                \"Cool\"            ],            \"metadata\": {                \"description\": \"The access tier used for billing.\"            }        },        \"storageAccountKind\": {            \"type\": \"string\",            \"defaultValue\": \"StorageV2\",            \"allowedValues\": [                \"StorageV2\",                \"Storage\",                \"BlobStorage\",                \"FileStorage\",                \"BlockBlobStorage\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"advancedThreatProtectionEnabled\": {            \"type\": \"bool\",            \"defaultValue\": false,            \"metadata\": {                \"description\": \"Enable or disable Advanced Threat Protection.\"            }        },        \"shares\": {            \"type\": \"array\",            \"metadata\": {                \"description\": \"List of the file share names.\"            }        },        \"location\": {            \"type\": \"string\",            \"defaultValue\": \"[resourceGroup().location]\",            \"metadata\": {                \"description\": \"The region to deploy the resources into\"            }        },        \"tagValues\": {            \"type\": \"object\",            \"defaultValue\": {            }        }    },    \"variables\": {        \"dnsLabel\": \"[if(empty(parameters('dnsLabel')), parameters('containerGroupName'), parameters('dnsLabel'))]\",        \"fqdn\": \"[toLower(concat(variables('dnsLabel'),'.',replace(parameters('location'), ' ', ''),'.azurecontainer.io'))]\"    },    \"resources\": [        {            \"type\": \"Microsoft.Storage/storageAccounts\",            \"name\": \"[parameters('storageAccountName')]\",            \"location\": \"[parameters('location')]\",            \"apiVersion\": \"2018-07-01\",            \"sku\": {                \"name\": \"[parameters('storageAccountType')]\"            },            \"kind\": \"[parameters('storageAccountKind')]\",            \"properties\": {                \"accessTier\": \"[parameters('accessTier')]\",                \"encryption\": {                    \"keySource\": \"Microsoft.Storage\",                    \"services\": {                        \"blob\": {                            \"enabled\": true                        },                        \"file\": {                            \"enabled\": true                        }                    }                },                \"supportsHttpsTrafficOnly\": true            },            \"resources\": [                {                    \"condition\": \"[parameters('advancedThreatProtectionEnabled')]\",                    \"type\": \"providers/advancedThreatProtectionSettings\",                    \"name\": \"Microsoft.Security/current\",                    \"apiVersion\": \"2017-08-01-preview\",                    \"dependsOn\": [                        \"[resourceId('Microsoft.Storage/storageAccounts/', parameters('storageAccountName'))]\"                    ],                    \"properties\": {                        \"isEnabled\": true                    }                }            ]        },        {            \"type\": \"Microsoft.Storage/storageAccounts/fileServices/shares\",            \"apiVersion\": \"2019-04-01\",            \"name\": \"[concat(parameters('storageAccountName'), '/default/', parameters('shares')[copyIndex()])]\",            \"copy\": {                \"name\": \"sharecopy\",                \"count\": \"[length(parameters('shares'))]\"            },            \"dependsOn\": [                \"[parameters('storageAccountName')]\"            ]        },        {            \"name\": \"[parameters('containerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"dependsOn\": [                \"sharecopy\"            ],            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"properties\": {                \"containers\": [                    {                        \"name\": \"mysql\",                        \"properties\": {                            \"image\": \"mysql\",                            \"environmentVariables\": [                                {                                    \"name\": \"MYSQL_USER\",                                    \"value\": \"grafana\"                                },                                {                                    \"name\": \"MYSQL_PASSWORD\",                                    \"secureValue\": \"grafana\"                                },                                {                                    \"name\": \"MYSQL_RANDOM_ROOT_PASSWORD\",                                    \"value\": \"yes\"                                },                                {                                    \"name\": \"MYSQL_DATABASE\",                                    \"value\": \"grafana\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 3306                                },                                {                                    \"port\": 443                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"mysql-data\",                                    \"mountPath\": \"/var/lib/mysql\"                                }                            ]                        }                    },                                        {                        \"name\": \"influxdb\",                        \"properties\": {                            \"image\": \"influxdb\",                            \"environmentVariables\": [                                {                                    \"name\": \"INFLUXDB_DB\",                                    \"value\": \"PERF\"                                },                                {                                    \"name\": \"INFLUXDB_ADMIN_USER\",                                    \"value\": \"influxadmin\"                                },                                {                                    \"name\": \"INFLUXDB_ADMIN_PASSWORD\",                                    \"secureValue\": \"influxadmin\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 8086                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"influxdb-volume\",                                    \"mountPath\": \"/var/lib/influxdb\"                                }                            ]                        }                    },                    {                        \"name\": \"grafana\",                        \"properties\": {                            \"image\": \"grafana/grafana\",                            \"ports\": [                                {                                    \"port\": 3000                                }                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"GF_SECURITY_ADMIN_PASSWORD\",                                    \"secureValue\": \"[parameters('grafanaAdminPassword')]\"                                },                                {                                    \"name\": \"GF_DATABASE_URL\",                                    \"secureValue\": \"mysql://grafana:grafana@localhost:3306/grafana\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 1,                                    \"memoryInGb\": 0.5                                }                            },                            \"volumeMounts\": [                                {                                    \"name\": \"grafana-volume\",                                    \"mountPath\": \"/var/lib/grafana\"                                },                                {                                    \"name\": \"grafana-provisioning\",                                    \"mountPath\": \"/etc/grafana/provisioning/datasources\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"OnFailure\",                \"ipAddress\": {                    \"type\": \"Public\",                    \"ports\": [                        {                            \"port\": 3000                        },                        {                            \"port\": 8086                        }                    ],                    \"dnsNameLabel\": \"[variables('dnsLabel')]\"                },                \"volumes\": [                    {                        \"name\": \"mysql-data\",                        \"azureFile\": {                            \"shareName\": \"mysql-data\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"influxdb-volume\",                        \"azureFile\": {                            \"shareName\": \"influxdb-volume\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"grafana-volume\",                        \"azureFile\": {                            \"shareName\": \"grafana-volume\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"grafana-provisioning\",                        \"secret\": {                            \"influxdb.yaml\": \"[base64('apiVersion: 1deleteDatasources:  - name: InfluxDB    orgId: 1datasources:  - name: InfluxDB    type: influxdb    access: proxy    orgId: 1    database: PERF    user: influxadmin    password: influxadmin    url: http://localhost:8086                            ')]\"                        }                    }                ]            }        }    ],    \"outputs\": {    }}grafana.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"value\": \"grafanapwd\"        },        \"containerGroupName\": {            \"value\": \"test-grafana-influxdb\"        },        \"storageAccountName\": {            \"value\": \"stotestacmenginx\"        },        \"shares\": {            \"value\": [                \"mysql-data\",                \"influxdb-volume\",                \"grafana-volume\"            ]        },        \"location\": {            \"value\": \"West Europe\"        }    }}It is possible to deploy by using the following PowerShell command: New-AzResourceGroupDeployment -ResourceGroupName $rg -TemplateFile .\\influxdb-grafana.json -TemplateParameterFile .\\influxdb-grafana.parameters.json -VerboseAlso, by using Az CLI:az group deployment create --resource-group $rg --template-file ./influxdb-grafana.json --parameters @influxdb-grafana.parameters.json --handle-extended-json-formatYou will have to use the setting --handle-extended-json-format that provides support for multiline in JSON.ConclusionWithin a few minutes, it is possible to assemble a Grafana and an InfluxDB database.There is a lot of use cases that might benefits for an InfluxDB and Grafana: IoT, application monitoring, etc. A use case could also be load tests with Locust. To be continued&#8230;&#8203;",
        "url": "//2020/05/29/aci-grafana-influxdb-en/"
      }
      ,
    
      "2020-05-19-moteur-template-php-i18n": {
        "title": "Moteur de template PHP et internationalisation",
        "tags": "php, i18n, blade",
        "date": "May 19, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionLes frameworks PHP comme Laravel, Symfony ou Phalcondispose tous d&#8217;un moteur de template propre, respectivement Blade,Twig ou Volt.Reprenant un projet PHP qui n&#8217;utilisait aucun framework, il me fallait une solution qui tourne sans framework impos√©.Et pourquoi pas Twig ?Mon choix s&#8217;est d&#8217;abord port√© sur Twig, qui existe en autonome en principe.J&#8217;ai d√ª m&#8217;en d√©tourner pour les raisons suivantes&nbsp;:La toute derni√®re version (3.x) ne supporte plus l&#8217;extensions d&#8217;internalisation mais requiert symfony/twig-bridge pour le tag trans. Or, symfony/twig-bridge. Il n&#8217;y a pas de documentation pour l&#8217;int√©gration dans un projet sans SymfonyCes extensions d&#8217;internationalisation reposent sur gettext.gettext est une solution tr√®s pr√©formante, cependant&nbsp;:Il n&#8217;y a pas d&#8217;outil gratuit qui permette une extraction des cha√Ænes de caract√®res&nbsp;:Poedit est certainement une tr√®s bonne solution mais l&#8217;extraction des cha√Ænes d&#8217;un fichier Twig requiert la licence pro.Toute autre solution est vou√©e √† g√©n√©r√©e les pages de Twig en fichier PHP et utiliser xgettext. Malheureusement, on perd le fichier d&#8217;origine.Les fichiers de traduction sont mis en cache par le serveur. La mise √† jour d&#8217;un fichier compil√© (i.e. .mo) peut requ√©rir un red√©marrage.Le comportement est diff√©rent entre Windows et Linux. Par exemple, Windows ne d√©finit la constante LC_MESSAGES, ce qui impose de forcer la locale pour LC_ALL ce qui peut avoir des cons√©quences importantes (dans la gestion des nombres, etc.).Il faut que la locale soit pr√©sente sur le serveur, ce qui est r√©dhibitoire pour un serveur partag√©.Le sauveur&nbsp;?Pour toute ces raisons, je me suis donc int√©ress√© au projet BladeOne, une impl√©mentation autonome et l√©g√®re de Blade.Elle supporte un module d&#8217;internationalisation int√©gr√© au moteur&nbsp;: BladeOneLang.Il est clair que la gestion des traductions ne pourrait convenir √† un projet d&#8217;envergure mais pour un projet sans Framework comme le mien, c&#8217;est parfait&nbsp;!InstallationL&#8217;installation se fait le plus simplement du monde gr√¢ce √† composer&nbsp;:composer require eftec/bladeoneIl existe d&#8217;autres m√©thodes document√©es dans le README.Il faut ensuite pr√©voir la cr√©ation de 3 r√©pertoires&nbsp;:cachePour le cacheviewsPour les vuesUtilisationCet exemple ultrasimple va se d√©composer en 3 fichiers&nbsp;:La vueLa traductionLe fichier PHP ex√©cut√©Commen√ßons par la vue. BladeOneLang d√©finit 3 m√©thodes pour aider √† la traduction&nbsp;:@_eVa rechercher la cha√Æne √† partir de la cl√©@_efVa permettre d&#8217;avoir des param√®tres@_nVa permettre de mettre au plurielL&#8217;exemple ci-dessous est un exemple de remplacement&nbsp;:views\\translation.blade.php&lt;h1&gt;Translation&lt;/h1&gt;Hat:&lt;br&gt;@_e('Hat')&lt;br&gt;&lt;br&gt;&lt;hr&gt;Trust this site always :&lt;br&gt;@_e('Trust this site always')&lt;br&gt;&lt;br&gt;&lt;hr&gt;'%s is a nice cat' with '{{$variable1}}' :&lt;br&gt;@_ef('%s is a nice cat', $variable1)&lt;br&gt;&lt;br&gt;La traduction se fait simplement dans un tableau associatif. Le tableau statique BladeOne::$dictionary sera utilis√© pour la traduction&nbsp;:locales\\fr.php&lt;?phpuse eftec\\bladeone\\BladeOne;BladeOne::$dictionary=array(    'Hat'=&gt;'Chapeau',    'Cat'=&gt;'Chat',    '%s is a nice cat'=&gt;'%s est un bon chat',    \"Trust this site always\" =&gt; \"Toujours faire confiance √† ce site\",    \"Deny\" =&gt; \"Refuser\");Finalement, le bout de code d&#8217;ex√©cution&nbsp;:translation.php&lt;?phprequire \"vendor/autoload.php\";Use eftec\\bladeone\\BladeOne;$views = __DIR__ . '/views';$cache = __DIR__ . '/cache';$blade = new BladeOne($views,$cache,BladeOne::MODE_AUTO); (1)$lang='fr'; // try es,jp or frinclude './locales/'.$lang.'.php'; (2)$blade-&gt;missingLog='./missingkey.txt'; // (optional) if a traduction is missing the it will be saved here.echo $blade-&gt;run(\"translation\",array(\"variable1\"=&gt;\"value1\")); (3)1Initialisation du moteur avec les r√©pertoires de cache et de vue.2Chargement du dictionnaire (statique) pour les traductions3G√©n√©ration du contenu √† partir de la vueUn petit coup de php -S localhost:8000, on saute sur http://localhost:8000/translation.php et voil√†&nbsp;:ConclusionBladeOne n&#8217;est probablement pas le projet du si√®cle mais propose une r√©ponse simple et √©l√©gante pour celui ou celle qui ne veut pas s&#8217;imposer un framework complet mais souhaite tout de m√™me s√©parer la vue du reste de l&#8217;application tout en conservant des capacit√©s d&#8217;internationalisation.Ce projet offre des avantages comme&nbsp;:L&#8217;ind√©pendance par rapport aux locales du serveurL&#8217;ind√©pendance par rapport au syst√®me d&#8217;exploitation du serveurLa rapidit√© et flexibilit√© de BladeA conserver en t√™te donc pour des petits projets requ√©rant de l&#8217;internationalisation.",
        "url": "//2020/05/19/moteur-template-php-i18n/"
      }
      ,
    
      "2020-05-03-vuejs-bulma": {
        "title": "Int√©grer Bulma CSS et Vue.js",
        "tags": "typescript, vue.js, css",
        "date": "May 3, 2020",
        "author": "",
        "category": "",
        "content": "Vue.js est un framework de d√©veloppement Web tr√®s int√©ressant. J&#8217;avais √©galement envie de voir autre chose que Bootstrap. J&#8217;ai donc donn√© un coup d&#8217;essai √† Bulma.Comme j&#8217;ai d√ª combiner 3 articles et quelques r√©sultats sur Stack Overflow pour avoir une bonne int√©gration entre les deux, voici un article pour d√©crire le modus operandi avec un projet utilisant TypeScript.Cr√©ation du projetLors de la cr√©ation du projet, pensez √† pr√©voir un pr√©processeur CSS. J&#8217;utilise node-sass mais je n&#8217;ai pas fait de comparaison avec dart-sass.InstallationL&#8217;installation se fait simplement avec la commande suivante&nbsp;:yarn add bulmaPersonnalisationCr√©er un fichier `.sass dans le r√©pertoire assets avec le contenu suivant&nbsp;:./assets/main.sass@charset \"utf-8\"$rouge: #DF776D$primary: $rouge@import \"../../node_modules/bulma/bulma.sass\"Importer la feuille de styleOuvrir le fichier src\\main.ts et ajouter la ligne suivante&nbsp;:import \"./assets/main.sass\";Les ic√¥nesBulma s&#8217;appuie sur Font Awesome 5 pour afficher des ic√¥nes. Pour pouvoir les utiliser, il faut donc penser √† charger le fichier de Font Awesome.Pour ce faire, ouvrir public\\index.html et ajouter dans la balise head la ligne suivante&nbsp;:&lt;script defer src=\"https://use.fontawesome.com/releases/v5.3.1/js/all.js\"&gt;&lt;/script&gt;Comme Font Awesome va continuer √† √©voluer, vous pouvez vous r√©f√©rer √† la page de d√©marrage de Bulma ou de Font Awesome pour avoir la derni√®re version disponible.ConclusionEt voil√† 5 √©tapes pour d√©marrer du bon pied avec Vue.js et Bulma&nbsp;!",
        "url": "//2020/05/03/vuejs-bulma/"
      }
      ,
    
      "2020-04-30-programmation-enfant": {
        "title": "Exercices de programmation pour enfant",
        "tags": "enfants, programmation",
        "date": "April 30, 2020",
        "author": "",
        "category": "",
        "content": "Quand on recherche des √©l√©ments pour enseigner la programmation, on tombe souvent sur la question des outils, voire du langage √† choisir.Ainsi, on peut tomber sur ce repo GitHub qui recense une liste impressionnante d&#8217;outils.Mes enfants ont d√©j√† appr√©hend√© la programmation au travers des heures de code de code.org.Je voulais sortir du mode \"programmation par bloc\" √† la Scratch pour aller vers un vrai langage de programmation.Quels exercices peut-on donner √† des enfants de 8-10 ans pour appr√©hender la programmation sans √™tre trop r√©barbatif ?Cet article se veut agnostique par rapport au langage.Sachez cependant que mon choix s&#8217;est port√© sur Python, ce qui va aussi me permettre de me d√©rouiller sur ce langage.Il existe probablement des tonnes de vid√©o pour pr√©senter Python. Une rapide recherche m&#8217;a conduit vers cette liste de vid√©os qui constitue une bonne introduction.Finalement, m√™me si au d√©but, j&#8217;√©tais que convaincu que IDLE, l&#8217;√©diteur par d√©faut ferait bien l&#8217;affaire, j&#8217;ai finalement install√© Code with Mu.J&#8217;ai le secret espoir qu&#8217;on pourra utiliser un de ses modes (PyGame Zero ou Adafruit par exemple).Le√ßon 1 - IntroCommen√ßons par les basiques&nbsp;: la pr√©sentation d&#8217;un ordinateur.Rien de tel que d&#8217;ouvrir le capot de son ordinateur portable pour y voir un disque dur, la RAM, la carte m√®re et deviner le processeur sous son radiateur.Il faudra √©galement insister sur les interfaces&nbsp;:Les interfaces homme-machine&nbsp;: clavier, √©cran, sourisLes ports USB, Ethernet, etc.Le√ßon 2 - le clavierEcrire avec un clavier n&#8217;a absolument rien de naturel&nbsp;!Il conviendra donc&nbsp;:D&#8217;avoir une vague r√©flexion sur l&#8217;ordre des lettres sur un clavierD&#8217;apprendre √† faire des minuscules et des majuscules (la touche Caps Lock reste optionnelle)De comprendre comment faire le caract√®re du haut ou de droite, respectivement avec Shift et Alt Gr, en comprenant que l&#8217;on peut garder enfonc√© ces touches de modification (quel bonheur de voir nos enfants tenter d&#8217;appuyer sur Shift et une touche simultan√©ment pour un r√©sultat al√©atoire)D&#8217;apprendre quelques symboles utiles √† la programmation comme \"accolade\", \"di√®se\", \"barre oblique\", etc.En bonus&nbsp;: Ctrl+C et Ctrl+V pour faire de nos bambins des consultants √©m√©rites&nbsp;!Le√ßon 3 - Les variablesA ce stade, vous allez me dire : \"toujours pas d&#8217;exercice de programmation !\". J&#8217;y arrive&nbsp;!La premi√®re chose √† voir est certainement ce qu&#8217;est une variable pour stocker un param√®tre ou le r√©sultat d&#8217;une fonction.ExerciceJ&#8217;ai 12 bonbons. Il y a 2 enfants. En partageant √©quitablement, combien de bonbons chaque enfant aura&nbsp;?Et s&#8217;il y avait 3 enfants&nbsp;?NotionsVariables, Fonction d&#8217;affichage (print), Utilisation du mode interactif (REPL) vs. Cr√©ation d&#8217;un programme dans un fichierLe√ßon 4 - boucle for et fonctionsExerciceAfficher la table de multiplication de 5, d&#8217;abord sans boucle for, puis avec.En faire une fonction pour afficher n&#8217;importe quelle table de multiplication.Afficher toutes les tables de multiplication de 1 √† 10.NotionsOp√©rateurs (+, *), boucle for, fonctions.Les enfants connaissent les boucles \"r√©p√©ter n fois\" dans la programmation par bloc.Bonus : afficher une cha√Æne format√©e pour afficher le r√©sultat de la multiplicationLe√ßon 5 - conjuguer les verbes du premier groupeExerciceDemander un verbe du premier groupe et le conjuguer au pr√©sent de l&#8217;indicatif, au futur, etc.Bonus : remonter une erreur si verbe \"aller\" ou verbe qui ne se termine pas par \"-er\" ou afficher \"j'\" √† la place de \"je\" si verbe commen√ßant par une voyelle.NotionsInteraction avec l&#8217;utilisation (input), concat√©nation de cha√Æne de caract√®res. Eventuellement, introduction aux conditions.Le√ßon 5 - les conditionsExerciceD√©finir un nombre hasard et tenter de le deviner avec le minimum de tentativesNotionsBoucle while, conditions, utilisation de module (pour random).Les enfants connaissent les boucles \"r√©p√©ter tant que\" dans la programmation par bloc.Le√ßon 6 - Le syst√®me de fichierExerciceA la fa√ßon de Raymond Queneau pour ses Cent mille milliards de po√®mes, lire un fichier texte qui contiendrait des vers et essayer de g√©n√©rer al√©atoirement des po√®mes.INFO: On peut en voir une adaptation Web par Magnus Bodin.NotionsUtilisation de module (pour random), lecture de fichier.ConclusionVoici un premier ensemble d&#8217;exercices qui doivent permettre d&#8217;aborder la base&nbsp;:Les variablesLes boucles for et whileLes conditions ifLes acc√®s aux fichiersC&#8217;est suffisant pour aborder d&#8217;autres exercices comme le li√®vre et la tortue.Il reste bien d&#8217;autres choses √† voir mais cela pourra faire l&#8217;objet d&#8217;un autre article.",
        "url": "//2020/04/30/programmation-enfant/"
      }
      ,
    
      "2020-04-15-docker-windows-2019": {
        "title": "Des containers Linux sur Windows Server 2019",
        "tags": "docker, 2019, WindowsServer2019",
        "date": "April 15, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionMicrosoft fournit de la doc pour installer Docker sur Windows Server 2019.D√®s que l&#8217;on parle Linux, on est renvoy√© vers de la doc pour Windows 10, qui pousse vers l&#8217;utilisation de Docker Desktop.En outre, la doc de Docker est r√©f√©renc√©e.Pour autant, je voulais une solution qui fonctionne sans Docker Desktop, qui requiert aujourd&#8217;hui un compte, ce qui ne convient pas dans un contexte \"Serveur\".Cette page est TRES fortement inspir√©e d&#8217;un article de Ben Thomas.Il s&#8217;agit en premier lieu d&#8217;une traduction. J&#8217;ai cependant adapt√© quelques √©tapes car cela n&#8217;a pas fonctionn√© pour moi.La proc√©dure a √©t√© test√©e sur Windows Server 2019 1809, qui b√©n√©ficie d&#8217;un support long terme.Pour faire ce test sur une VM Azure, il faut s&#8217;assurer que la VM supporte la virtualisation imbriqu√©e. La liste des types de VM supportant la virtualisation imbriqu√©e est disponible sur le site de Microsoft.On pourra faire des tests avec les VM de s√©rie D_v3 ou Ds_v3 par exemple.Toutes les commandes PowerShell donn√©es ci-dessous sont √† ex√©cuter dans un prompt PowerShell En tant qu&#8217;administrateur.Installation d&#8217;Hyper-VL&#8217;installation d&#8217;Hyper-V peut faire simplement en PowerShell gr√¢ce √† la ligne de commande suivante&nbsp;:Install-WindowsFeature -Name Hyper-V,Containers -IncludeAllSubFeature -IncludeManagementToolsEn principe, un red√©marrage est n√©cessaire. Ceci √©tant, on peut attendre la fin de la proc√©dure.Installation de DockerToujours en PowerShell&nbsp;:Install-Module -Name DockerMsftProvider -Repository PSGallery -ForceInstall-Package -Name docker -ProviderName DockerMsftProvider -Update -ForcePour une raison que j&#8217;ignore, docker vient avec une version 17.0.En for√ßant la mise √† jour, on obtient une version 19.03, beaucoup plus acceptable.Groupe de s√©curit√©Par d√©faut, il faut √™tre administrateur de la machine pour pouvoir communiquer avec le d√©mon Docker, pour construire ou ex√©cuter une image par exemple.Il est cependant possible d&#8217;autoriser un groupe sp√©cifique, qu&#8217;on appellera \"docker\".Les commandes PowerShell ci-dessous permettent de cr√©er le groupe, s&#8217;il n&#8217;existe pas d√©j√†&nbsp;:$dockerGroup = \"docker\"$g = Get-LocalGroup $dockerGroup -EA 0if ($g) {   Write-Host \"Group $dockerGroup already exists\"}else {   Write-Host \"Group $dockerGroup does not exist\"   New-LocalGroup -Name \"docker\"}Activer le support des containers LinuxL&#8217;activation des containers Linux peut se faire avec la commande PowerShell suivante&nbsp;:[Environment]::SetEnvironmentVariable(\"LCOW_SUPPORTED\", \"1\", \"Machine\")Le moteur Docker sous Windows 2019 peut g√©rer des images Windows ou Linux. Pour ex√©cuter des images Linux il est n√©cessaire de pr√©ciser le param√®tre --platform=linux.Il est cependant possible de d√©finir la plateforme par d√©faut avec la commande suivante&nbsp;:[Environment]::SetEnvironmentVariable(\"LCOW_API_PLATFORM_IF_OMITTED\", \"linux\", \"Machine\")Configuration du moteurMicrosoftd√©crit toutes les options disponibles.Nous aurons besoin de&nbsp;:Activer le mode exp√©rimentalConfigurer le groupe de s√©curit√©Encore une fois, la commande PowerShell$configfile = @\"{    \"experimental\": true,    \"group\": \"docker\"}\"@$configfile | Out-File -FilePath C:\\ProgramData\\docker\\config\\daemon.json -Encoding ascii -ForceNoyauUn noyau LinuxKit est n√©cessaire. Les commandes suivantes vont t√©l√©charger le noyau √† partir de la derni√®re release et le pousser dans le bon r√©pertoire.Ecraser le contenu du r√©pertoire C:\\Program Files\\Linux Containers\\, notamment le fichier initrd faisait que rien ne fonctionnait.$Archive = Join-Path $env:TEMP \"release.zip\"Invoke-WebRequest -Uri \"https://github.com/linuxkit/lcow/releases/download/v4.14.35-v0.3.9/release.zip\" -UseBasicParsing -OutFile $Archive$target = Join-Path $env:TEMP \"Linux Containers\"md $targetExpand-Archive $Archive -DestinationPath $target$kernel = Join-Path $target \"kernel\"Copy-Item $kernel \"$Env:ProgramFiles\\Linux Containers\\.\"TestApr√®s red√©marrage, vous devriez √™tre en mesure d&#8217;ex√©cuter la commande ci-dessous (sans √™tre administrateur) et obtenir un prompt bash&nbsp;:docker run --rm -it ubuntu bash",
        "url": "//2020/04/15/docker-windows-2019/"
      }
      ,
    
      "2020-02-01-aci-grafana-influxdb": {
        "title": "Grafana et InfluxDB sur Azure Container Instances",
        "tags": "docker, aci, azure, influxdb, grafana, arm",
        "date": "February 1, 2020",
        "author": "",
        "category": "",
        "content": "Azure Container Instances (ACI) fait partie des nombreuses fa√ßons d&#8217;ex√©cuter des containers sur Azure.Un des avantages d&#8217;ACI par rapport √† App Service (pr√©sent√© dans un pr√©c√©dent article) est lacapacit√© √† exposer plusieurs ports.Ainsi, nous allons exposer un Grafana et une base InfluxDB.Grafana est une solution open source pour la cr√©ation de tableau de bord.InfluxDB est son compagnon de choix pour le stockage de s√©rie temporelle (time series).Dans cet article, pour des raisons de simplicit√©, je n&#8217;exposerai pas Grafana en HTTPS.Il faudra se r√©f√©rer √† mon pr√©c√©dent article Certificat Let&#8217;s Encrypt sur Azure Container Instances et NGINX pour la mise en place de HTTPS.La solutionComme √©voqu√©, la solution tournera sur Azure Container Instances.Grafana a besoin d&#8217;une base de donn√©es pour sa configuration. Grafana supporte 3 bases de donn√©es&nbsp;:SQLiteMySQLPostgreSQLPour √©viter de perdre la configuration √† chaque red√©marrage, la persistance des donn√©es est assur√©e par Azure Files.Malheureusement, √† cause de certaines limitations, il n&#8217;a pas √©t√© possible de faire persister SQLite (embarqu√© par d√©faut dans Grafana) (une sombre histoire de verrou) ou d&#8217;utiliser l&#8217;image de base de PostgreSQL (une sombre histoire de propri√©taire sur des fichiers).On utilisera donc l&#8217;image docker de MySQL.MySQL ne sera pas expos√© sur InternetLes sources de donn√©es GrafanaIl est possible de fournir une liste de sources de donn√©es par fichier YAML.Nous allons utiliser ce m√©canisme pour configurer automatiquement InfluxDB.Ainsi la configuration de la source de donn√©es en YAML sera&nbsp;:influxdb.yamlapiVersion: 1deleteDatasources:  - name: InfluxDB    orgId: 1datasources:  - name: InfluxDB    type: influxdb    access: proxy    orgId: 1    database: PERF    user: influxadmin    password: influxadmin    url: http://localhost:8086Ce fichier sera pass√© comme secret.On utilisera la fonction base64 d&#8217;ARM template pour passer le fichier YAML en secret.Note sur les groupes de container dans Azure Container InstancesAzure Container Instances utilisent un format de donn√©es \"propri√©taire\" qui n&#8217;est ni Docker Compose, ni un fichier de d√©ploiement Kubernetes.Le point important √† garder en t√™te est que l&#8217;on va d√©clarer chaque port expos√© par un container, puis ensuite quels sont les ports expos√©s par le groupe de container. Il n&#8217;est pas possible de changer le port expos√© par un container par rapport au port du groupe (par une translation), comme rappel√© dans la FAQ.La communication entre les containers se fait non pas en utilisant le nom du container (comme dans Docker Compose) mais localhost&nbsp;!Ainsi Grafana pointera dans sa configuration vers localhost:3036 pour sa base de donn√©es et localhost:8086 pour le cas d&#8217;InfluxDB.Automatisation du d√©ploiementIl est possible d&#8217;utiliser du YAML ou de l&#8217;ARM template.Comme √©voqu√© dans mon pr√©c√©dent article, je recommande fortement l&#8217;utilisation d&#8217;ARM template qui va permettre de rendre dynamique certains param√®tres de d√©ploiement.Pour autant, je vais limiter les param√®tres possibles.Variables d&#8217;environnementLes variables d&#8217;environnement que nous allons utiliser sont d√©crites ci-dessous.Table 1. MySQLNomDescriptionMYSQL_DATABASENom de la base cr√©e au d√©marrageMYSQL_USER, MYSQL_PASSWORDNom de l&#8217;utilisateur et mot de passe propri√©taire de la baseMYSQL_RANDOM_ROOT_PASSWORDVa g√©n√©rer un mot de passe al√©atoire pour l&#8217;utilisateur rootD&#8217;autres variables d&#8217;environnement sont disponibles et sont d√©crites sur la page de l&#8217;image Docker de MySQL.Table 2. InfluxDBNomDescriptionINFLUXDB_DBNom de la base cr√©e au d√©marrageINFLUXDB_ADMIN_USER, INFLUXDB_ADMIN_PASSWORDNom de l&#8217;utilisateur et mot de passe administrateur de la baseD&#8217;autres variables d&#8217;environnement sont disponibles et sont d√©crites sur la page de l&#8217;image Docker d&#8217;InfluxDB.Grafana dispose d&#8217;un m√©canisme tr√®s extensible qui permet de d√©finir n&#8217;importe quel param√®tre √† partir de variables d&#8217;environnement.Table 3. GrafanaNomDescriptionGF_DATABASE_URLURL de connexion √† MySQLGF_SECURITY_ADMIN_PASSWORDMot de passe de l&#8217;utilisateur admin (cela √©vitera de passer dans l&#8217;assistant de configuration)Dans mon pr√©c√©dent article, j&#8217;avais √©galement utilis√© la variable GF_SERVER_DOMAIN pour configurer Grafana derri√®re NGINX.ARM templateL&#8217;ARM template et les param√®tres sont d√©finis ci-dessous.grafana.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"type\": \"securestring\",            \"metadata\": {                \"description\": \"Password for Grafana admin.\"            }        },        \"containerGroupName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Container Group name.\"            }        },        \"dnsLabel\": {            \"type\": \"string\",            \"defaultValue\": \"\",            \"metadata\": {                \"description\": \"DNS label used to by the container group. The FQDN is &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io\"            }        },        \"storageAccountName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Name of the Storage Account\"            }        },        \"storageAccountType\": {            \"type\": \"string\",            \"defaultValue\": \"Standard_LRS\",            \"allowedValues\": [                \"Standard_LRS\",                \"Standard_GRS\",                \"Standard_ZRS\",                \"Premium_LRS\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"accessTier\": {            \"type\": \"string\",            \"defaultValue\": \"Hot\",            \"allowedValues\": [                \"Hot\",                \"Cool\"            ],            \"metadata\": {                \"description\": \"The access tier used for billing.\"            }        },        \"storageAccountKind\": {            \"type\": \"string\",            \"defaultValue\": \"StorageV2\",            \"allowedValues\": [                \"StorageV2\",                \"Storage\",                \"BlobStorage\",                \"FileStorage\",                \"BlockBlobStorage\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"advancedThreatProtectionEnabled\": {            \"type\": \"bool\",            \"defaultValue\": false,            \"metadata\": {                \"description\": \"Enable or disable Advanced Threat Protection.\"            }        },        \"shares\": {            \"type\": \"array\",            \"metadata\": {                \"description\": \"List of the file share names.\"            }        },        \"location\": {            \"type\": \"string\",            \"defaultValue\": \"[resourceGroup().location]\",            \"metadata\": {                \"description\": \"The region to deploy the resources into\"            }        },        \"tagValues\": {            \"type\": \"object\",            \"defaultValue\": {            }        }    },    \"variables\": {        \"dnsLabel\": \"[if(empty(parameters('dnsLabel')), parameters('containerGroupName'), parameters('dnsLabel'))]\",        \"fqdn\": \"[toLower(concat(variables('dnsLabel'),'.',replace(parameters('location'), ' ', ''),'.azurecontainer.io'))]\"    },    \"resources\": [        {            \"type\": \"Microsoft.Storage/storageAccounts\",            \"name\": \"[parameters('storageAccountName')]\",            \"location\": \"[parameters('location')]\",            \"apiVersion\": \"2018-07-01\",            \"sku\": {                \"name\": \"[parameters('storageAccountType')]\"            },            \"kind\": \"[parameters('storageAccountKind')]\",            \"properties\": {                \"accessTier\": \"[parameters('accessTier')]\",                \"encryption\": {                    \"keySource\": \"Microsoft.Storage\",                    \"services\": {                        \"blob\": {                            \"enabled\": true                        },                        \"file\": {                            \"enabled\": true                        }                    }                },                \"supportsHttpsTrafficOnly\": true            },            \"resources\": [                {                    \"condition\": \"[parameters('advancedThreatProtectionEnabled')]\",                    \"type\": \"providers/advancedThreatProtectionSettings\",                    \"name\": \"Microsoft.Security/current\",                    \"apiVersion\": \"2017-08-01-preview\",                    \"dependsOn\": [                        \"[resourceId('Microsoft.Storage/storageAccounts/', parameters('storageAccountName'))]\"                    ],                    \"properties\": {                        \"isEnabled\": true                    }                }            ]        },        {            \"type\": \"Microsoft.Storage/storageAccounts/fileServices/shares\",            \"apiVersion\": \"2019-04-01\",            \"name\": \"[concat(parameters('storageAccountName'), '/default/', parameters('shares')[copyIndex()])]\",            \"copy\": {                \"name\": \"sharecopy\",                \"count\": \"[length(parameters('shares'))]\"            },            \"dependsOn\": [                \"[parameters('storageAccountName')]\"            ]        },        {            \"name\": \"[parameters('containerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"dependsOn\": [                \"sharecopy\"            ],            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"properties\": {                \"containers\": [                    {                        \"name\": \"mysql\",                        \"properties\": {                            \"image\": \"mysql\",                            \"environmentVariables\": [                                {                                    \"name\": \"MYSQL_USER\",                                    \"value\": \"grafana\"                                },                                {                                    \"name\": \"MYSQL_PASSWORD\",                                    \"secureValue\": \"grafana\"                                },                                {                                    \"name\": \"MYSQL_RANDOM_ROOT_PASSWORD\",                                    \"value\": \"yes\"                                },                                {                                    \"name\": \"MYSQL_DATABASE\",                                    \"value\": \"grafana\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 3306                                },                                {                                    \"port\": 443                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"mysql-data\",                                    \"mountPath\": \"/var/lib/mysql\"                                }                            ]                        }                    },                                        {                        \"name\": \"influxdb\",                        \"properties\": {                            \"image\": \"influxdb\",                            \"environmentVariables\": [                                {                                    \"name\": \"INFLUXDB_DB\",                                    \"value\": \"PERF\"                                },                                {                                    \"name\": \"INFLUXDB_ADMIN_USER\",                                    \"value\": \"influxadmin\"                                },                                {                                    \"name\": \"INFLUXDB_ADMIN_PASSWORD\",                                    \"secureValue\": \"influxadmin\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 8086                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"influxdb-volume\",                                    \"mountPath\": \"/var/lib/influxdb\"                                }                            ]                        }                    },                    {                        \"name\": \"grafana\",                        \"properties\": {                            \"image\": \"grafana/grafana\",                            \"ports\": [                                {                                    \"port\": 3000                                }                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"GF_SECURITY_ADMIN_PASSWORD\",                                    \"secureValue\": \"[parameters('grafanaAdminPassword')]\"                                },                                {                                    \"name\": \"GF_DATABASE_URL\",                                    \"secureValue\": \"mysql://grafana:grafana@localhost:3306/grafana\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 1,                                    \"memoryInGb\": 0.5                                }                            },                            \"volumeMounts\": [                                {                                    \"name\": \"grafana-volume\",                                    \"mountPath\": \"/var/lib/grafana\"                                },                                {                                    \"name\": \"grafana-provisioning\",                                    \"mountPath\": \"/etc/grafana/provisioning/datasources\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"OnFailure\",                \"ipAddress\": {                    \"type\": \"Public\",                    \"ports\": [                        {                            \"port\": 3000                        },                        {                            \"port\": 8086                        }                    ],                    \"dnsNameLabel\": \"[variables('dnsLabel')]\"                },                \"volumes\": [                    {                        \"name\": \"mysql-data\",                        \"azureFile\": {                            \"shareName\": \"mysql-data\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"influxdb-volume\",                        \"azureFile\": {                            \"shareName\": \"influxdb-volume\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"grafana-volume\",                        \"azureFile\": {                            \"shareName\": \"grafana-volume\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"grafana-provisioning\",                        \"secret\": {                            \"influxdb.yaml\": \"[base64('apiVersion: 1deleteDatasources:  - name: InfluxDB    orgId: 1datasources:  - name: InfluxDB    type: influxdb    access: proxy    orgId: 1    database: PERF    user: influxadmin    password: influxadmin    url: http://localhost:8086                            ')]\"                        }                    }                ]            }        }    ],    \"outputs\": {    }}grafana.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"value\": \"grafanapwd\"        },        \"containerGroupName\": {            \"value\": \"test-grafana-influxdb\"        },        \"storageAccountName\": {            \"value\": \"stotestacmenginx\"        },        \"shares\": {            \"value\": [                \"mysql-data\",                \"influxdb-volume\",                \"grafana-volume\"            ]        },        \"location\": {            \"value\": \"West Europe\"        }    }}Il est possible de d√©ployer par PowerShell&nbsp;: New-AzResourceGroupDeployment -ResourceGroupName $rg -TemplateFile .\\influxdb-grafana.json -TemplateParameterFile .\\influxdb-grafana.parameters.json -VerboseEgalement, en Az CLI&nbsp;:az group deployment create --resource-group $rg --template-file ./influxdb-grafana.json --parameters @influxdb-grafana.parameters.json --handle-extended-json-formatIl faudra bien penser au param√®tre --handle-extended-json-format qui apporte le support du multiligne en JSON.ConclusionEn quelques minutes, il est possible de monter un Grafana et une base InfluxDB.Les cas d&#8217;usage d&#8217;InfluxDB et Grafana ne manquent pas&nbsp;: IoT, surveillance applicative, etc.Un cas d&#8217;utilisation pourrait √™tre aussi des tests de charge avec Locust.A suivre&#8230;&#8203;",
        "url": "//2020/02/01/aci-grafana-influxdb/"
      }
      ,
    
      "2020-01-30-aci-letsencrypt-nginx": {
        "title": "Certificat Let&amp;#8217;s Encrypt sur Azure Container Instances et NGINX",
        "tags": "docker, aci, azure, nginx, letsencrypt, arm",
        "date": "January 30, 2020",
        "author": "",
        "category": "",
        "content": "Azure Container Instances fait partie des nombreuses fa√ßons d&#8217;ex√©cuter des containers sur Azure.J&#8217;ai d√©j√† pr√©sent√© dans un pr√©c√©dent article l&#8217;ex√©cution de container sur App Service. Cette m√©thode expose automatiquement une URL en azurewebsites.net reconnue par les navigateurs. Malheureusement, on ne peut exposer qu&#8217;un port.Microsoft propose d√©j√† une m√©thode √† base de NGINX pour exposer un point de terminaison en SSL. Malheureusement, la m√©thode d√©crite se base sur des certificats g√©n√©r√©s au pr√©alable, voire auto-sign√©s si on suit la doc&nbsp;!Point d&#8217;attention sur Azure Files et client Let&#8217;s EncryptAzure Files est utilis√© conjointant avec Azure Container Instances pour assurer la persistance des donn√©es. Les disques manag√©s ne sont pas support√©s.De fait, Azure Files souffre de quelques limitations comme le non-support des liens symboliques, la gestion des droits POSIX, etc.Mon premier choix pour l&#8217;enr√¥lement de certificat s&#8217;√©tait port√© sur certbot - le client recommand√© par Let&#8217;s Encrypt - et son image Docker.Malheureusement, il s&#8217;est av√©r√© que certbot utilise des liens symboliques pour g√©rer les certificats.Let&#8217;s Encrypt propose une longue liste de client.Je me suis donc tourn√© vers acme.sh qui propose √©galementune image Docker.Les √©tapesLe processus complet va se d√©couper en 2 grandes √©tapes&nbsp;:L&#8217;√©mission du certificatL&#8217;utilisation du certificatEtape 1&nbsp;: √©mission du certificatCette √©tape va consister en&nbsp;:La cr√©ation du compte de stockage (Storage Account) et des partages associ√©s (Files). Au moins 2 partages doivent √™tre cr√©√©s pour&nbsp;:La config d&#8217;acme.shLes certificats √† utiliser avec NGINX ult√©rieurementLa cr√©ation de 2 r√©pertoires n√©cessaires √† acme.shLa g√©n√©ration du certificat en utilisant le mode autonome d&#8217;acme.shL&#8217;installation des certificats pour l&#8217;utilisation par NGINXTout a √©t√© automatis√© avec un ARM template.Ainsi, l&#8217;ARM template permet de&nbsp;:Cr√©er les ressources AzureCr√©ation d&#8217;un Azure Container Instance s&#8217;appuyant sur l&#8217;image microsoft/azure-cli pour cr√©er les r√©pertoires.Cela correspond √† ex√©cuter commande Az CLI az storage directory create --name certs --share-name acme-certCr√©ation d&#8217;un Azure Container Instance avec l&#8217;image neilpang/acme.sh pour l&#8217;√©mission du certificat.Cela revient √† ex√©cuter la commande acme.sh --issue --standalone -d $FQDNCr√©ation d&#8217;un Azure Container Instance avec l&#8217;image neilpang/acme.sh pour l&#8217;installation du certificat.Le FQDN utilisable dans ce contexte est de la forme &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io, dnsLabel √©tant un param√®tre que l&#8217;on peut d√©finir.Ci-dessous l&#8217;ARM template utilis√©&nbsp;:certificate.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"containerGroupName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Container Group name.\"            }        },        \"dnsLabel\": {            \"type\": \"string\",            \"defaultValue\": \"\",            \"metadata\": {                \"description\": \"DNS label used to by the container group. The FQDN is &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io\"            }        },        \"storageAccountName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Name of the Storage Account\"            }        },        \"storageAccountType\": {            \"type\": \"string\",            \"defaultValue\": \"Standard_LRS\",            \"allowedValues\": [                \"Standard_LRS\",                \"Standard_GRS\",                \"Standard_ZRS\",                \"Premium_LRS\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"accessTier\": {            \"type\": \"string\",            \"defaultValue\": \"Hot\",            \"allowedValues\": [                \"Hot\",                \"Cool\"            ],            \"metadata\": {                \"description\": \"The access tier used for billing.\"            }        },        \"storageAccountKind\": {            \"type\": \"string\",            \"defaultValue\": \"StorageV2\",            \"allowedValues\": [                \"StorageV2\",                \"Storage\",                \"BlobStorage\",                \"FileStorage\",                \"BlockBlobStorage\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"advancedThreatProtectionEnabled\": {            \"type\": \"bool\",            \"defaultValue\": false,            \"metadata\": {                \"description\": \"Enable or disable Advanced Threat Protection.\"            }        },        \"shares\": {            \"type\": \"array\",            \"metadata\": {                \"description\": \"List of the file share names.\"            }        },        \"location\": {            \"type\": \"string\",            \"defaultValue\": \"[resourceGroup().location]\",            \"metadata\": {                \"description\": \"The region to deploy the resources into\"            }        },        \"tagValues\": {            \"type\": \"object\",            \"defaultValue\": {            }        }    },    \"variables\": {        \"createFolderPrivateContainerGroupName\": \"[concat(parameters('containerGroupName'),'-cli-private')]\",        \"createFolderCertsContainerGroupName\": \"[concat(parameters('containerGroupName'),'-cli-certs')]\",        \"installContainerGroupName\": \"[concat(parameters('containerGroupName'),'-install')]\",        \"dnsLabel\": \"[if(empty(parameters('dnsLabel')), parameters('containerGroupName'), parameters('dnsLabel'))]\",        \"fqdn\": \"[toLower(concat(variables('dnsLabel'),'.',replace(parameters('location'), ' ', ''),'.azurecontainer.io'))]\"    },    \"resources\": [        {            \"type\": \"Microsoft.Storage/storageAccounts\",            \"name\": \"[parameters('storageAccountName')]\",            \"location\": \"[parameters('location')]\",            \"apiVersion\": \"2018-07-01\",            \"sku\": {                \"name\": \"[parameters('storageAccountType')]\"            },            \"kind\": \"[parameters('storageAccountKind')]\",            \"properties\": {                \"accessTier\": \"[parameters('accessTier')]\",                \"encryption\": {                    \"keySource\": \"Microsoft.Storage\",                    \"services\": {                        \"blob\": {                            \"enabled\": true                        },                        \"file\": {                            \"enabled\": true                        }                    }                },                \"supportsHttpsTrafficOnly\": true            },            \"resources\": [                {                    \"condition\": \"[parameters('advancedThreatProtectionEnabled')]\",                    \"type\": \"providers/advancedThreatProtectionSettings\",                    \"name\": \"Microsoft.Security/current\",                    \"apiVersion\": \"2017-08-01-preview\",                    \"dependsOn\": [                        \"[resourceId('Microsoft.Storage/storageAccounts/', parameters('storageAccountName'))]\"                    ],                    \"properties\": {                        \"isEnabled\": true                    }                }            ]        },        {            \"type\": \"Microsoft.Storage/storageAccounts/fileServices/shares\",            \"apiVersion\": \"2019-04-01\",            \"name\": \"[concat(parameters('storageAccountName'), '/default/', parameters('shares')[copyIndex()])]\",            \"copy\": {                \"name\": \"sharecopy\",                \"count\": \"[length(parameters('shares'))]\"            },            \"dependsOn\": [                \"[parameters('storageAccountName')]\"            ]        },        {            \"name\": \"[variables('createFolderCertsContainerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"dependsOn\": [                \"sharecopy\"            ],            \"properties\": {                \"containers\": [                    {                        \"name\": \"create-folder-private\",                        \"properties\": {                            \"image\": \"microsoft/azure-cli\",                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.1,                                    \"memoryInGb\": 0.1                                }                            },                            \"command\": [                                \"az\",                                \"storage\",                                \"directory\",                                \"create\",                                \"--name\",                                \"certs\",                                \"--share-name\",                                \"acme-cert\"                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"AZURE_STORAGE_KEY\",                                    \"value\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                                },                                {                                    \"name\": \"AZURE_STORAGE_ACCOUNT\",                                    \"value\": \"[parameters('storageAccountName')]\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\"            }        },        {            \"name\": \"[variables('createFolderPrivateContainerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"dependsOn\": [                \"sharecopy\"            ],            \"properties\": {                \"containers\": [                    {                        \"name\": \"create-folder-private\",                        \"properties\": {                            \"image\": \"microsoft/azure-cli\",                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.1,                                    \"memoryInGb\": 0.1                                }                            },                            \"command\": [                                \"az\",                                \"storage\",                                \"directory\",                                \"create\",                                \"--name\",                                \"private\",                                \"--share-name\",                                \"acme-cert\"                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"AZURE_STORAGE_KEY\",                                    \"value\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                                },                                {                                    \"name\": \"AZURE_STORAGE_ACCOUNT\",                                    \"value\": \"[parameters('storageAccountName')]\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\"            }        },        {            \"name\": \"[parameters('containerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"dependsOn\": [                \"[variables('createFolderPrivateContainerGroupName')]\",                \"[variables('createFolderCertsContainerGroupName')]\"            ],            \"properties\": {                \"containers\": [                    {                        \"name\": \"acme-sh\",                        \"properties\": {                            \"image\": \"neilpang/acme.sh\",                            \"command\": [                                \"--issue\",                                \"--standalone\",                                \"-d\",                                \"[variables('fqdn')]\"                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.1,                                    \"memoryInGb\": 0.1                                }                            },                            \"ports\": [                                {                                    \"port\": 80                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"acme-config\",                                    \"mountPath\": \"/acme.sh/\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\",                \"ipAddress\": {                    \"type\": \"Public\",                    \"ports\": [                        {                            \"port\": 80                        }                    ],                    \"dnsNameLabel\": \"[variables('dnsLabel')]\"                },                \"volumes\": [                    {                        \"name\": \"acme-config\",                        \"azureFile\": {                            \"shareName\": \"acme-config\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                        }                    }                ]            }        },        {            \"name\": \"[variables('installContainerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"dependsOn\": [                \"[parameters('containerGroupName')]\"            ],            \"properties\": {                \"containers\": [                    {                        \"name\": \"acme-sh\",                        \"properties\": {                            \"image\": \"neilpang/acme.sh\",                            \"command\": [                                \"--install-cert\",                                \"--key-file\",                                \"/etc/pki/tls/private/key.pem\",                                \"--fullchain-file\",                                \"/etc/pki/tls/certs/fullchain.pem\",                                \"-d\",                                \"[variables('fqdn')]\"                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.1,                                    \"memoryInGb\": 0.1                                }                            },                            \"volumeMounts\": [                                {                                    \"name\": \"acme-config\",                                    \"mountPath\": \"/acme.sh/\"                                },                                {                                    \"name\": \"acme-cert\",                                    \"mountPath\": \"/etc/pki/tls/\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\",                \"volumes\": [                    {                        \"name\": \"acme-cert\",                        \"azureFile\": {                            \"shareName\": \"acme-cert\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"acme-config\",                        \"azureFile\": {                            \"shareName\": \"acme-config\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                        }                    }                ]            }        }    ],    \"outputs\": {    }}Et les param√®tres associ√©s&nbsp;:certificate.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"containerGroupName\": {            \"value\": \"testacmenginx\"        },        \"storageAccountName\": {            \"value\": \"stotestacmenginx\"        },        \"storageAccountType\": {            \"value\": \"Standard_LRS\"        },        \"accessTier\": {            \"value\": \"Hot\"        },        \"storageAccountKind\": {            \"value\": \"StorageV2\"        },        \"advancedThreatProtectionEnabled\": {            \"value\": false        },        \"shares\": {            \"value\": [                \"acme-config\",                \"acme-cert\"            ]        },        \"tagValues\": {            \"value\": {}        },        \"location\": {            \"value\": \"West Europe\"        }    }}Au moment de la r√©daction de cet article, Azure Container Instances n&#8217;est pas disponible en France. J&#8217;ai donc forc√© l&#8217;utilisation d&#8217;Europe de l&#8217;Ouest.Il suffit alors de d√©ployer cet ARM template et ses param√®tres. Je recommande l&#8217;utilisation de la cmdlet PowerShell New-AzResourceGroupDeployment.Une fois le d√©ploiement r√©alis√©, il faut supprimer les ACI manuellement&nbsp;:rg=XXXcn=testacmenginxaz container delete -g $rg -y -n ${cn}az container delete -g $rg -y -n ${cn}-cli-privateaz container delete -g $rg -y -n ${cn}-cli-certsaz container delete -g $rg -y -n ${cn}-installEtape 2&nbsp;: utilisation des certificats par NGINXDans cette √©tape, nous allons d√©ployer un NGINX avec SSL.La configuration SSL a √©t√© renforc√©e afin de viser un A+ sur SSL Labs.Voici ce que donne la configuration NGINX&nbsp;:site.templateserver {    listen 80;    server_name ${NGINX_HOST};    server_tokens off;    location / {        return 301 https://$host$request_uri;    }}server {    listen 443 ssl;    server_name ${NGINX_HOST};    server_tokens off;    ssl_certificate /etc/pki/tls/certs/fullchain.pem;    ssl_certificate_key /etc/pki/tls/private/key.pem;    ssl_session_cache shared:le_nginx_SSL:1m;    ssl_session_timeout 1d;    ssl_session_tickets off;    ssl_protocols TLSv1.3 TLSv1.2;    ssl_prefer_server_ciphers on;    #ssl_ciphers \"EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\";    ssl_ciphers EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA512:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:ECDH+AESGCM:ECDH+AES256:DH+AESGCM:DH+AES256:RSA+AESGCM:!aNULL:!eNULL:!LOW:!RC4:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS;    ssl_ecdh_curve secp384r1;    ssl_stapling on;    ssl_stapling_verify on;    add_header Strict-Transport-Security \"max-age=15768000; includeSubdomains; preload;\" ;    #add_header Content-Security-Policy \"default-src 'none'; frame-ancestors 'none'; script-src 'self'; img-src 'self'; style-src 'self'; base-uri 'self'; form-action 'self';\";    add_header Referrer-Policy \"no-referrer, strict-origin-when-cross-origin\";    add_header X-Frame-Options SAMEORIGIN;    add_header X-Content-Type-Options nosniff;    add_header X-XSS-Protection \"1; mode=block\";    location / {        proxy_pass  http://localhost:3000;        proxy_set_header    Host                $http_host;        proxy_set_header    X-Real-IP           $remote_addr;        proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;    }}Cette configuration sera pass√©e comme un secret au container NGINX. Pour pouvoir le passer en secret, il faut alors l&#8217;encoder en base64. J&#8217;ai utilis√© mon Windows Subsystem for Linux (WSL) mais il existe d&#8217;autres fa√ßons d&#8217;encoder en base64. Sous linux, la commande est&nbsp;:base64 -w 0 mysite.templateJ&#8217;ai introduit la variable ${NGINX_HOST} qui sera remplac√©e au d√©marrage. Pour ce faire, j&#8217;utilise la commande envsubst, que je n&#8217;ai pas invent√©e car donn√©e par la documentation de l&#8217;image Docker de NGINX.2 petites choses √† noter cependant&nbsp;:Par d√©faut envsubst va substituer toutes les variables de la forme $VAR ou ${VAR}.Du coup, dans ma configuration, $http_host √©tait remplac√©e&#8230;&#8203; par une cha√Æne vide. J&#8217;ai donc restreint la substitution √† la seule variable ${NGINX_HOST}En Docker, il est possible de passer des commandes en Shell Form ou Exec Form. Je recommande cet article pour bien comprendre la diff√©rence.Azure Container Instances ne supporte que la forme Exec.Or, pour le d√©marrage de NGINX, j&#8217;avais besoin d&#8217;une s√©quence de programme pour r√©aliser la substitution et d√©marrer le d√©mon.J&#8217;ai donc trich√© en utilisant la forme Exec et la commande sh -c&nbsp;:\"command\": [    \"sh\",    \"-c\",    \"envsubst '$NGINX_HOST' &lt; /tmp/nginx/mysite.template &gt; /etc/nginx/conf.d/default.conf &amp;&amp; exec nginx -g 'daemon off;'\"]Comme √† l&#8217;√©tape 1, le d√©ploiement se fait avec un ARM template.Derri√®re le NGINX, j&#8217;ai mis un grafana dont le mot de passe admin est fix√© par param√®tre.nginx.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"type\": \"securestring\",            \"metadata\": {                \"description\": \"Password for Grafana admin.\"            }        },        \"containerGroupName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Container Group name.\"            }        },        \"dnsLabel\": {            \"type\": \"string\",            \"defaultValue\": \"\",            \"metadata\": {                \"description\": \"DNS label used to by the container group. The FQDN is &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io\"            }        },        \"storageAccountName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Name of the Storage Account\"            }        },        \"location\": {            \"type\": \"string\",            \"defaultValue\": \"[resourceGroup().location]\",            \"metadata\": {                \"description\": \"The region to deploy the resources into\"            }        },        \"tagValues\": {            \"type\": \"object\",            \"defaultValue\": {            }        }    },    \"variables\": {        \"dnsLabel\": \"[if(empty(parameters('dnsLabel')), parameters('containerGroupName'), parameters('dnsLabel'))]\",        \"fqdn\": \"[toLower(concat(variables('dnsLabel'),'.',replace(parameters('location'), ' ', ''),'.azurecontainer.io'))]\"    },    \"resources\": [        {            \"name\": \"[parameters('containerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"properties\": {                \"containers\": [                    {                        \"name\": \"nginx\",                        \"properties\": {                            \"image\": \"nginx:alpine\",                            \"command\": [                                \"sh\",                                \"-c\",                                \"envsubst '$NGINX_HOST' &lt; /tmp/nginx/mysite.template &gt; /etc/nginx/conf.d/default.conf &amp;&amp; exec nginx -g 'daemon off;'\"                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"NGINX_HOST\",                                    \"value\": \"[variables('fqdn')]\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 80                                },                                {                                    \"port\": 443                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"acme-cert\",                                    \"mountPath\": \"/etc/pki/tls/\"                                },                                {                                    \"name\": \"nginx-config\",                                    \"mountPath\": \"/tmp/nginx/\"                                }                            ]                        }                    },                    {                        \"name\": \"grafana\",                        \"properties\": {                            \"image\": \"grafana/grafana\",                            \"ports\": [                                {                                    \"port\": 3000                                }                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"GF_SECURITY_ADMIN_PASSWORD\",                                    \"value\": \"[parameters('grafanaAdminPassword')]\"                                },                                {                                    \"name\": \"GF_SERVER_DOMAIN\",                                    \"value\": \"[variables('fqdn')]\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 1,                                    \"memoryInGb\": 1                                }                            },                            \"volumeMounts\": [                                {                                    \"name\": \"acme-cert\",                                    \"mountPath\": \"/etc/pki/tls/\"                                },                                {                                    \"name\": \"nginx-config\",                                    \"mountPath\": \"/etc/nginx/conf.d/\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\",                \"ipAddress\": {                    \"type\": \"Public\",                    \"ports\": [                        {                            \"port\": 80                        },                        {                            \"port\": 443                        }                    ],                    \"dnsNameLabel\": \"[variables('dnsLabel')]\"                },                \"volumes\": [                    {                        \"name\": \"acme-cert\",                        \"azureFile\": {                            \"shareName\": \"acme-cert\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"nginx-config\",                        \"secret\": {                            \"mysite.template\": \"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\"                        }                    }                ]            }        }    ],    \"outputs\": {    }}nginx.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"value\": \"secretPwd\"        },        \"containerGroupName\": {            \"value\": \"testacmenginx\"        },        \"storageAccountName\": {            \"value\": \"stotestacmenginx\"        },        \"tagValues\": {            \"value\": {}        },        \"location\": {            \"value\": \"West Europe\"        }    }}Un nouveau, l&#8217;on peut d√©ployer avec la cmdlet PowerShell New-AzResourceGroupDeployment.Et voil√†&nbsp;:ConclusionL&#8217;utilisation d&#8217;acme.sh m&#8217;a permis de r√©cup√©rer un certificat Let&#8217;s Encrypt et l&#8217;utiliser dans NGINX qui agit comme reverse-proxy pour d&#8217;autres applications (grafana dans mon exemple).Je n&#8217;ai pas abord√© la probl√©matique de renouvellement du certificat.Les certificats Let&#8217;s Encrypt n&#8217;ont une dur√©e de vie que de 90 jours.Cela √©tant, Azure Container Instances n&#8217;est probablement pas fait pour des programmes \"permanents\", donc 90 jours est largement suffisant.Il est possible de s&#8217;appuyer sur des fichiers YAML pour le d√©ploiement d&#8217;Azure Container Instances.Cela s&#8217;av√®re tr√®s utile en phase de d√©ploiement mais compl√©tement inutile en phase d&#8217;industrialisation.En effet, il n&#8217;est pas possible d&#8217;utiliser des variables, des param√®tres ou faire r√©f√©rence √† d&#8217;autres ressources comme j&#8217;ai pu le faire dans l&#8217;ARM template.Ainsi, dans l&#8217;ARM template, l&#8217;utilisation de l&#8217;image microsoft/azure-cli se fait avec une r√©f√©rence aux cl√©s du compte de stockage:{    \"name\": \"AZURE_STORAGE_KEY\",    \"value\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"}Ou m√™me, la commande de g√©n√©ration de certificat avec l&#8217;image neilpang/acme.sh qui utilise une variable de mon ARM template:\"command\": [    \"--issue\",    \"--standalone\",    \"-d\",    \"[variables('fqdn')]\"]La r√©f√©rence ARM est relativement bien document√©e.Il ne faut donc pas h√©siter √† l&#8217;utiliser&nbsp;!",
        "url": "//2020/01/30/aci-letsencrypt-nginx/"
      }
      ,
    
      "2020-01-12-acr-repositories-devops": {
        "title": "Utilisation des autorisations d&amp;#8217;√©tendue de r√©f√©rentiel dans ACR avec Azure DevOps",
        "tags": "docker, azure-devops, azure, acr, pipeline, yaml",
        "date": "January 12, 2020",
        "author": "",
        "category": "",
        "content": "Dans un pr√©c√©dent article, j&#8217;expliquais comment cr√©er une autorisation d&#8217;√©tendue de r√©f√©rentiel dans ACR. Nous allons voir comment l&#8217;utiliser dans Azure DevOps.Cr√©ation d&#8217;une jeton d&#8217;acc√®sComme nous l&#8217;avions vu, nous pouvons cr√©er un jeton d&#8217;acc√®s √† partir d&#8217;une scope map existante ou en un cr√©er directement avec la scope map.Suivant la deuxi√®me option, voici la commande&nbsp;:az acr token create -n test-azure-devops -r testscopemap --repository samples/go content/write content/readCr√©ation d&#8217;une connexion de service dans Azure DevOpsDans Azure DevOps, dans votre projet, aller dans les settings en cliquant sur la route dent√©e en bas √† droite .Dans le menu, choisir \"Service Connections\"&nbsp;:.Si vous √™tes comme moi et qu&#8217;il s&#8217;agit de votre premier Service Connection, cliquer sur \"Create service connection\"&nbsp;:.Chercher les connexions de type \"Docker\" et choisir \"Docker Registry\"&nbsp;:.Renseigner les informations&nbsp;:Docker Registry&nbsp;: de la forme https://&lt;nom de l&#8217;ACR&gt;.azurecr.ioDocker ID&nbsp;: le nom du jeton d&#8217;acc√®s pr√©c√©demment cr√©√©Docker Password&nbsp;: Un des 2 mots de passe du  jeton d&#8217;acc√®s pr√©c√©demment cr√©√©Service connection name&nbsp;: A noter pour la suite. J&#8217;ai donn√© le nom du jeton d&#8217;acc√®s mais ce n&#8217;est pas obligatoire.Apr√®s avoir cliquer sur \"Save\", la page des connexions d&#8217;affiche&nbsp;:.Cr√©ation du pipeline dans Azure DevOpsDans le menu de gauche, dans le menu \"Pipelines\"&nbsp;:.Si comme moi, vous cr√©ez le premier pipeline, alors cliquer sur \"Create Pipeline\"&nbsp;:.Mon projet est dans Azure Repos Git, adosser √† mon projet.Si vous √™tes comme dans mon cas, choisir \"Azure Repos Git YAML\"&nbsp;:.Choisir votre repository git&nbsp;:.Choisir un \"starter pipeline\"&nbsp;:.Il est alors possible de renseigner son pipelineazure-pipelines.ymltrigger:- masterpool:  vmImage: 'ubuntu-latest'variables:  imageName: 'samples/go'  dockerRegistryServiceConnection: test-azure-devopssteps:- task: Docker@2  displayName: Login to ACR  inputs:    command: login    containerRegistry: $(dockerRegistryServiceConnection)- task: Docker@2  displayName: Build and push an image to container registry  inputs:    command: buildAndPush    repository: $(imageName)    containerRegistry: $(dockerRegistryServiceConnection)La premi√®re t√¢che va permettre de se connecter vis-√†-vis de l&#8217;ACR en utilisant le jeton d&#8217;acc√®s pr√©c√©demment cr√©√© et les droits associ√©s.La deuxi√®me t√¢che construit l&#8217;image et pousse l&#8217;image dans l&#8217;ACR.Cliquer sur \"Save and Run\".Tout est vert&nbsp;!Apr√®s ex√©cution, on peut voir que la connexion s&#8217;est bien pass√©e ainsi que la construction de l&#8217;image et le transfert vers l&#8217;ACR&nbsp;:.On peut v√©rifier dans l&#8217;ACR le r√©f√©rentiel ainsi cr√©√©&nbsp;:.",
        "url": "//2020/01/12/acr-repositories-devops/"
      }
      ,
    
      "2020-01-10-acr-repositories": {
        "title": "Utilisation des autorisations d&amp;#8217;√©tendue de r√©f√©rentiel dans ACR",
        "tags": "docker, azure, acr",
        "date": "January 10, 2020",
        "author": "",
        "category": "",
        "content": "Jusqu&#8217;√† aujourd&#8217;hui, on pouvait g√©rer les droits Azure Container Registry gr√¢ce aux m√©canismes RBAC standards.Par exemple&nbsp;:AcrPull pour pouvoir r√©cup√©rer (pull) une imageAcrPush pour pouvoir envoyer (push) une imageAvec les autorisations d&#8217;√©tendu de r√©f√©rentiel (pas s√ªr de la traduction&#8230;&#8203;), il est possible de de restreindre les droits √† un ou des r√©f√©rentiels (repositories).Cette fonctionnalit√© n&#8217;est disponible qu&#8217;avec un ACR Premium.Nous allons voir comment&nbsp;:Cr√©er un ACRCr√©er des autorisations d&#8217;√©tendue de r√©f√©rentielUtiliser ces autorisations d&#8217;√©tendue de r√©f√©rentielAu moment de la r√©daction de cet article, cette fonctionnalit√© est r√©cente et toujours en pr√©visualisation.Conceptsr√©f√©rentiels/repositories/espace de noms/namespaceLes r√©f√©rentiels sont des collections d&#8217;images ayant le m√™me nom, mais des √©tiquettes diff√©rentes.Par exemple, les trois images suivantes se trouvent dans le r√©f√©rentiel \"acr-helloworld\"&nbsp;:acr-helloworld:latestacr-helloworld:v1acr-helloworld:v2Les noms des r√©f√©rentiels peuvent √©galement comprendre des espaces de noms.Par exemple, avec l&#8217;espace de nom samples :samples/hello-world:v1samples/nginx:v1Carte d&#8217;√©tendue/mappage d&#8217;√©tendue/scope mapUne scope map (les traductions fran√ßaises sont peu satisfaisantes&#8230;&#8203;) permet de lister des r√©f√©rentiels (repository) et des droits associ√©s.Les droits possibles sont&nbsp;:content/write&nbsp;: droit d&#8217;envoyer une image (push)content/read&nbsp;: droit de r√©cup√©rer une image (pull)metadata/read&nbsp;: droit de lire les m√©tadonn√©es comme les balises (tags)metadata/write&nbsp;: droit de mettre √† jour les m√©tadonn√©es d&#8217;une imagecontent/delete&nbsp;: droit de supprimer une imagePour pouvoir pousser une image, le droit content/read est n√©cessaire en m√™me temps que le droit content/write.Jeton d‚Äôacc√®sOn remerciera ici Microsoft d&#8217;apporter ici un peu de confusion dans un monde informatique qui n&#8217;en manque pas.Bien √©videmment, on dissociera d&#8217;embl√©e ce terme avec les standards OAuth2.0/OpenID Connect.Ici, le terme \"jeton d&#8217;acc√®s\" est la correspondance entre un jeu de cr√©dentiels (1 login de connexion et 2 mots de passe) et une scope map.Cr√©ation d&#8217;un ACRLes commandes seront donn√©es en Azure CLI ex√©cut√©es sous un prompt PowerShell.Commen√ßons par cr√©er le groupe de ressources&nbsp;:az group create -l francecentral -n rg-test-acrCr√©ons maintenant l&#8217;ACR en premiumaz acr create -n testscopemap -g rg-test-acr --sku Premiumle nom de l&#8217;ACR doit √™tre unique globalement, c&#8217;est-√†-dire pour tous les clients de MicrosoftCr√©ation d&#8217;une scope map et du jeton d&#8217;acc√®sPar la suite, je vais construire une image en Go.Je vais donc cr√©er un r√©f√©rentiel pour cette image&nbsp;: samples/go. Il me faudra les droits de lecture et √©criture pour pouvoir pousser l&#8217;image.az acr scope-map create -n GoSampleScopeMap -r testscopemap --repository samples/go content/write content/read --description \"Scope map for go samples\"Le r√©sultat de la commande est comme suit&nbsp;:{  \"actions\": [    \"repositories/samples/go/content/write\",    \"repositories/samples/go/content/read\"  ],  \"creationDate\": \"2020-01-12T15:52:01.191235+00:00\",  \"description\": \"Scope map for go samples\",  \"id\": \"/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/rg-test-acr/providers/Microsoft.ContainerRegistry/registries/testscopemap/scopeMaps/GoSampleScopeMap\",  \"name\": \"GoSampleScopeMap\",  \"provisioningState\": \"Succeeded\",  \"resourceGroup\": \"rg-test-acr\",  \"scopeMapType\": \"UserDefined\",  \"type\": \"Microsoft.ContainerRegistry/registries/scopeMaps\"}Les scope maps peuvent √™tre mis √† jour ult√©rieurement pour ajouter ou supprimer d&#8217;autres r√©f√©rentiels avec la commande az acr scope-map update.Pour cr√©er un jeton d&#8217;acc√®s pour la scope map cr√©√© pr√©c√©demment, ex√©cuter la commande suivante&nbsp;:az acr token create -n TestDocker -r testscopemap --scope-map GoSampleScopeMapLe retour est alors&nbsp;:{  \"creationDate\": \"2020-01-12T15:56:42.673384+00:00\",  \"credentials\": {    \"certificates\": [],    \"passwords\": [      {        \"creationTime\": \"2020-01-12T15:56:54.807783+00:00\",        \"expiry\": null,        \"name\": \"password1\",        \"value\": \"/qY1exMos...GNGYp43iPMe\"      },      {        \"creationTime\": \"2020-01-12T15:56:54.807783+00:00\",        \"expiry\": null,        \"name\": \"password2\",        \"value\": \"bODh6ePvNXK...E25POt+ba\"      }    ],    \"username\": \"TestDocker\"  },  \"id\": \"/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/rg-test-acr/providers/Microsoft.ContainerRegistry/registries/testscopemap/tokens/TestDocker\",  \"name\": \"TestDocker\",  \"objectId\": null,  \"provisioningState\": \"Succeeded\",  \"resourceGroup\": \"rg-test-acr\",  \"scopeMapId\": \"/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/rg-test-acr/providers/Microsoft.ContainerRegistry/registries/testscopemap/scopeMaps/GoSampleScopeMap\",  \"status\": \"enabled\",  \"type\": \"Microsoft.ContainerRegistry/registries/tokens\"}2 mots de passe sont g√©n√©r√©s. Bien les conserver pour la suite.Il est possible de cr√©er la scope map et le jeton d&#8217;acc√®s en une seule commande&nbsp;:az acr token create -n TestDocker2 -r testscopemap --repository samples/go content/write content/readDans ce cas, le nom de la scope map est g√©n√©r√©e automatiquement, de la forme &lt;NomToken&gt;-scope-mapFinalement, il est possible de reg√©n√©rer un mot de passe et lui assigner une dur√©e de validit√© (par d√©faut, la dur√©e du mot de passe est infinie).La commande suivante reg√©n√®re le premier mot de passe pour une dur√©e de validit√© de 30 jours&nbsp;:az acr token credential generate --name TestDocker2 --registry testscopemap --days 30 --password1 --query 'passwords[0].value' --output tsvUtiliser les autorisations d&#8217;√©tendue de r√©f√©rentielLes autorisations d&#8217;√©tendue de r√©f√©rentiel sont utilis√©es au moment de la connexion √† l&#8217;ACR.J&#8217;ai une image locale hello-go:latest √† pousser dans le r√©f√©rentiel d√©fini pr√©c√©demment.La premi√®re √©tape consiste √† donner le bon label √† l&#8217;image.Pour rappel, dans mon exemple testscopemap est le nom de l&#8217;ACR.docker tag hello-go:latest testscopemap.azurecr.io/samples/go:1Pour se connecter, dans un prompt PowerShell&nbsp;:$TOKEN_NAME=\"TestDocker\"$TOKEN_PWD=\"/qY1exMos...GNGYp43iPMe\"$ACR=\"testscopemap\"docker login --username $TOKEN_NAME -p $TOKEN_PWD \"$ACR.azurecr.io\"Il ne reste plus qu&#8217;√† pousser&nbsp;docker push testscopemap.azurecr.io/samples/go:1Et voil√†&nbsp;!",
        "url": "//2020/01/10/acr-repositories/"
      }
      ,
    
      "2020-01-01-sonarqube-app-service": {
        "title": "SonarQube sur App Service",
        "tags": "docker, sonarqube, azure, app-service",
        "date": "January 1, 2020",
        "author": "",
        "category": "",
        "content": "SonarQube sur son poste, c&#8217;est top&nbsp;!Mais il peut √™tre n√©cessaire de le rendre accessible depuis Internet, depuis Azure DevOps ou simplement partager l&#8217;instance entre plusieurs personnes et plusieurs projets.Il existe diff√©rentes strat√©gies pour h√©berger SonarQube sur Azure et le rendre accessible&nbsp;:Utiliser App Service et le tomcat int√©gr√©H√©berger SonarQube sur une machine virtuelleetc.J&#8217;ai choisi ici d&#8217;utiliser Docker pour les raisons d√©j√† √©voqu√©es&nbsp;:Simplicit√©&nbsp;: en utilisant l&#8217;image officielle de Docker, on peut d√©marrer sans passer de temps √† installer le logicielPortabilit√©&nbsp;: je peux utiliser le m√™me genre de configuration sur mon poste ou dans AzureIl n&#8217;existe pas moins de 6 fa√ßons d&#8217;ex√©cuter Docker dans Azure. J&#8217;ai donc retenu d&#8217;utiliser App Service dont les co√ªts pour un App Service Plan Linux ont diminu√©. Ainsi, nous allons pouvoir faire tourner App Service sur une instance B2 √† ~‚Ç¨21.547/mois (offre promotionnelle visiblement).Azure Container Instance nous permettrait de r√©gler plus finement la m√©moire et le CPU allou√©s ainsi que d&#8217;arr√™ter le container au besoin mais App Service int√®gre une connexion HTTPS par d√©faut avec un certificat reconnu, ce qui particuli√®rement int√©ressant pour des raisons de s√©curit√© √©videntes.Table des mati√®resArchitectureVersion simpleDocker ComposeImage DockerConstruction de l&#8217;imagePr√©paration du Docker ComposeCr√©ation de l&#8217;App Service avec Docker ComposeAcc√®s SSHArchitectureL&#8217;architecture se composera simplement de&nbsp;:Un App Service Plan LinuxUn App Service s&#8217;appuyant sur une image DockerPas de base de donn√©es externe.Version simpleDans un premier temps, nous allons proc√©der √† la cr√©ation d&#8217;un container sur la base de l&#8217;image officielle seule.Pour ce faire, ouvrir un prompt PowerShell et ex√©cuter les commandes AZ CLI suivantes&nbsp;:# Variables √† adapter$rg=\"&lt;resource-group-name&gt;\" # Nom du groupe de ressources$ASP=\"&lt;app-service-plan&gt;\" # Nom de l'App Service Plan$appName=\"&lt;app-name&gt;\" # Nom de l'App Service (va d√©terminer l'URL d'acc√®s)# Cr√©ation du groupe de ressources. La localisation est √† adapter. Ici \"France Central\"az group create --location \"France Central\" --name $rg#Cr√©ation de l'App Service Plan.az appservice plan create --name $ASP --resource-group $rg --sku B2 --is-linux# Cr√©ation de L'App Service sur la base de l'image officielleaz webapp create --resource-group $rg --plan $ASP --name $appName --deployment-container-image-name sonarqube:8.1-community-beta# Publication du port 9000az webapp config appsettings set  --resource-group $rg --name $appName --settings WEBSITES_PORT=9000# Configuration du stockage permanentaz webapp config appsettings set --resource-group $rg --name $appName --settings WEBSITES_ENABLE_APP_SERVICE_STORAGE=true# Configuration des logsaz webapp log config --resource-group $rg --name $appName --docker-container-logging filesystem# Petit red√©marrageaz webapp restart --resource-group $rg --name $appName# Acc√®s √† SonarQubestart \"https://$appName.azurewebsites.net\"# R√©cup√©ration des logsaz webapp log tail --resource-group $rg --name $appNameSans l&#8217;acc√®s √† l&#8217;URL, le d√©ploiement de l&#8217;image ne semble pas se faireLe premier d√©marrage, incluant le t√©l√©chargement de l&#8217;image est assez long.Docker ComposeLe support de Docker Compose est encore en preview mais il permet de&nbsp;:Contr√¥ler les variables d&#8217;environnementsD√©clarer des volumesAjouter une base de donn√©es externe telle que postgreMalheureusement, plusieurs probl√®mes se sont pos√©s, n√©cessitant la cr√©ation d&#8217;une image personnalis√©e (mais h√©rit√©e de l&#8217;image officielle).L&#8217;utilisation d&#8217;une image personnalis√©e a pu apporter le support de SSH dans App Service.Les probl√®mes √©taient, par ordre d&#8217;apparition&nbsp;:Erreur \"max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\". C&#8217;est erreur est remont√©e par Elastic Search.Sachant qu&#8217;il n&#8217;est pas possible de modifier cette valeur sur un App Service, plusieurs solutions sont possibles&nbsp;:Modifier les param√®tres d&#8217;Elastic Search (cf. https://jira.sonarsource.com/browse/SONAR-12264)Emp√™cher SonarQube de forcer la v√©rification. Cette v√©rification est forc√©e lorsqu&#8217;une base autre que H2 est utilis√©e.App Service remplace les \".\" des variables d&#8217;environnement par des \"_\", ce qui ne m&#8217;a pas permis de facilement surcharg√© les param√®tres de SonarQubeLe container s&#8217;ex√©cute en tant que l&#8217;utilisateur \"sonarqube\" par d√©faut, ce qui est une bonne chose d&#8217;un point de vue s√©curit√©, mais ce qui ne permet pas de d√©marrer le service SSH simplementLe projet est disponible sur GitHubCommen√ßons donc par la cr√©ation d&#8217;une image Docker.Image DockerL&#8217;image est pr√©par√©e √† partir de l&#8217;image officielle sonarqube:8.1-community-beta.DockerfileFROM sonarqube:8.1-community-beta# sshENV SSH_PASSWD \"root:Docker!\"USER rootRUN apt-get update \\     &amp;&amp; apt-get install -y openssh-server dialog --no-install-recommends \\     &amp;&amp; rm -rf /var/lib/apt/lists/* \\     &amp;&amp; echo \"$SSH_PASSWD\" | chpasswdADD sshd_config /etc/ssh/EXPOSE 9000 2222COPY --chown=sonarqube:sonarqube run.sh \"$SONARQUBE_HOME/bin/\"Il consiste en&nbsp;:Devenir root pour pouvoir installer le serveur OpenSSH et ex√©cuter le container en tant que rootPersonnaliser la configuration d&#8217;OpenSSH √† partir d&#8217;un fichier d&#8217;exempleD√©finir le mot de passe de rootModifier la directive EXPOSE pour exposer le serveur OpenSSH en plus de SonarQubeLa copie du fichier personnalis√© run.shLe fichier run.sh reprend quasiment enti√®rement le fichier de l&#8217;image officielle, √† quelques d√©tails pr√®s.run.shwhile IFS='=' read -r envvar_key envvar_valuedo    if [[ \"$envvar_key\" =~ sonar.* ]] || [[ \"$envvar_key\" =~ ldap.* ]]; then        sq_opts+=(\"-D${envvar_key}=${envvar_value}\")    fi    if [[ \"$envvar_key\" =~ sonar_* ]]; then        # Replacing '_' by '.'        envvar_key=\"$(sed s/_/./g &lt;&lt;&lt;$envvar_key)\"        sq_opts+=(\"-D${envvar_key}=${envvar_value}\")    fidone &lt; &lt;(env)...if [ \"$init_only\" = false ]; then  echo \"Starting SSH ...\"  service ssh start  su sonarqube -c 'java -jar \"lib/sonar-application-$SONAR_VERSION.jar\" -Dsonar.log.console=true \"$@\"' -- \"run.sh\" \"${sq_opts[@]}\" \"$@\"fiLa premi√®re partie se charge de restaurer le \".\" sur les variables d&#8217;environnement.La deuxi√®me partie se charge de&nbsp;:D√©marrer le service SSHEx√©cuter SonarQube en tant qu&#8217;utilisateur sonarqube. En effet, Elastic Search ne d√©marre pas s&#8217;il est ex√©cut√© en tant que root. Peut-√™tre existait-il un flag √† chercher au fin fond d&#8217;une doc mais cela semblait une bonne pratique de ne pas l&#8217;ex√©cuter en tant que root.Construction de l&#8217;imageL&#8217;image va √™tre construite et pouss√©e sur un Azure Container Registry.Pour ce faire, dans un prompt PowerShell&nbsp;:Cr√©ation d&#8217;un Azure Container Registry$acr=\"myregistry\"$rg=\"&lt;resource-group-name&gt;\"az acr create -n $acr -g $rg --sku Basic --admin-enabled trueLoginaz acr login -n $acrR√©cup√©ration des credentialsaz acr credential show -n $acr --password-name passwordConstruction de l&#8217;image et publication$tag=\"8\"$image=\"sonarqubeonazure\"docker build  -t $image:$tag -f \".\\8.Dockerfile\" .docker tag $image:$tag $acr.azurecr.io/$image:$tagdocker push $acr.azurecr.io/$image:$tagPr√©paration du Docker ComposeSonarQube fournit un exemple assez proche de la cibledocker-compose.ymlversion: '3.3'services:  sonarqube:    depends_on:      - db    image: myregistry.azurecr.io/sonarqubeonazure:7    ports:      - \"7000:9000\"    networks:      - sonarnet    environment:      - sonar.forceAuthentication=true      - sonar.telemetry.enable=false      - sonar.es.bootstrap.checks.disable=true      - SONARQUBE_JDBC_URL=jdbc:postgresql://db:5432/sonar      - SONARQUBE_JDBC_USERNAME=sonar      - SONARQUBE_JDBC_PASSWORD=sonar    volumes:      - sonarqube_conf:/opt/sonarqube/conf      - sonarqube_data:/opt/sonarqube/data      - sonarqube_extensions:/opt/sonarqube/extensions  db:    image: postgres    networks:      - sonarnet    environment:      - POSTGRES_USER=sonar      - POSTGRES_PASSWORD=sonar    volumes:      - postgresql:/var/lib/postgresql      # This needs explicit mapping due to https://github.com/docker-library/postgres/blob/4e48e3228a30763913ece952c611e5e9b95c8759/Dockerfile.template#L52      - postgresql_data:/var/lib/postgresql/datanetworks:  sonarnet:    driver: bridgevolumes:  sonarqube_conf:  sonarqube_data:  sonarqube_extensions:  postgresql:  postgresql_data:Les diff√©rences avec l&#8217;exemple concernent&nbsp;:L&#8217;utilisation des variables d&#8217;environnement SONARQUBE_JDBC_USERNAME et SONARQUBE_JDBC_PASSWORDAjout de la directive depends_onEt bien s√ªr, ajout de la variable d&#8217;environnement sonar.es.bootstrap.checks.disable pour d√©sactiver le checkOn peut alors tester le fichier docker compose √† l&#8217;aide de la commande&nbsp;:docker-compose upLes containers peuvent √™tre supprim√©s, ainsi que les volumes avec la commandedocker-compose down -vCr√©ation de l&#8217;App Service avec Docker ComposeLe d√©ploiement d&#8217;un App Service avec Docker Compose est assez proche de la version simple.Ouvrir un prompt PowerShell et ex√©cuter les commandes suivantes&nbsp;:# Variables √† adapter$rg=\"&lt;resource-group-name&gt;\" # Nom du groupe de ressources$ASP=\"&lt;app-service-plan&gt;\" # Nom de l'App Service Plan$appName=\"&lt;app-name&gt;\" # Nom de l'App Service (va d√©terminer l'URL d'acc√®s)$dockerComposePath=\".\\docker-compose.yml\" # Chemin vers le fichier Docker Compose# Cr√©ation du groupe de ressources. La localisation est √† adapter. Ici \"France Central\"az group create --location \"France Central\" --name $rg# Cr√©ation de l'App Service Plan.az appservice plan create --name $ASP --resource-group $rg --sku B2 --is-linux# Cr√©ation de L'App Service √† partir du fichier Docker Composeaz webapp create --resource-group $rg --plan $ASP --name $appName --multicontainer-config-type compose --multicontainer-config-file $dockerComposePath --docker-registry-server-user $acr --docker-registry-server-password \"3...9bHTFzFd\"# Publication du port 7000az webapp config appsettings set  --resource-group $rg --name $appName --settings WEBSITES_PORT=7000# Configuration du stockage permanentaz webapp config appsettings set --resource-group $rg --name $appName --settings WEBSITES_ENABLE_APP_SERVICE_STORAGE=trueaz webapp config appsettings set --resource-group $rg --name $appName --settings DOCKER_REGISTRY_SERVER_URL=https://$acr.azurecr.ioaz webapp config appsettings set --resource-group $rg --name $appName --settings DOCKER_REGISTRY_SERVER_USERNAME=$acraz webapp config appsettings set --resource-group $rg --name $appName --settings DOCKER_REGISTRY_SERVER_PASSWORD=3...9bHTFzFd# Configuration des logsaz webapp log config --resource-group $rg --name $appName --docker-container-logging filesystem# Petit red√©marrageaz webapp restart --resource-group $rg --name $appName# Acc√®s √† SonarQubestart \"https://$appName.azurewebsites.net\"# R√©cup√©ration des logsaz webapp log tail --resource-group $rg --name $appNameLe t√©l√©chargement de l&#8217;image, le d√©marrage de l&#8217;application sont toujours aussi long. Mais √©ventuellement, cela marchera&#8230;&#8203;Acc√®s SSHComme √©voqu√© pr√©c√©demment, si n√©cessaire, il est possible d&#8217;acc√©der √† SonarQube en SSH en allant √† l&#8217;adresse https://$appName.scm.azurewebsites.net/webssh/host",
        "url": "//2020/01/01/sonarqube-app-service/"
      }
      ,
    
      "2019-12-31-sonarqube-dotnet": {
        "title": "Analyse de .NET Core avec SonarQube sur Windows",
        "tags": "docker, sonarqube, windows, dotnet-core",
        "date": "December 31, 2019",
        "author": "",
        "category": "",
        "content": "Un SonarScanner est disponible pour .Net Core. Nous allons voir comment l&#8217;installer puis l&#8217;utiliser.Tout d&#8217;abord, cr√©ons un nouveau projet. Si vous avez suivi lepr√©c√©dent tutoriel, se connecter √† http://localhost:8000.M√™me si l&#8217;on va analyser un code .Net Core, Java est requis&nbsp;!Cr√©ation du projetDans l&#8217;interface, cliquer sur le \"+\" en haut √† droite, puis \"Create new project\"&nbsp;:Renseigner un identifiant du projet et un nom d&#8217;affichage et cliquer sur \"Set Up\"&nbsp;:Il faut alors cr√©er un token si vous n&#8217;en disposez pas d√©j√† d&#8217;un. Si l&#8217;on fait l&#8217;hypoth√®se qu&#8217;il s&#8217;agit du premier projet, nous n&#8217;avons pas de token, donc cr√©ons-en un.Choisir \"Generate a token\", choisir un nom et cliquer \"Generate\".Noter pr√©cieusement la valeur du token et cliquer sur \"Continue\".Installation du SonarScannerSonarQube fournit un scanner .Net Core. L&#8217;installation se fait simplement par la commande suivante&nbsp;:dotnet tool install --global dotnet-sonarscannerConfiguration du SonarScannerPour √©viter de taper syst√©matiquement l&#8217;URL de SonarQube et le token, il est possible de configurer le scanner.La documentation pr√©cise qu&#8217;il faut mettre le fichier SonarQube.Analysis.xml dans le r√©pertoire d&#8217;installation mais on ne sait pas exactement o√π a √©t√© install√© l&#8217;utilitaire avec la commande pr√©c√©dente.La commande where dotnet-sonarscanner retourne alors C:\\Users\\&lt;username&gt;\\.dotnet\\tools\\dotnet-sonarscanner.exe. C&#8217;est presque √ßa.Ouvrir l&#8217;explorateur et aller dans C:\\Users\\&lt;username&gt;\\.dotnet\\tools\\.store\\dotnet-sonarscanner\\4.8.0\\dotnet-sonarscanner\\4.8.0\\tools\\netcoreapp3.0\\any\\. Le chemin est √† adapter en fonction de la version .Net Core √† utiliser.Editer le fichier SonarQube.Analysis.xml pour y mettre l&#8217;URL et le token g√©n√©r√© pr√©c√©demment&nbsp;:&lt;SonarQubeAnalysisProperties xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"    xmlns=\"http://www.sonarsource.com/msbuild/integration/2015/1\"&gt;    &lt;Property Name=\"sonar.host.url\"&gt;http://localhost:8000&lt;/Property&gt;    &lt;Property Name=\"sonar.login\"&gt;[my-user-token]&lt;/Property&gt;&lt;/SonarQubeAnalysisProperties&gt;ScannerUne fois le scanner configur√©, le scan s&#8217;effectue en 3 √©tapes&nbsp;:D√©marrer le scan avec la commande dotnet sonarscanner begin /k:\"project-key\"Construire le projet, tester, etc. avec la commande dotnet buildAnalyser et envoyer √† SonarQube avec la commande dotnet sonarscanner end",
        "url": "//2019/12/31/sonarqube-dotnet/"
      }
      ,
    
      "2019-12-30-sonarqube-docker-windows": {
        "title": "SonarQube sur Windows avec Docker",
        "tags": "docker, sonarqube, windows",
        "date": "December 30, 2019",
        "author": "",
        "category": "",
        "content": "Il existe diff√©rente fa√ßon de faire tourner SonarQube sur Windows.Mon choix s&#8217;est port√© sur Docker pour sa simplicit√© et sa portabilit√©.SonarQube fournit une image officielle, autant en profiter.Cet article fait l&#8217;hypoth√®se que vous avez un environnement Docker fonctionnel.Pr√©requisPour assurer la persistance  de l&#8217;installation, nous allons cr√©er des r√©pertoires sur le disque.Ces r√©pertoires contiendront&nbsp;:La base de donn√©esLa configurationLes pluginsLes logsetc.Pour ce faire, ouvrir un prompt PowerShell et ex√©cuter les commandes suivantes&nbsp;:$SONARQUBE_HOME=\"C:\\temp\\sonarqube\"mkdir $SONARQUBE_HOMEmkdir $SONARQUBE_HOME/confmkdir $SONARQUBE_HOME/extensionsmkdir $SONARQUBE_HOME/logsmkdir $SONARQUBE_HOME/dataR√©cup√©rer SonarQubeR√©cup√©rons maintenant SonarQube.Il existe diff√©rentes versions disponibles sur Docker Hub mais nous allons utiliser l&#8217;image officielle et la version 8.1 community.docker pull sonarqube:8.1-community-betaEx√©cuter SonarQubeUne seule ligne de commande est n√©cessaire pour faire tourner SonarQube. Toujours dans le prompt PowerShell (noter les ` ci-dessous), ex√©cuter&nbsp;:docker run -d --name sonarqube `  -p 8000:9000 ` (1)  -v $SONARQUBE_HOME/conf:/opt/sonarqube/conf ` (2)  -v $SONARQUBE_HOME/extensions:/opt/sonarqube/extensions `  -v $SONARQUBE_HOME/logs:/opt/sonarqube/logs `  -v $SONARQUBE_HOME/data:/opt/sonarqube/data `  -e sonar.forceAuthentication=true ` (3)  -e sonar.telemetry.enable=false `  sonarqube:8.1-community-beta (4)1Sur mon poste, le port 9000 √©tant d√©j√† pris, j&#8217;ai fait correspondre le port 9000 de SonarQube avec mon port 8000. Avec cette commande, SonarQube sera donc accessible √† l&#8217;adresse http://localhost:80002Suis une s√©rie de ligne pour cr√©er des volumes, c&#8217;est-√†-dire faire correspondre un r√©pertoire local avec un r√©pertoire dans le container3Il est possible de configurer SonarQube en passant des param√®tres au d√©marrage4On retrouve ici la version 8.1 CommunityComme le container est pr√©sent sur le poste, il d√©marre rapidement.Apr√®s quelques minutes, en acc√©dant √† http://localhost:8000, vous aurez l&#8217;√©cran de login. Il ne restera plus qu&#8217;√† saisir admin/admin&nbsp;:cette version 8.1 vient avec tous les analyseurs de code standard (C#, JS, etc.). Des profils de base sont cr√©√©s, il est donc possible de passer directement √† la cr√©ation d&#8217;un projet)Arr√™ter SonarQubeLorsque SonarQube n&#8217;est plus n√©cessaire, il est possible de l&#8217;arr√™ter&nbsp;:docker stop sonarqubeEt pour reprendre ult√©rieurement&nbsp;:docker start sonarqubeNettoyageEt si vous voulez nettoyer, 2 commandes pour supprimer le container et l&#8217;image&nbsp;:docker rm sonarqubedocker image rm sonarqube",
        "url": "//2019/12/30/sonarqube-docker-windows/"
      }
      ,
    
      "2019-10-13-tp-docker": {
        "title": "Petit TP Docker",
        "tags": "docker, python",
        "date": "October 13, 2019",
        "author": "",
        "category": "",
        "content": "Introcavote est une application de vote en ligne open source d√©velopp√©e par la f√©d√©ration FDN.L&#8217;installation paraissait simple (pip install -r requirements.txt, etc.) mais je me suis rapidement rendu compte que la petite mention \"test√© avec python 2.7\" allait rapidement me bloquer avec mon python 3.6 et 3.7 si je ne voulais pas r√©√©crire l&#8217;application.C&#8217;est l√† que rentre Docker en jeu avec ses capacit√©s √† supporter des syst√®mes h√©t√©rog√®nes, voire ancien comme dans mon cas. En effet, je ne tenais pas √† installer un 2.7 sur mon Windows 10 dernier cri.M√™me si le fichier Docker ne fait qu&#8217;une dizaine de ligne, c&#8217;est l&#8217;occasion de rappeler quelques pratiques.Le fichier complet est disponible √† la finImageL&#8217;image de d√©part est extr√™mement importante. L&#8217;objectif est d&#8217;avoir une image de d√©part&nbsp;:Qui soit fiable, d&#8217;un point de vue s√©curit√©&nbsp;: pour ce faire pr√©f√©rer les images officiellesQui soit la plus petite possible&nbsp;: pour ce faire, pr√©f√©rer les versions √† base d&#8217;alpine plut√¥t qu&#8217;√† base d&#8217;Ubuntu ou DebianFROM python:2.7-alpineComme on peut le voir ci-dessous, l&#8217;image python:2.7-alpine ne fait que 61,68MB.&gt; docker system df -vImages space usage:REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE                SHARED SIZE         UNIQUE SIZE         CONTAINERS...python                2.7-alpine          df73112425b5        6 weeks ago         61.68MB             61.68MB             0B                  0...Installation des d√©pendancesAfin de pouvoir g√©n√©rer le plus rapidement possible une image, tout en profitant du m√©canisme de couche, il est recommand√© de&nbsp;:Copier en premier le fichier de d√©pendance pip requirements.txt et ex√©cuter la commande pip installCopier les fichiers python de l&#8217;application √† la finAinsi, tant que le fichier de d√©pendance n&#8217;est pas mis √† jour, la construction de l&#8217;image pourra se faire en repartant de l&#8217;ancienne image.Flask dans DockerFlask est un framework Web python r√©pandu.Par d√©faut, Flask √©coute sur l&#8217;interface 127.0.0.1. Le port n&#8217;est donc pas accessible quand publie le port avec Docker.Il faut donc modifier la ligne suivante    app.run()par    app.run(host= '0.0.0.0')Ignorer des fichiersIl est possible d&#8217;ignorer des fichiers&#8201;&#8212;&#8201;√† la mani√®re de git avec .gitignore&#8201;&#8212;&#8201;avec le fichier .dockerignore.J&#8217;ai donc ignor√© le r√©pertoire git et la configuration d&#8217;exemple avec le fichier suivant&nbsp;:Dockerfile de d√©veloppementLe fichier Docker pour la version \"d√©veloppement\" compl√®te est disponible ci-dessous&nbsp;:Construction d&#8217;une imageLors de la construction d&#8217;une image, il est tr√®s fortement recommand√© de la tagu√©&nbsp;:docker build . -t cavote:latestEt c&#8217;est parti!docker run -d --rm -p 5000:5000 cavote:latest-dva automatiquement rendre la main et transformer le docker en d√©mon--rmsupprimera le container √† la fin-pva mapper le port 5000 du container sur le port 5000 de l&#8217;h√¥te (donc en local)La commande suivante va donner la liste des containers en cours d&#8217;ex√©cution&nbsp;:&gt; docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMESb08233412e9b        cavote:latest       \"gunicorn -w 4 --bin‚Ä¶\"   11 minutes ago      Up 11 minutes       0.0.0.0:5000-&gt;5000/tcp   elastic_kellerLa commande suivante va l&#8217;arr√™ter (et le supprimer si l&#8217;option --rm avait √©t√© pr√©cis√© initialement)&nbsp;:docker stop b08233412e9bMise en production avec gunicornLa documentation pr√©cise que, pour une installation en production, on peut utiliser un serveur comme gunicorn.Pour ce faire, j&#8217;ai donc ajout√© gunicorn dans les d√©pendances&nbsp;:La commande √† ex√©cuter dans docker est modifi√©e pour d√©marrer gunicorn&nbsp;:CMD [\"gunicorn\", \"-w\", \"4\", \"--bind\", \"0.0.0.0:5000\",\"main:app\"]Ce qui donne&nbsp;:ConclusionIl s&#8217;agissait d&#8217;une petite application et d&#8217;un fichier Docker pour la tester mais il convient de respecter certaines bonnes pratiques pour acc√©l√©rer la construction des images, leurs tests et leurs d√©ploiements.Ainsi, dans mon exemple, la configuration est charg√©e directement dans l&#8217;image.Il s&#8217;agit √©videmment d&#8217;une mauvaise pratique.Il faudra donc s&#8217;int√©resser aux volumes pour s&#8217;assurer que les fichiers de configuration ne fassent pas partie de l&#8217;image.Egalement, gunicorn est \"expos√©\" directement.L&#8217;application est accessible en HTTP, ce qui est bien suffisant pour un test local.Pour une mise en production, on pourrait s&#8217;appuyer sur un reverse-proxy comme NGINX qui assurerait la terminaison SSL.On pourrait donc imaginer embarquer NGINX et cavote ensemble gr√¢ce √† Docker Compose.",
        "url": "//2019/10/13/TP-docker/"
      }
      ,
    
      "2019-07-04-dotnet-core-datalakestorage": {
        "title": "Charger des fichiers sur un Data Lake Storage Gen 2 en .Net Core",
        "tags": "azure, dotnet-core, rest",
        "date": "July 4, 2019",
        "author": "",
        "category": "",
        "content": "IntroAzure Data Lake Gen2 est maintenant mon composant de stockage Azure favori pour des gros volumes de donn√©es et qui requiert du contr√¥le d&#8217;acc√®s suivant une arborescence, gr√¢ce aux espaces de noms hi√©rarchique.Comme pr√©sent√© dans un pr√©c√©dent article,  Microsoft ne fournit pas de SDK √† ce jour, juste une API REST.Cette API REST est con√ßue pour s&#8217;adapter √† Azure Storage Blob mais aussi √™tre compatible avec un FileSystem Hadoop.On verra que cela peut complexifier certaines choses. Dans tous les cas, cette API se rapproche d&#8217;un de l&#8217;API High-Throughput Block Blob (HTBB) et permet donc un transfert par bloc optimis√©.En l&#8217;absence d&#8217;API .Net Core, j&#8217;ai donc d√©marr√© un petit projet sur GitHub. Ce projet est sans pr√©tention et ne vise pas √† impl√©menter l&#8217;ensemble des services de la REST API. Il n&#8217;impl√©mente pas de transfert optimis√©, de gestion des appels concurrents, etc. En outre, pour des transferts optimis√©s, pour le moment, seul AzCopy peut vous aider.Vous trouverez cependant quelques perles que j&#8217;ai r√©cup√©r√©es en chemin&#8230;&#8203;Charger un fichierLe chargement de fichier va en r√©alit√© n√©cessiter 3 op√©rations&nbsp;:Cr√©er&#8201;&#8212;&#8201;ou plut√¥t d√©clarer&#8201;&#8212;&#8201;le fichierTransf√©rer les octets par blocFinaliser le transfert&#8201;&#8212;&#8201;autrement dit, fermer le fichier.Au-del√† du c√¥t√© non naturel de ces 3 appels, il est √† noter que chaque appel REST va compter comme une op√©ration. Cela peut avoir des cons√©quences au niveau de la facturation Azure si vous avez beaucoup de petits fichiers.La d√©claration du fichier se fait avec la m√©thode Create pour une resource file.Par d√©faut, l&#8217;√©crasement de fichier est autoris√©. Si vous voulez emp√™cher l&#8217;√©crasement d&#8217;un fichier, il faut ajouter If-None-Match avec la valeur \"*\".En .Net Core, il est possible de fixer cet ent√™te sur l&#8217;objet HttpRequestMessage comme suit&nbsp;:req.Headers.IfNoneMatch.Add(EntityTagHeaderValue.Any)Le transfert se fait gr√¢ce √† la m√©thode Update avec le param√®tre action=append.Le transfert se faisant par bloc, il faut donner l&#8217;emplacement de ce bloc. Le premier commence √† 0. Cette position est √† mettre dans le param√®tre d&#8217;URL position.Finalement, le fichier doit √™tre ferm√©. On fait donc appel √† la m√©thode Update avec le param√®tre action=flush. Cette fois-ci, le param√®tre position prend comme valeur la taille du fichier complet.Projet .Net CoreLa documentation Microsoft est bien faite mais √† toutes fins utiles, je rappelle ici quelques commandes.Cr√©er un projet console dans le r√©pertoire Ma.Super.Appli avec un namespace par d√©faut Ma.Super.Appli&nbsp;:dotnet new console -n Ma.Super.AppliCr√©er un projet NUnit dans le r√©pertoire Ma.Super.Appli.Tests&nbsp;:dotnet new nunit -n Ma.Super.Appli.TestsFaire une r√©f√©rence √† un autre projet:dotnet add reference ../Ma.Super.Appli/Ma.Super.Appli.csprojCr√©er un fichier de solution&nbsp;:dotnet new sln -n monsuperprojet.slnAjouter les projets pr√©c√©demment cr√©√©s au fichier solution&nbsp;:dotnet sln monsuperprojet.sln.sln add Ma.Super.Appli\\Ma.Super.Appli.csprojou si vous √™tes d√©j√† dans le bon r√©pertoire&nbsp;:dotnet sln add Ma.Super.Appli\\Ma.Super.Appli.csprojQuelques r√©f√©rences:Unit testing C# with NUnit and .NET Core.gitignoreSignaturePour le moment, je n&#8217;ai exp√©riment√© que l&#8217;authentification par Shared Key. D&#8217;apr√®s la page du driver ABFS, l&#8217;API devrait supporter √©galement l&#8217;authentification Azure AD.L&#8217;authentification par Shared Key est expliqu√©e sur la doc Microsoft.Je me suis appuy√© sur les appels d&#8217;Azure Storage Explorer et d&#8217;AzCopy (cf. l&#8217;article Comment capturer les appels REST vers Azure Data Lake gen2 avec Storage Explorer) pour √©tablir un jeu de test.Cela a permis de g√©rer quelque \"bizarrerie\" comme la gestion de l&#8217;ent√™te Content-Length qui doit √™tre omis dans la signature s&#8217;il est √† 0.",
        "url": "//2019/07/04/dotnet-core-datalakestorage/"
      }
      ,
    
      "2019-07-02-comment-capturer-appels-rest-adls-gen2-storage-calls-avec-azure-using-azure-storage-explorer": {
        "title": "Comment capturer les appels REST vers Azure Data Lake gen2 avec Storage Explorer",
        "tags": "azure, fiddler, rest",
        "date": "July 2, 2019",
        "author": "",
        "category": "",
        "content": "IntroAzure Data Lake gen2, qui n&#8217;est autre qu&#8217;un Storage Account avec un espace de noms hi√©rarchique, est disponible depuis quelque temps.Pour autant, Microsoft ne fournit pas de SDK, juste une API REST. Et cette documentation peut s&#8217;av√©rer sibylline&#8230;&#8203;Mes recherches m&#8217;ont men√© sur cette page mais malheureusement, elle n&#8217;est plus √† jour avec les derni√®res versions.Nous allons voir comment capturer des appels avec Microsoft Azure Storage Explorer version 1.8.1.Ceci permettra d&#8217;apporter un nouvel √©clairage sur la doc&nbsp;: l&#8217;impl√©mentation n&#8217;est-elle pas la doc&nbsp;?Le mode d√©veloppeur du Microsoft Azure Storage ExplorerLe plus simple est d&#8217;ouvrir le mode d√©veloppeur en appuyant sur F12 ou aller dans le menu Help &gt; Toggle Developer Tools&nbsp;:En allant dans l&#8217;onglet \"Network\", on peut ainsi voir les URL, les ent√™tes des requ√™tes et des r√©ponses.Malheureusement, comme l&#8217;indique Microsoft Azure Storage Explorer, pour tout ce qui concerne le t√©l√©chargement, Microsoft Azure Storage Explorer s&#8217;appuie sur AzCopy&nbsp;:Commandes AzCopyEn r√©alisant un transfert, Microsoft Azure Storage Explorer nous propose de copier la commande AzCopy associ√©e&nbsp;:Ceci nous donne des commandes PowerShell, comme&nbsp;:$env:AZCOPY_CRED_TYPE = \"SharedKey\";$env:ACCOUNT_NAME = \"XXX\";$env:ACCOUNT_KEY = \"xbDE/...0isig==\";./azcopy.exe copy \"c:\\path\\to\\test.png\" \"https://XXX.dfs.core.windows.net/root/test.png\" --overwrite=false  --follow-symlinks --recursive --from-to=LocalBlobFS --put-md5;$env:AZCOPY_CRED_TYPE = \"\";$env:ACCOUNT_NAME = \"\";$env:ACCOUNT_KEY = \"\";Microsoft Azure Storage Explorer vient avec des binaires d&#8217;AzCopy, pr√©sent par d√©faut dans C:\\Program Files (x86)\\Microsoft Azure Storage Explorer\\resources\\app\\node_modules\\se-az-copy-exe-win\\dist\\bin.Pour tracer les requ√™tes, nous allons nous appuyer sur Fiddler.FiddlerFiddler est un excellent proxy Web gratuit propos√© par Telerik. Vous pouvez le t√©l√©charger et l&#8217;installer simplement.Le point important est de configurer Fiddler pour d√©chiffrer les flux HTTPS. Pour ce faire, apr√®s avoir d√©marr√© Fiddler, aller dans le menu Tools &gt; Options&#8230;&#8203;.Aller dans l&#8217;onglet HTTPS et cocher la case Decrypt HTTPS traffic. Des fen√™tres vont inviter √† faire confiance √† un certificat&nbsp;: r√©pondre \"oui\".De retour sur la fen√™tre Options, cliquer sur OK.Capturer le trafic d&#8217;AzCopyUne fois Fiddler d√©marr√© et configur√©, d√©marrez un prompt PowerShell et taper les commandes ci-dessous. Il faut penser √† renseigner le nom du compte et la cl√© primaire. La ligne de commande a √©t√© adapt√©e pour prendre en compte le nom complet du binaire AzCopy et autoriser un √©crasement (--overwrite=true).cd \"C:\\Program Files (x86)\\Microsoft Azure Storage Explorer\\resources\\app\\node_modules\\se-az-copy-exe-win\\dist\\bin\"$env:HTTPS_PROXY=\"http://localhost:8888\"$env:AZCOPY_CRED_TYPE = \"SharedKey\";$env:ACCOUNT_NAME = \"XXX\";$env:ACCOUNT_KEY = \"xbDE/...sig==\";./azcopy_windows_amd64.exe copy \"C:\\path\\to\\test1.png\" \"https://pocdlgen2.dfs.core.windows.net/root/test1.png\" --overwrite=true --follow-symlinks --recursive --from-to=LocalBlobFS --put-md5;$env:AZCOPY_CRED_TYPE = \"\";$env:ACCOUNT_NAME = \"\";$env:ACCOUNT_KEY = \"\";Si tout se passe bien, dans Fiddler, en allant dans Inspector, vous verrez le d√©tail des requ√™tes et des r√©ponses&nbsp;:Il est possible de r√©cup√©rer la cl√© primaire directement dans Microsoft Azure Storage Explorer √† partir du panneau Actions en bas √† gauche simplement en cliquant sur \"Copy Primary Key\"&nbsp;:Si on vous ne voyez que des \"tunnel to\", c&#8217;est que Fiddler n&#8217;est pas correctement configur√© pour d√©chiffrer le flux HTTPS&nbsp;:",
        "url": "//2019/07/02/comment-capturer-appels-rest-adls-gen2-storage-calls-avec-azure-using-azure-storage-explorer/"
      }
      ,
    
      "2018-11-27-trucs-powershell": {
        "title": "Quelques trucs et astuces PowerShell",
        "tags": "powershell, trucs",
        "date": "November 27, 2018",
        "author": "",
        "category": "",
        "content": "IntroPowerShell est aujourd&#8217;hui un langage largement utilis√© et mature : la version 5.1 est embarqu√©e dans Windows Server 2016 et Windows 10 tandis que PowerShell Core 6.0 est disponible depuis janvier 2018 en GA.Il existe une litt√©rature dithyrambique sur le sujet. J&#8217;ai cependant voulu √©crire cet article pour partager mes (bonnes ?) pratiques.Table des mati√®resIntroUtiliser des param√®tresAfficher les infos d&#8217;un objet complexe$ErrorActionPreferenceValidation de param√®treParameterSetNameArgument splattingWrite-Output vs. Write-Host vs. Write-Verbose etc.Switch caseStrict#RequiresCmdletBindingCommentairesConvention de nommageUtiliser des param√®tresOn d√©marre sur les chapeaux de roue avec celle-l√† !Il est tr√®s facile d&#8217;utiliser des param√®tres. Pas de raison de s&#8217;en priver !Donc pas de cha√Æne de caract√®re en dur (genre le nom d&#8217;un Storage Account) : on le passe en param√®tre avec une valeur par d√©faut et √ßa pourra toujours resservir.Afficher les infos d&#8217;un objet complexeIl est possible de mettre une variable dans une string pour en obtenir la valeur$name = Read-Host \"Quel est ton nom ?\"Write-Host \"Hello $name\"Ainsi, apr√®s avoir r√©pondu √† la question (disons \"World\"), on obtiendra bien le fameux \"Hello World\".Mais quid d&#8217;objet plus complexe ? Admettons que je veuille afficher les infos d&#8217;un process.$a = Get-Process | select -First 1Write-Host \"Le nom du process est $a.ProcessName\"Le r√©sultat peut para√Ætre surprenant :Le nom du process est System.Diagnostics.Process (ApplicationFrameHost).ProcessNamePour obtenir la valeur de la propri√©t√© ProcessName, il faut \"√©chapper\" avec $()Write-Host \"Le nom du process est $($a.ProcessName)\"Et voil√†!Le nom du process est ApplicationFrameHost AppVShNotif$ErrorActionPreference$ErrorActionPreference fait partie des ces variables qui permettent de modifier le comportement de PowerShell. $ErrorActionPreference d√©termine le comportement en cas d&#8217;erreur.Par d√©faut, la valeur est continue, c&#8217;est-√†-dire que PowerShell affiche l&#8217;erreur et continue.Personnellement, je ne comprends pas ce comportement par d√©faut. Quand une cmdlet plante, je n&#8217;ai pas envie que mon script continue&#8230;&#8203; C&#8217;est pourquoi, dans tous mes scripts j&#8217;ajoute la ligne suivante :$ErrorActionPreference = \"stop\"Validation de param√®treLa validation de param√®tre est un m√©canisme simple qui permet de gagner du temps en √©vitant :L&#8217;√©criture de code pour testerL&#8217;affichage de message d&#8217;erreurAinsi, au lieu de :param(    $ComputerName)if (-not $ComputerName) {    Write-Error \"ComputerName is mandatory\"    Exit 1}(...)Il est possible d√©clarer :param(    [Parameter(Mandatory)]    $ComputerName)(...)Le r√©sultat est diff√©rent :D&#8217;un point de vue \"Exp√©rience Utilisateur\", la valeur est demand√©e interactivement : c&#8217;est pas plus mal.D&#8217;un point de vue code, les contr√¥les sont d√©claratifs. Rien √† faire de particulier et en plus Visual Studio Code g√®re parfaitement la compl√©tion.Ceci n&#8217;est qu&#8217;un exemple et d&#8217;autres contr√¥les peuvent √™tre utiliser :[ValidateLength(1,15)]S&#8217;assure que la cha√Æne a entre 1 et 15 caract√®res[ValidatePattern(\"[a-z]{6}\\d{4}\")]Permet de valider une cha√Æne de caract√®re par rapport √† une expression r√©guli√®re[ValidateCount(1,3)]Permet de garantir la taille du tableau[ValidateRange(1,12)]Permet de donner un intervalle pour des entiers[ValidateSet[(\"Start\",\"Stop\")]Permet de d√©finir un ensemble de valeurs possibles. L&#8217;avantage est que PowerShell peut faire de la compl√©tion ![ValidateScript({Test-Path -Path $_ -PathType Leaf})]Il est possible de coder son propre test. Int√©ressant pour tester l&#8217;existence d&#8217;un fichier ou au contraire, s&#8217;assurer que le fichier n&#8217;existe pasParameterSetNameUne classique des bonnes pratiques : le ParameterSetName !Pour rentre les cmdlets plus flexibles, il est int√©ressant de d√©finir des jeux de param√®tres. Ainsi la cmdlet pourrait accueillir le nom d&#8217;une souscription ou l&#8217;identifiant d&#8217;une souscription. Inutile de faire 2 cmdlets pour autant, il suffit d&#8217;utiliser un ParameterSetName.Exemple :param(    [Parameter(ParameterSetName=\"subname\", Mandatory)]    [string]    $subname,    [Parameter(ParameterSetName=\"subid\", Mandatory)]    [string]    $subid,    [Parameter(Mandatory)]    $inputFile)if ($PsCmdlet.ParameterSetName -eq \"subname\") {    Write-Host \"Nom de la souscription : $subname\"} else {    Write-Host \"Identifiant de la souscription : $subid\"}Write-Host $inputFileArgument splattingArgument splatting (D√©sol√©, je n&#8217;ai pas de traduction pour ce terme) est une fonctionnalit√© souvent m√©connue de PowerShell.Basiquement, il est possible de \"construire\" les arguments √† passer √† une cmdlet. Ainsi, on construit une hashtable avec les param√®tres √† passer ou non.C&#8217;est tr√®s int√©ressant avec les `ParameterSetName`s car on peut appeler la m√™me cmdlet mais avec des arguments diff√©rents en fonction du ParameterSetName.Ci-dessous un exemple. Mon script prend un param√®tre optionnel SubscriptionName. Si une valeur est renseign√©e, je r√©cup√®re LA souscription souhait√©e, sinon j&#8217;appelle ma cmdlet Get-AzureRmSubscription sans param√®tre et r√©cup√®re ainsi toutes les souscriptions.param(    [string]$SubscriptionName,    (...))(...)$subSplat=@{}if (-not [string]::IsNullOrEmpty($SubscriptionName)) {    $subSplat.Add(\"SubscriptionName\", $SubscriptionName)}$subs = Get-AzureRmSubscription @subSplat(...)Write-Output vs. Write-Host vs. Write-Verbose etc.Pour faire simple :Write-Host √† utiliser et √† abuser pour affiche des infos sur l&#8217;√©tat d&#8217;avancement du scriptWrite-Output √† proscrire pour afficher des infos. L&#8217;objectif de Write-Output est d&#8217;ajouter un objet dans le pipeline. Utiliser Write-Output peut avoir des effets ind√©sirables. Il a l&#8217;avantage de signifier que l&#8217;on veut mettre un objet dans le pipeline. Un peu comme un return : √ßa sert √† rien mais c&#8217;est plus lisibleWrite-Verbose √† utiliser et √† abuser! Pour afficher des infos de debug/plus verbeuses (cf. CmdletBinding)Prenons l&#8217;exemple suivant :param()function Get-Output {    [CmdletBinding()]    param (    )    Write-Host \"Hello1\"    \"Hello2\"    Write-Output \"Hello3\"    return \"Hello4\"}$a = Get-OutputWrite-Host \"Contenu de `$a :\"$aA votre avis, qu&#8217;est-ce qui sera affich√© dans la console ? Avant et apr√®s \"Contenu de `$a :\" ? \"Hello4\"?R√©sultatHello1Contenu de $a :Hello2Hello3Hello4\"Hello2\", \"Hello3\" et \"Hello4\" ont √©t√© ajout√© au pipeline et assign√© √† $a.Seul Hello1 est afficher \"correctement dans la fonction.Switch caseLa directive switch a une syntaxe toute particuli√®re en PowerShell. Ce qui est tout autant particulier (et m√©connu) est l&#8217;existence de flag √† cette directive comme -regexp ou -wildcard.Il existe un article exhaustif sur le sujet :https://kevinmarquette.github.io/2018-01-12-Powershell-switch-statement/StrictUne bonne pratique est d&#8217;utiliser un mode stricte en ajoutant la ligne suivante :Set-StrictMode -Version latestCeci va garantir que :Les meilleures pratiques sont respect√©esUne variable qui n&#8217;existe pas ne sera pas utilis√©eSouvent dans des cas de refactoring du code, de mauvais copi√©/coll√©, des noms de variable qui n&#8217;auraient jamais d√ª √™tre l√† sont utilis√©s malencontreusement. Avec le mode stricte, PowerShell va g√©n√©rer une erreur et sortir.Le principal inconv√©nient est pour le test de pr√©sence de certaines propri√©t√©s dans un objet.J&#8217;ai donc une petite fonction en stock qui permet d&#8217;√©viter une erreur en mode strictefunction Test-HasProperty($object, $propertyName) {    &lt;#    .SYNOPSIS        Utility function to check if an object has a property. Useful in strict mode    #&gt;    $propertyName -in $object.PSobject.Properties.Name}#RequiresJe ne vois quasiment jamais la directive #Requires utilis√©e, pourtant elle est tr√®s int√©ressante pour documenter:La version PowerShellLes modules n√©cessaires, notamment pour des d√©pendances particuli√®resLa n√©cessit√© d&#8217;ex√©cuter le script en tant qu&#8217;administrateur (UAC a parfois des comportements et des messages bizarres. Si des droits administrateurs sont requis, autant le pr√©ciser#Requires -Version 6.0#Requires -Modules ActiveDirectory#Requires -RunAsAdministratorCmdletBindingCmdletBinding est un attribut de cmdlet tr√®s puissant.Personnellement, je l&#8217;utilise syst√©matiquement pour pouvoir interpr√©ter automatiquement le flag -verbose. Ainsi, dans l&#8217;exemple ci-dessous, ex4.ps1 a l&#8217;attribut CmdletBinding et non ex5.ps1.CommentairesLes commentaires sont extr√™mement importants dans le code. PowerShell n&#8217;√©chappe pas √† cette r√®gle !Rappelons qu&#8217;il est possible de faire des commentaires de bloque gr√¢ce √† &lt;# &#8230;&#8203; #&gt;.Sinon, inutile de r√©inventer la roue pour documenter ses cmdlets ou ses fonctions, PowerShell dispose d√©j√† de ses propres m√©canismes (cf. About Comment Based Help)L&#8217;avantage est que le Get-Help du script fonctionnera et pourra ainsi les infos n√©cessaires, des exemples, etc.J&#8217;utilise principalement les mots-cl√©s suivants :.SYNOPSISBr√®ve description de la fonction ou du script.DESCRIPTIONDescription plus d√©taill√©e si n√©cessaire.PARAMETER &lt;Parameter-Name&gt;Permet de documenter un param√®tre.EXAMPLEPermet de donner un exemple d&#8217;usage avec la sortieA noter que pour une fonction, il est possible de mettre le bloc de commentaire avant la fonction, au d√©but de la fonction (ou apr√®s).Convention de nommageIl faut favoriser la convention VERB-NOUN en utilisant les verbes pr√©conis√©s.",
        "url": "//2018/11/27/trucs-powershell/"
      }
      ,
    
      "2018-09-04-az-cli-ml": {
        "title": "G√©rer les certificats d&amp;#8217;Azure CLI",
        "tags": "azure, windows, az-cli",
        "date": "September 4, 2018",
        "author": "",
        "category": "",
        "content": "IntroductionL&#8217;outil de ligne de commande Azure CLI permet aussi de g√©rer Machine Learning Server.Cela permet notamment de :Configurer les n≈ìuds Web et computeChiffrer les mots de passeRed√©marrer les n≈ìudsEx√©cuter des tests de diagnosticEtc.Or, dans mon cas, le Machine Learning Server utilise un certificat √©mis par une autorit√© de certification interne.Cela g√©n√©rait l&#8217;erreur suivante :&gt;az login --mls --mls-endpoint https://monendpoint/The behavior of this command has been altered by the following extension: azure-ml-admin-cliUsername: XXX@XXX.comPassword:2018-09-04 09:05:19,307 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': //login2018-09-04 09:05:19,323 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': //login2018-09-04 09:05:19,354 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': //loginAssert that [--mls-endpoint https://monendpoint/] is correct.HTTPSConnectionPool(host='monendpoint', port=443): Max retries exceeded with url: //login (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))A noter la syntaxe de la commande az login pour ML Server, qui est un peu diff√©rente de la doc.R√©solutionAzure CLI s&#8217;appuie sur python. Malgr√© mes tentatives pour ajouter les variables classiques (CA_BUNDLE, CURL_CA_BUNDLE, REQUESTS_CA_BUNDLE, SSL_CERT_FILE) mais rien n&#8217;y fait : la v√©rification de certificat √©choue lamentablement.Un peu de recherche pointe vers le projet Requests.Il s&#8217;appuie sur le projet sur Certifi.Pour s&#8217;en convaincre, il suffit de lancer python et les quelques lignes suivantes :cd C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2&gt;python.exeC:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2&gt;python.exePython 3.6.1 (v3.6.1:69c0db5, Mar 21 2017, 17:54:52) [MSC v.1900 32 bit (Intel)] on win32Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import requests.adapters&gt;&gt;&gt; print(requests.adapters.DEFAULT_CA_BUNDLE_PATH)C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\lib\\site-packages\\certifi\\cacert.pemIl ne reste plus qu&#8217;√† √©diter C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\lib\\site-packages\\certifi\\cacert.pem.A noter qu&#8217;il faut ajouter ses autorit√©s de certification au fichier et ne pas remplacer le contenu.",
        "url": "//2018/09/04/az-cli-ml/"
      }
      ,
    
      "2018-07-11-maj-powershell-azurerm": {
        "title": "Astuce du jour : mettre √† jour tous ses modules AzureRm",
        "tags": "azure, truc, powershell",
        "date": "July 11, 2018",
        "author": "",
        "category": "",
        "content": "La ligne de commandeLa commande magique pour mettre √† jour tous les modules AzureRM :Get-Module -ListAvailable | ?{$_.Name -like \"AzureRM.*\"} | group Name | Update-ModuleUpdate-Module AzureRM√áa peut prendre tr√®s longtempsNote pour plus tard: comment nettoyer les vieilles versions ?Pour √©viter les demandes de confirmationPar d√©faut, PowerShell Gallery n&#8217;est pas consid√©r√© comme une source s√ªre.Ainsi, √† chaque installation ou mise √† jour, la commande Install-Module ou Update-Module demande une confirmation.Il est possible de lister les sources avec la commande Get-PSRepository :PS &gt; Get-PSRepositoryName                      InstallationPolicy   SourceLocation----                      ------------------   --------------PSGallery                 Untrusted            https://www.powershellgallery.com/api/v2/En pratique, on accepte tout module en provenance de PSGallery.Autant lui faire confiance et se poser des vraies questions quand la gestion des modules demande confirmation.Pour ce faire, apr√®s v√©rification de l&#8217;URL de PSGallery, ex√©cuter la commande ci-dessous :Set-PSRepository -Name PSGallery -InstallationPolicy Trusted",
        "url": "//2018/07/11/maj-powershell-azurerm/"
      }
      ,
    
      "2018-07-10-debug-packer-windows": {
        "title": "D√©buguer la cr√©ation d&amp;#8217;image Packer pour Windows sur Azure",
        "tags": "packer, azure, windows",
        "date": "July 10, 2018",
        "author": "",
        "category": "",
        "content": "IntroductionPacker est un outil tr√®s adapt√© √† la cr√©ation d&#8217;images personnalis√©es sur Azure.Packer va √™tre responsable de cr√©er bon nombre de ressources :Un Key VaultUn VNETUne interface r√©seau et son IP publiqueUne VMTout √ßa c&#8217;est tr√®s bien mais c&#8217;est relativement long √† d√©ployer et en phase de d√©veloppement, cela revient √† beaucoup de temps de perdu&#8230;&#8203;Voici donc quelques trucs.Tester le scriptJ&#8217;ai perdu un peu de temps √† mes d√©buts avec √ßa.√áa parait b√™te mais aujourd&#8217;hui j&#8217;ai toujours une machine virtuelle d√©marr√©e pour copier et tester le script en live.C&#8217;est tr√®s TRES efficace.Je n&#8217;utilise jamais de \"inline\" pour les provisioners Windows Shell ou PowerShell.Cela me permet de tester plus facilement le script, de le r√©utiliser ou m√™me d&#8217;encha√Æner les scripts de m√™me nature avec l&#8217;utilisation du param√®tre \"scripts\"Du debug dans le scriptL√† aussi √ßa parait √©vident, mais il est possible d&#8217;afficher des commentaires qui seront retourn√©s par Packer.Rien d&#8217;exceptionnel ici : un Write-Host dans un script PowerShell fera l&#8217;affaire et pourra remonter des informations en cours d&#8217;ex√©cution ou savoir √† quel moment exactement le script √©choue.La construction d&#8217;image √©choueSi la construction de l&#8217;image √©choue, par d√©faut, packer supprime les ressources cr√©√©es.Si vous souhaitez acc√©der √† la machine pour r√©cup√©rer des logs ou simplement ex√©cuter manuellement le script √† des fins de debug, il est possible d&#8217;utiliser le param√®tre -on-error=abort ou -on-error=ask.abort sortira d√®s l&#8217;√©chec tandis que ask demandera la proc√©dure √† suivre.En condition r√©elleSi malgr√© tout √ßa, le script √©choue sans raison apparente, il va falloir remonter les manches !Packer s&#8217;appuie sur WinRM pour passer les scripts et les ex√©cuter.Packer configure d√©j√† WinRM sur la machine, ce qui n&#8217;est pas une mince affaire !Nous allons voir comment ex√©cuter des commandes WinRM avec une image construite par Packer.Le pied de bichePour se connecter √† la machine, il va certainement falloir √† r√©initialiser le mot de passe administrateur dans le portail Azure, car packer d√©finit un mot de passe al√©atoire par d√©faut.Ceci permet de r√©initialiser le mot de passe du compte packer (compte cr√©√© par d√©faut).Une fois le login/mot de passe connu, il est possible de se connecter en RDP √† la machine, le portail Azure donnant le FQDN du serveur au format &lt;nom VM al√©atoire&gt;.&lt;localisation&gt;.cloudapp.azure.com (ex: pkrvmq69gzbq1tn.westeurope.cloudapp.azure.com). Penser √† noter l&#8217;IP par la m√™me occasion.CertificatL&#8217;utilisation de SSL est obligatoire dans la configuration r√©alis√©e par Packer pour WinRM.Le certificat est cependant :Auto-sign√©Pour un FQDN diff√©rent de celui de donn√© par AzureDans un premier temps, il nous faut extraire le certificat utilis√© par WinRM.2 possibilit√©s :Se connecter √† la machine virtuelle, ouvrir le magasin de certificat de la machine, exporter le certificat et copier le certificat sur sa machineUtiliser opensslCommme la premi√®re m√©thode est plus longue √† d√©tailler, je vais d√©tailler la deuxi√®me. Ex√©cuter la commande openssl suivante en remplacement avec votre FQDN&gt; c:\\apps\\OpenSSL\\bin\\openssl.exe s_client -connect pkrvmq69gzbq1tn.westeurope.cloudapp.azure.com:5986 -showcertsCONNECTED(0000021C)depth=0 CN = pkrvmq69gzbq1tn.cloudapp.netverify error:num=20:unable to get local issuer certificateverify return:1depth=0 CN = pkrvmq69gzbq1tn.cloudapp.netverify error:num=21:unable to verify the first certificateverify return:1---Certificate chain 0 s:/CN=pkrvmq69gzbq1tn.cloudapp.net (1)   i:/CN=pkrvmq69gzbq1tn.cloudapp.net-----BEGIN CERTIFICATE---(2)MIIDDjCCAfagAwIBAgIRAOAE4qOtV3FeMAKd0/F4U4EwDQYJKoZIhvcNAQELBQAwJzElMCMGA1UEAxMccGtydm1xNjlnemJxMXRuLmNsb3VkYXBwLm5ldDAeFw0xODA3MTAyMTE2NTdaFw0xODA3MTEyMTE2NTdaMCcxJTAjBgNVBAMTHHBrcnZtcTY5Z3picTF0bi5jbG91ZGFwcC5uZXQwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCxnTGBTMq0jxbdVNRC1kPRTVyPquIvEbZGDZ64L+NB34vrHa3FlFkGVVzv0uG35z/lgrbgjNdr5pj6LUJ1QS23TLVAeZgrMe1VCly36d7FIu/X+U4vFE2UKKIA/Cftmyp7vPkzN8v7hye4kM2mQhNw9/k7DSkx+scLhrk1+7qZXl1DebcgpTzOdjM1WtACpu3ZI0F7/qtLaoIRdaBBMVNfsZGasqu+QqpXKG+WVHLkC2VDDwwBC8U6haN6XKFHEIcoTyLfDvcDHDBrFwtGVsrBB9I5kHXNDyGgiJZCx7EGpk0uobF+5lQJo7c/z6lWWurqu83U1XrESpp0zsPhDAh1AgMBAAGjNTAzMA4GA1UdDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMBAf8EAjAAMA0GCSqGSIb3DQEBCwUAA4IBAQCky/mY+BlCA3RTSPy8Bxa8yewdhEL8ENS9UEX7fgrCDTVeiqxSgvYjQqhzVu7vZ9nYXttpXhLyi6l56iV3DEs5uBktnOdQZnds3zwfI/e53gqQC82lCGMDskE9kAagppFuNO27K9bXs0szIYUY8yJJdc2QR3xF7l3aLXfF6J42aD9Kw3Q9Iss28BUSu/TmRy59MZMs5XfSgw9SZGRave2S2c4yPZBUQ67CDL3Ng7Axnl2EBSpT5uQTvXbgxHV115pJ+kIoYqz0iL3rmprlzOLEohlIUn46gVqr+LNHlO1FuvfMx0e2io7lsLvJ933KG0QWqNVHvz2hEhi6u3KIqL64-----END CERTIFICATE--------Server certificatesubject=/CN=pkrvmq69gzbq1tn.cloudapp.netissuer=/CN=pkrvmq69gzbq1tn.cloudapp.net---No client certificate CA names sentPeer signing digest: SHA1Server Temp Key: ECDH, P-256, 256 bits---SSL handshake has read 1270 bytes and written 433 bytes---New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES256-GCM-SHA384Server public key is 2048 bitSecure Renegotiation IS supportedCompression: NONEExpansion: NONENo ALPN negotiatedSSL-Session:    Protocol  : TLSv1.2    Cipher    : ECDHE-RSA-AES256-GCM-SHA384    Session-ID: D820000035CA3984027AC8D13B4C4BDF4D73C0C63091B3DE510EAF06E2FABDA5    Session-ID-ctx:    Master-Key: 85504F679F0ABA212F87E25A0C3C68B5843B5990EE23523BD56702FBBC736F10C35F26253D795D1804A473620EECA2BE    Key-Arg   : None    PSK identity: None    PSK identity hint: None    SRP username: None    Start Time: 1531286527    Timeout   : 300 (sec)    Verify return code: 21 (unable to verify the first certificate)---read:errno=100931Notez le FQDN inclus dans le certificat auto-sign√©2Copier dans le contenu entre les balises \"-----BEGIN CERTIFICATE-----\" et \"-----END CERTIFICATE-----\" en incluant ces m√™mes balises dans un fichier avec une extension .cer par exemple : vous avez votre certificat !Il ne vous reste plus qu&#8217;√† installer le certificat. Sous Windows, en cliquant-droit sur le fichier, vous avez dans le menu \"Installer le certificat\".En suivant le wizard, il est n√©cessaire de choisir manuellement le magasin de certificat \"Autorit√©s de certification racine de confiance\"hostsVous l&#8217;aurez remarqu√© : le FQDN contenu dans le certificat auto-sign√© est diff√©rent de celui utilis√© pour se connecter. Et malgr√© le fait que vous fassiez confiance √† ce certificat, l&#8217;√©tablissement de la connexion SSL √©chouera car le nom inclut dans le certificat est diff√©rent de celui utilis√© pour la r√©solution DNS.Il est reste donc une derni√®re √©tape pour feinter Windows.Sur votre machine, √©diter le fichier C:\\Windows\\System32\\drivers\\etc\\hosts et y ajouter l&#8217;entr√©e :&lt;Adresse IP publique&gt; &lt;nom VM al√©atoire&gt;.cloudapp.netEx:40.91.194.154 pkrvmq69gzbq1tn.cloudapp.netTout est bon ?&gt; $cred = Get-Credential&gt; Test-WSMan pkrvmq69gzbq1tn.westeurope.cloudapp.azure.com -Credential $cred -UseSSL -Authentication Defaultwsmid           : http://schemas.dmtf.org/wbem/wsman/identity/1/wsmanidentity.xsdProtocolVersion : http://schemas.dmtf.org/wbem/wsman/1/wsman.xsdProductVendor   : Microsoft CorporationProductVersion  : OS: 10.0.14393 SP: 0.0 Stack: 3.0C&#8217;est partiInvoke-Command -ComputerName pkrvmq69gzbq1tn.cloudapp.net -ScriptBlock { ipconfig } -credential $cred -UseSSLIl ne reste plus qu&#8217;√† remplacer ipconfig par la commande de votre choix.ConclusionLe dernier recours √† base de commande WinRM est probablement exag√©r√©.Je ne l&#8217;ai utilis√© qu&#8217;une fois, mais il m&#8217;a permis d&#8217;en savoir plus sur WinRM.Certainement une bonne base pour d&#8217;autres outils s&#8217;appuyant sur WinRM comme ansible&#8230;&#8203;Bonus : vider mon groupe de ressourceDans le cas o√π packer ne nettoierait pas tout, il est possible de vider le groupe de ressource avec la commande suivante :Get-AzureRmResource -ResourceGroupName &lt;mon groupe de resource&gt; | Remove-AzureRmResource -ForceC&#8217;est l&#8217;√©quivalent d&#8217;un rm -f sur Linux donc attention √† passer le bon groupe de ressource !",
        "url": "//2018/07/10/debug-packer-windows/"
      }
      ,
    
      "2018-05-23-vscode-extensions": {
        "title": "Mes extensions Visual Studio Code",
        "tags": "vscode",
        "date": "May 23, 2018",
        "author": "",
        "category": "",
        "content": "J&#8217;utilise Visual Studio Code depuis un moment.Cette page recense les extensions que j&#8217;utilise pour √©viter les \"c&#8217;est quoi d√©j√† l&#8217;extension que j&#8217;utilise pour faire ce truc ?\". Je compl√©terai au fur et √† mesure.Mise √† jour 2018-09-05: Ajout extension pour AsciiDocMise √† jour 2018-11-27: Ajout de quelques extensions (Bracket Pair Colorizer, ARM Params Generator, .NET Core Test Explorer, C# Extensions) et promotion de C# &amp; AsciiDocAzureAzure Resource Manager ToolsAzure Resource Manager Snippets: Des snippets int√©ressants. Mes pr√©f√©r√©es : arm-parameter et arm-paramvalue.expand-region: excellente extension qui me permet de s√©lectionner des r√©gions: tr√®s pratiques pour s√©lectionner rapidement une ressource dans un ARM templatePowerShellPas trop de d√©bat :Powershell: l&#8217;extension s&#8217;est clairement bonifi√©e et je n&#8217;ai presque plus recours √† PowerShell ISEWebBeautifyC#C#AsciiDocAsciiDocXMLXML Tools: juste pour le \"Format\"En cours de testC#.NET Core Test ExplorerC# ExtensionsAzureBracket Pair Colorizer: Int√©ressant quand on a des JSON √† rallongeARM Params Generator: tr√®s sympatique extension qui g√©n√®re des fichiers de param√®tres √† partir de template ARM",
        "url": "//2018/05/23/vscode-extensions/"
      }
      ,
    
      "2018-05-22-azure-rbac": {
        "title": "Gestion des r√¥les dans Azure",
        "tags": "azure, rbac, role",
        "date": "May 22, 2018",
        "author": "",
        "category": "",
        "content": "Je m&#8217;√©tais pos√© la question. On m&#8217;a pos√© la question. Voici donc quelques commandes que j&#8217;ai glan√©es sur la gestion des r√¥les dans Azure.Rappelons qu&#8217;il est possible d&#8217;affecter un r√¥le sur 3 niveaux :La souscription (donc l&#8217;ensemble des ressources de la souscription)Un groupe de ressourcesDirectement sur une ressourceIl existe par d√©faut de nombreux r√¥les (cf. Built-in roles for Azure role-based access control).Certains r√¥les sont sp√©cialis√©s sur un type de ressource mais tr√®s souvent les ressources n&#8217;utilisent que les r√¥les de base : owner/propri√©taire, contributor/conntributeur et reader/lecteur.En plus de la page de r√©f√©rence de Microsoft, voici quelques √©l√©ments pour construire vos r√¥les.Liste des r√¥lesGet-AzureRmRoleDefinition | Format-Table Name, Description(Get-AzureRmRoleDefinition \"Virtual Machine Contributor\").Actions(Get-AzureRmRoleDefinition \"Virtual Machine Contributor\").NotActionsComment obtenir la liste des actions possiblesUn fournisseur correspond plus ou moins √† un type de sous-ressource.Pour obtenir une liste de fournisseurs:Get-AzureRmResourceProvider -ListAvailable | Select-Object ProviderNamespace, RegistrationStatePour r√©pertorier les op√©rations possibles d&#8217;un fournisseur :Get-AzureRmProviderOperation Microsoft.Compute/virtualMachines/* |  select -ExpandProperty operationOn notera l&#8217;utilisation du caract√®re '*' dans la commande pr√©c√©dente pour lister les op√©rationsCr√©er un r√¥le personnalis√© bas√© sur un JSONNew-AzureRmRoleDefinition -InputFile C:\\MycustomRole.jsonExporter un r√¥le au format JSONGet-AzureRmRoleDefinition &lt;nom du r√¥le&gt; | ConvertTo-JsonIl sera alors possible stocker/versionner un r√¥le dans un gestionnaire de source.Mettre √† jour un r√¥le personnalis√©Mettez √† jour la d√©finition du r√¥le avec :$ role = Get-AzureRmRoleDefinition -Name \"ROLE_DEFINITION_NAME\"$ role.AssignableScopes.Add (\"/ abonnements / NEW_SUBSCRIPTION_ID_GOES_HERE\") ## [[R√©p√©tez cette √©tape pour ajouter tous les abonnements que vous souhaitez ajouter]]$ role.Actions.Remove (\"Microsoft.Compute / virtualMachines / write\") # Ajouter une autorisation √† un r√¥le$ role.Actions.Add (\"Microsoft.Compute / virtualMachines / write\") # Supprimer l'autorisation d'un r√¥leSet-AzureRmRoleDefinition -Role $ roleTrouver o√π un r√¥le est utilis√©Get-AzureRmRoleAssignment -RoleDefinitionName \"ROLE_DEFINITION_NAME\"Affecter un r√¥le √† un groupe sur un groupe de ressources$AADGroup = Get-AzureRmADGroup -SearchString \"GROUP_NAME\"New-AzureRmRoleAssignment -ObjectID $AADGroup.ID `    -RoleDefinitionName \"ROLE_DEFINITION_NAME\" `    -ResourceGroupName \"RG_NAME\"Supprimer un r√¥le personnalis√©Un r√¥le ne peut √™tre supprim√© s&#8217;il est affect√©Pour supprimer un r√¥le personnalis√© existant, ex√©cutez la commande suivante :Remove-AzureRmRoleDefinition -Id ROLE_DEFINITION_ID```powershellOu```powershellRemove-AzureRmRoleDefinition -Name \"ROLE_DEFINITION_Name\"",
        "url": "//2018/05/22/azure-rbac/"
      }
      ,
    
      "2018-04-30-github-pages-jekyll-travisci": {
        "title": "Faire un blog avec Jekyll, GitHub Pages et TravisCI",
        "tags": "github, jekyll, travisci, blog",
        "date": "April 30, 2018",
        "author": "",
        "category": "",
        "content": "Pourquoi d√©j√† ?Jekyll est un moteur puissant de g√©n√©rateur de site statique d√©velopp√© en Ruby. Il offre de nombreux plugins, th√®mes ainsi que le support d&#8217;AsciiDoc au travers d&#8217;un plugin particulier.GitHub Pages est un bon moyen d&#8217;h√©berger son site statique. GitHub Pages supporte m√™me Jekyll mais sans le plugin AsciiDoc.Bien s√ªr, il aurait √©t√© possible de g√©n√©rer son site statique sur son poste et de le pousser sur GitHub pour publication, mais cela aurait d√ª √™tre fait √† chaque fois.J&#8217;ai donc pr√©f√©r√© automatiser compl√®tement la g√©n√©ration du site gr√¢ce √† TravisCI.Je ne suis ni un expert Jekyll ni Ruby.Cet article regroupe donc quelques points sur la configuration de la cha√Æne compl√®te.Base du siteComme pr√©conis√© par le  plugin, je suis parti d&#8217;un fork du d√©marrage rapide.Ceci a permis de :Installer les pr√©requisActiver TravisCIJeton d&#8217;acc√®sPour g√©n√©rer le jeton, ne pas √† se r√©f√©rer √† la doc du site, mais plut√¥t √† celle de TravisCI.Branche GitHubDans le cas d&#8217;un site perso, par opposition √† un site projet, il est obligatoire de publier dans la branche master.J&#8217;ai donc cr√©√© et mis le code du site dans une branche dev. Pour ma part, j&#8217;ai utilis√© :git checkout -b devConfiguration de TravisCITravisCI permet d&#8217;automatiser tout pipeline de livraison.Il propose m√™me un d√©ploiement pour GitHub Pages, ce qui √©vite la cr√©ation de scripts sp√©cifiques devant g√©rer les git clone, push, etc.Le premier √©l√©ment concerne le fichier .travis.yml.Celui-ci se compose de la sorte :language: rubyrvm: 2.2install: bundle installscript: bundle exec jekyll builddeploy:  provider: pages  skip_cleanup: true  github_token: $GITHUB_TOKEN # Set in travis-ci.org dashboard (1)  local-dir: _site (2)  target-branch: master (3)  on:    branch: dev1Il existe plusieurs fa√ßons de s√©curiser son jeton GitHub.Ici, j&#8217;utilise les variables d&#8217;environnement. J&#8217;ai donc cr√©er une variable GITHUB_TOKEN avec mon jeton (cf. doc). Par d√©faut, la valeur de la variable n&#8217;est pas affich√©e (\"Display value in build log\" √† \"Off\")2Jekyll g√©n√®re les pages dans le r√©pertoire _site3Il faut pousser les modifications dans la branche masterNe pas construireLorsque je poussais mes modifications sur la branche dev, cela r√©sultait en des modifications pouss√©es sur la branche master : le site en lui-m√™me.TravisCI essayait de construire le site sur master ce qui donnait inexorablement une erreur.En cochant la case \"Build only if .travis.yml is present\", cela a emp√™ch√© la construction de la branche master.ConclusionApr√®s tous ces efforts, quelle fiert√© d&#8217;avoir son petit build au vert :",
        "url": "//2018/04/30/github-pages-jekyll-travisci/"
      }
      ,
    
      "2017-12-23-udacity-with-azure-part2": {
        "title": "Suivre le tutorial d&amp;#8217;Udacity sur Kubernetes avec Azure (2e partie)",
        "tags": "kubernetes, azure, aks, docker, microservices",
        "date": "December 23, 2017",
        "author": "",
        "category": "",
        "content": "IntroductionNous prenons ici la suite du cours gratuit d&#8217;Udacity sur Docker, les microservices et Kubernetes.Vous pouvez trouver la premi√®re partie iciLesson 3: KubernetesStep 4: Setting up Kubernetes for this courseSi l&#8217;on reprend l√† o√π on en √©tait rest√©, vous devriez avoir:Une souscription AzureUn Azure Cloud Shell ouvert sous BashUn resource group rg-udacity-test. Pour rappel, pour en cr√©er un :az group create --name rg-udacity-test --location westeuropeA ce stade, vous pouvez instancier un Kubernetes sur AKS gr√¢ce √† la commande:az aks create --resource-group rg-udacity-test --name myK8sCluster --node-count 1 --generate-ssh-keysaz aks get-credentials --resource-group rg-udacity-test --name myK8sClusterEtant sur Azure Cloud Shell, il n&#8217;est pas n√©cessaire d&#8217;installer kubectl.Il est d√©j√† pr√©sent.Tester la commande:kubectl get nodesEn ex√©cutant la commande ci-dessous, on peut s&#8217;apercevoir que le cluster est en 1.7.7 et que la derni√®re version disponible est la 1.8.2:az aks get-versions --resource-group rg-udacity-test --name myK8sCluster -o tableTaper la commande suivante pour automatiquement mettre √† jour le cluster vers la 1.8.2:az aks upgrade --resource-group rg-udacity-test --name myK8sCluster -k 1.8.2Step 5: Kubernetes Intro DemoPas de sp√©cificit√© sur les commandes. Nginx se d√©ploie correctement.Step 7: Creating PodsEditer le fichier pods/monolith.yaml et modifier la ligneimage: udacity/example-monolith:1.0.0parimage: &lt;acrLoginServer&gt;/example-monolith:1.0.0o√π: &lt;acrLoginServer&gt; est le \"Login Server (cf. partie 1).vim est pr√©sent sur Azure Cloud ShellLe reste des commande est inchang√©.Step 8: Interacting With PodsPas de sp√©cificit√©. Bien penser qu&#8217;il est possible d&#8217;ouvrir plusieurs Azure Cloud Shell.Step 12: Creating SecretsPas de sp√©cificit√©.Step 13: Accessing A Secure HTTPS EndpointEditer le fichier pods/secure-monolith.yaml et modifier la ligneimage: udacity/example-monolith:1.0.0parimage: &lt;acrLoginServer&gt;/example-monolith:1.0.0Lesson 4: Deploying Microservices",
        "url": "//2017/12/23/udacity-with-azure-part2/"
      }
      ,
    
      "2017-12-15-udacity-with-azure": {
        "title": "Suivre le tutorial d&amp;#8217;Udacity sur Kubernetes avec Azure (1√®re partie)",
        "tags": "kubernetes, azure, aks, docker, microservices",
        "date": "December 15, 2017",
        "author": "",
        "category": "",
        "content": "IntroductionUdacity propose un cours gratuit sur Docker, les microservices et Kubernetes (en anglais). Tout est tr√®s bien d√©crit, y compris les commandes mais cela se base (naturellement) sur Google Container Engine (GKE).Disposant d√©j√† d&#8217;une souscription Azure et Azure proposant √©galement une offre manag√©e sur Kubernetes : Azure Container Service (AKS).Azure disposant √©galement d&#8217;un Registry priv√© (Azure Container Registry), ce sera l&#8217;occasion de l&#8217;utiliser!Le tutorial fait √©galement largement usage de Google Cloud Shell. Azure dispose √©galement d&#8217;un shell: Azure Cloud Shell. Il est m√™me propos√© \"en plein √©cran\" depuis peu et propose un raccourci vers bash ou PowerShell. Il dispose de nombreuses fonctionnalit√©s et language par d√©faut.L&#8217;Azure Cloud Shell permet une persistance a un espace de stockage en √©tant li√© √† un Storage Account. Ce sera donc parfait pour cr√©er une image, la publier et autre.La suite de cet article pr√©sente par le√ßon, √©tape par √©tape les adaptationsLesson 1: Introduction to MicroservicesEtape 5: Get the Source CodeJe fais l&#8217;hypoth√®se que vous avez une souscription Azure et que vous avez d√©marr√© un Bash dans Azure Cloud Shell.Sous Windows, utilisez Ctrl+Insert pour copier and Shift+Insert pour coller.Go √©tant d√©j√† install√©, rien √† faire ici:$ go versiongo version go1.7 linux/amd64Donc, hormis l&#8217;installation de Go, vous pouvez proc√©der comme indiqu√© et extraire directement le code source:$ echo \"export GOPATH=~/go\" &gt;&gt; ~/.bashrc$ source ~/.bashrc$ mkdir -p $GOPATH/src/github.com/udacity$ git clone https://github.com/udacity/ud615$ cd ud615/app/Etape 6: Build And Interact With MonolithLa compilation se passe comme un charge mais pour tester l&#8217;application, cela devient l√©g√®rement plus rus√©.Pour ex√©cuter le programme monolith, j&#8217;utilise le port 10081 au lieu de 81 car la commande sudo n&#8217;est pas disponible.Pour ouvrir une \"deuxi√®me console\", ouvrez un nouvel onglet dans votre navigateur sur le Cloud Shell../bin/monolith -http :10080 -health :10081Les tests √† base de curl s&#8217;ex√©cute corretement.Pour tuer le programme, il suffira de le ramener en avant-plan (commande fg puis Ctrl+C).Etape 9: Refactor To MSAPas de difficult√©s ici. Les commandes passent (compilations et tests).Lesson 2: Building the Containers with DockerEtape 3: Installing Apps With Native OS ToolsLes festivit√©s commencent&#8230;&#8203;Le \"d√©marrage rapide\" donne en r√©alit√© toutes les indications. Dans les grosses mailles:Choisir sa souscription (az account list puis az account set --subscription my-subscription-name)Cr√©er un resource group (unit√© de base dans Azure)Cr√©er la VM (configuration de base)Se connecter √† la VMCe qui donne:az group create --name rg-udacity-test --location westeuropeaz vm create -n ubuntu -g rg-udacity-test --image UbuntuLTS --generate-ssh-keysssh username@ipaddressNe pas oublier d&#8217;√©teindre la VM pour √©viter d&#8217;exploser le forfait!Pour connaitre l&#8217;adresse IP de la VM: az vm list-ip-addresses -g rg-udacity-test -n ubuntu --output tableUne fois connect√©, les autres commandes ne changent pas:sudo apt-get updatesudo apt-get install nginxnginx -v...Etape 7 : Intalling Images With DockerPas de sp√©cificit√©.Etape 8 : Running Images With DockerPas de sp√©cificit√©.Etape 9 : Talking To Docker InstancesPas de sp√©cificit√©.Etape 11 : Create An ImagePas de sp√©cificit√©.Etape 12 : Create docker images for the remaining microservices - auth and helloPas de sp√©cificit√©.Etape 14 : Push ImagesNous allons ici utilis√© l&#8217;Azure Container Registry.az group create --name rg-common-docker --location westeuropeaz acr create --resource-group rg-common-docker --name &lt;acrName&gt; --sku BasicLa commande va retourner une structure. Bien noter la ligne:\"loginServer\": \"&lt;acrLoginServer&gt;\"Sur la VM Ubuntu, installer Azure CLI 2.0 en suivant la proc√©dure:echo \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ wheezy main\" | \\     sudo tee /etc/apt/sources.list.d/azure-cli.listsudo apt-key adv --keyserver packages.microsoft.com --recv-keys 52E16F86FEE04B979B07E28DB02C46DF417A0893sudo apt-get install apt-transport-httpssudo apt-get update &amp;&amp; sudo apt-get install azure-cliPuis se logguer sur Azure puis l&#8217;ACR avant de publier l&#8217;imagesudo az loginsudo az acr login --name &lt;acrName&gt;La commande de publication ('push') doit √™tre adapt√©:docker tag monolith:1.0.0 &lt;acrLoginServer&gt;/example-monolith:1.0.0docker push &lt;acrLoginServer&gt;/example-monolith:1.0.0On peut ensuite v√©rifier le travail:$ sudo az acr repository list --name &lt;acrName&gt; --output tableResult----------------example-authexample-helloexample-monolithA ce stade, il est possible d&#8217;arr√™ter la VM: az vm deallocate -g rg-udacity-test -n ubuntuUn peu de nettoyageComme d&#8217;habitude, ne pas oublier de nettoyer. Le plus simple: supprimer le resource group.az group delete --name rg-udacity-test",
        "url": "//2017/12/15/udacity-with-azure/"
      }
      ,
    
      "2017-10-27-hello-world": {
        "title": "Hello World!",
        "tags": "",
        "date": "October 27, 2017",
        "author": "",
        "category": "",
        "content": "Finally!After giving a lot of thought, here I am!I hope to contribute a little to this computer science world and that you will find usefull information.See you soon",
        "url": "//2017/10/27/hello-world/"
      }
      
    
  };
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/0.7.1/lunr.min.js"></script>
<script src="/assets/js/search.js"></script>
</section>
</article>

    </div>
    


<footer class="site-footer">
	<nav class="site-nav">
		<ul>
			
<li>
	<a href="/feed.xml" title="Suivre sur RSS">
		<i class="fa fa-fw fa-rss"></i>
	</a>
</li>















<li>
	<a href="https://github.com/r3dlin3" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>




























		</ul>
	</nav>
	<p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <i class="fa fa-heart" aria-hidden="true" style="color:Tomato"></i>
</p>
</footer>

  </body>
</html>
