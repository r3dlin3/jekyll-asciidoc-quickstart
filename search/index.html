<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>Search | A bit of everything</title>
	<meta name="description" content="A bit of everything">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- CSS -->
	<link rel="stylesheet" href="/assets/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="/search/">

	<!-- RSS -->
	<link type="application/atom+xml" rel="alternate" href="https://r3dlin3.github.io/feed.xml" title="A bit of everything" />
	<!-- SEO -->
	<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Search | A bit of everything</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Search" />
<meta name="author" content="r3dLiN3" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A bit of everything" />
<meta property="og:description" content="A bit of everything" />
<link rel="canonical" href="https://r3dlin3.github.io/search/" />
<meta property="og:url" content="https://r3dlin3.github.io/search/" />
<meta property="og:site_name" content="A bit of everything" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"r3dLiN3"},"headline":"Search","description":"A bit of everything","@type":"WebPage","url":"https://r3dlin3.github.io/search/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


	<!-- Font Awesome -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	

	<!-- Google Analytics -->
	
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/">
			<img class="avatar" src="/assets/img/avatar.png" alt="avatar"/>
		</a>
		
		<h1 class="site-title">
			<a href="/">A bit of everything</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
			
			
			
			
			<li>
				<a class="page-link" href="/about/">
					A propos
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			<li>
				<a class="page-link" href="/tags/">
					tags
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled  -->
			
			
            
            <!-- Search bar -->
            
		</ul>
	</nav>
    
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/')">
    <h1 class="title">Search</h1>
    
  </header>
  <section class="post-content"><div class="search">
    <div id="search-results"></div>
    <p id="not-found" style="display: none">
        Aucun résultat trouvé.
    </p>
</div>


<script>
  window.store = {
    
      "2021-03-11-postman-dynamic-content": {
        "title": "Requêtes dynamiques avec Postman",
        "tags": "rest",
        "date": "March 11, 2021",
        "author": "",
        "category": "",
        "content": "IntroductionPostman est un excellent outil pour tester des API REST.L&#8217;utilisation des environnements permet déjà d&#8217;apporter une certaine dynamicité en regroupant certaines variables propres un environnement justement&nbsp;: URL, login et mot de passe, etc.En utilisant les variables entre double accolade (ex&nbsp;: {{base_url}}), il est alors possible de réutiliser ces variables dans l&#8217;URL, dans le contenu de la requête ou autre.Postman permet de faire des prétraitements en JavaScript.C&#8217;est ce que nous allons exploiter.Les scripts de prérequêtesIl est possible d&#8217;ajouter du JavaScript à 2 moments&nbsp;:Avant d&#8217;envoyer la requête&nbsp;: le contenu du script est dans l&#8217;onglet \"Pre-request Script\"Après avoir reçu la réponse&nbsp;: le contenu du script est dans l&#8217;onglet \"Tests\"Il est à noter qu&#8217;on peut positionner des scripts à plusieurs niveaux&nbsp;:Au niveau de la collectionAu niveau du répertoireAu niveau de la requêteUn premier scriptL&#8217;exemple ci-dessous permet de créer 2 variables&nbsp;: startTime et endTime.var now = new Date().getTime();console.log(now);(1)var startTime = new Date(now + 60*1000);var endTime = new Date(now + 5*60*1000);console.log(startTime);pm.environment.set('startTime', startTime.toISOString()); (2)pm.environment.set('endTime', endTime.toISOString());1Il est possible de logguer, ce qui est très appréciable.2Les variables sont rendues disponibles grâce à cette commande.La console développeur avec les logs est disponible dans le menu View&#160; Show Postman ConsoleUtilisation des variablesL&#8217;exemple montre l&#8217;utilisation des variables dans le corps du message.{    \"startTime\": \"{{startTime}}\",    \"endTime\": \"{{endTime}}\"}ConclusionIl n&#8217;est pas rare que l&#8217;on veuille tester avec des valeurs aléatoires ou dépendantes du temps.L&#8217;utilisation de script permet de rendre plus dynamique les requêtes.",
        "url": "//2021/03/11/postman-dynamic-content/"
      }
      ,
    
      "2021-01-05-logic-app-azure-media-services": {
        "title": "Logic App, API Azure et Media Services",
        "tags": "azure, logic-app",
        "date": "January 5, 2021",
        "author": "",
        "category": "",
        "content": "IntroductionLogic App dispose d&#8217;ores-et-déjà de nombreux connecteurs pour piloter des ressources Azure&nbsp;:L&#8217;arrêt/relance d&#8217;instance App ServiceLa gestion des clés ou des secrets dans Azure Key VaultSi le connecteur n&#8217;existe pas, l&#8217;utilisation du connecteur REST et des identités managés permettent de rapidement arriver à ses fins.Ainsi, dans mon cas, je voulais pouvoir arrêter un Streaming Endpoint sur un Azure Media Services.En effet, un Streaming Endpoint est facturé mais peut être arrêté. Et dans mon environnement de bac à sable, je n&#8217;en ai pas besoin en permanence.Création de la Logic AppLa création d&#8217;une Logic App se fait assez simplement dans le portail.Identité managéeUne fois créée, il faut activer l&#8217;identité managée, qui est désactivée par défaut.Pour ce faire, il faut simplement aller dans la blade Identity&nbsp;:Le bouton \"Attributions de rôle Azure\" permet d&#8217;attribuer des droits sur le Media Services.Malheureusement, par ce biais, il n&#8217;est possible, pour le moment, que d&#8217;attribuer des droits au niveau d&#8217;une souscription ou d&#8217;un groupe de ressources ou des ressources comme SQL, compte de stockage ou Key Vault, mais pas sur un media services.Il n&#8217;existe pas de rôle spécifique à Media Services.Nous allons devoir recourir au rôle \"Contributeur\" si l&#8217;on ne veut pas avoir de rôle personnalisé, ce qui est mon cas, car je veux garder les choses simples.Pour autant, pour éviter d&#8217;attribuer trop de droits, je préconise d&#8217;attribuer le rôle \"Contributeur\" directement sur l&#8217;instance Media Services.API REST et connecteur Logic AppAzure Media Services dispose d&#8217;une API REST et donc d&#8217;une méthode spécifique pour arrêter un Streaming Endpoint.Il s&#8217;agit d&#8217;une simple requête POST sur L&#8217;URL https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Media/mediaservices/{accountName}/streamingEndpoints/{streamingEndpointName}/stop?api-version=2020-05-01Une fois les valeurs remplacées dans l&#8217;URL ci-dessus, on peut utiliser simplement un connecteur HTTP en activant l&#8217;authentification par identité managée&nbsp;:Le déploiement automatisé par ARM templateJ&#8217;ai préparé un ARM template qui va&nbsp;:Déployer la Logic App et configurer l&#8217;URLAttribuer le droit \"Contributeur\" sur Media ServicesJe fais l&#8217;hypothèse que la Logic App est déployée dans le même groupe de ressources que l&#8217;Azure Media Services.Comme d&#8217;habitude, il existe plusieurs façon de le déployer, comme par exemple&nbsp;:En 1 clic&nbsp;:En PowerShellNew-AzResourceGroupDeployment -ResourceGroupName \"mon-rg\" -TemplateParameterFile .\\parameters.json -TemplateFile .\\template.json -VerboseConclusionEn quelques clics, il est possible d&#8217;automatiser des tâches dans Azure avec Logic App, même si le connecteur n&#8217;est pas disponible.L&#8217;économie peut être substantielle alors que le coût de mise en œuvre est ridicule.",
        "url": "//2021/01/05/logic-app-azure-media-services/"
      }
      ,
    
      "2020-12-21-php-app-service": {
        "title": "PHP sur Azure App Service : Windows ou Linux ?",
        "tags": "azure, php, app-service",
        "date": "December 21, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionPHP est supporté sur App Service. Bien avant l&#8217;avènement des App Services sous Linux, il était possible de faire tourner un Wordpress sur un App Service Windows.App Service sur Linux permet de faire tourner son application parmi les piles d&#8217;application supportées ou faire tourner son propre container.Pour mes tests, j&#8217;ai utilisé phpOIDC comme base de référence et Locust comme injecteur.Le scénario de test comprend&nbsp;:L&#8217;interrogation de l&#8217;URL de métadonnéesL&#8217;interrogation de l&#8217;URL de webfingerL&#8217;authentification et la récupération d&#8217;un tokenLa récupération des informations de l&#8217;utilisateur (userinfo)La validation du jetonWindowsLes graphiques suivants présentent les résultats pour un App Service plan B1 sous Windows.Le nombre de requêtes est relativement erratique&#8201;&#8212;&#8201;entre 2 et 6 requêtes/s&#8201;&#8212;&#8201;avec une moyenne d&#8217;environ 3 requêtes/s.LinuxPlan B1Les graphiques suivants présentent les résultats pour un App Service plan B1 sous Linux.Le nombre de requêtes est relativement plus stable que pour Windows avec une moyenne d&#8217;environ 3 requêtes/s.Plan B3.Au moment de la rédaction de cet article, les plans Linux sont beaucoup moins cher que Windows.Ainsi en décembre 2020 pour France Central&nbsp;:OSTailleCoresMémoirePrixWindowsB111,75 GB~€57.868/moisLinuxB111,75 GB~€11.081/moisLinuxB347 GB~€43.093/moisOn voit ainsi que l&#8217;on peut avoir beaucoup plus de ressources avec un plan Linux B3 qu&#8217;un plan Windows B1.Comparons ce qui est comparable et voyons les résultats pour un plan Linux B3&nbsp;:Cette fois-ci, avec un peu de stress, on arrive à 12 requêtes par secondes.OPcache à la rescousseOPcache améliore les performances de PHP en stockant le bytecode desscripts précompilés en mémoire partagée, faisant ainsi qu&#8217;il n&#8217;estplus nécessaire à PHP de charger et d&#8217;analyser les scripts à chaquedemande.Il est inclus par défaut depuis PHP 5.5.Les graphiques suivants présentent les résultats pour un App Service plan B1 sous Linux avec OPcache activé dans l&#8217;image Docker&nbsp;:Le nombre de requêtes est relativement erratique&#8201;&#8212;&#8201;entre 6 et 10 requêtes/s&#8201;&#8212;&#8201;avec une moyenne d&#8217;environ 8 requêtes/s.ConclusionLes tests de performance de phpOIDC n&#8217;ont pas du tout été impressionnant (sic.).Je n&#8217;ai pas joué avec le cache local sur App Service sur Windows.C&#8217;est une option intéressante en termes de performance.Cela étant, on a pu voir qu&#8217;à prix équivalent, il est préférable d&#8217;utiliser un plan Linux.L&#8217;utilisation d&#8217;OPcache permet également de grandement améliorer les performances. Seule une image personnalisée permet d&#8217;avoir OPcache activé, donc un plan Linux.Il n&#8217;existe pas de réponse absolue quand on parle de tests de performance&nbsp;: Cela dépend fortement de l&#8217;application, des accès en lecture/écriture, etc.On peut voir que l&#8217;utilisation de plan sur Linux permet d&#8217;être plus efficace et devrait être favorisé.",
        "url": "//2020/12/21/php-app-service/"
      }
      ,
    
      "2020-09-24-azure-cli-powershell": {
        "title": "Transformer des commandes Bash Azure CLI pour PowerShell",
        "tags": "azure, az-cli, powershell",
        "date": "September 24, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionLa plupart des exemples pour Azure CLI sont données pour Bash.Pour autant, on peut être sous Windows, sans sous-système Linux.On aura cependant toujours PowerShell&nbsp;!Voyons comment transformer les commandes Bash pour être exécutées sous PowerShell.Les variablesLes variables s&#8217;utilisent de la même façon grâce au symbole $.Ainsi la commande suivante s&#8217;exécute sous Bash ou PowerShell&nbsp;:echo $mavariableecho est un alias pour Write-Output en PowerShell.Par contre, la déclaration est bien différente&nbsp;:BashPowerShellmavariable=toto$mavariable=\"toto\"Passage à la lignePour des raisons lisibilités évidentes, les longues commandes Bash sont le plus souvent découpées pour passer à la ligne.Le caractère \\ suivi d&#8217;une nouvelle ligne est compris comme une continuation de ligne.BashPowerShellaz storage account create \\        --name $sa \\        -g $rg \\        --access-tier Hot \\        --sku Standard_LRSaz storage account create `        --name $sa `        -g $rg `        --access-tier Hot `        --sku Standard_LRSRécupération de la sortie d&#8217;une commandeEn mettant simplement entre  `, il est possible de récupérer le résultat d&#8217;une commande pour la mettre dans une variable.Finalement, ce n&#8217;est pas si compliqué en PowerShell.BashPowerShellstreaming_endpoint_hostname=`az ams streaming-endpoint show -g $rg -a $ams -n default`$streaming_endpoint_hostname = az ams streaming-endpoint show -g $rg -a $ams -n defaultConclusionVoici quelques exemples pour adapter les commandes sur PowerShell.Il resterait beaucoup à dire&nbsp;:Gestion des erreursTransformation en objet PowerShell (ex: az aks list | ConvertFrom-Json)Conversion de fonction plus avancées comme&nbsp;:Les bouclesLes pipesL&#8217;utilisation de fonction spécifiques non présentes par défaut comme jqEtc.Je mettrai à jour cette page en fonction des cas que je rencontre.",
        "url": "//2020/09/24/azure-cli-powershell/"
      }
      ,
    
      "2020-09-23-lab-data-factory": {
        "title": "Préparer rapidement un lab Data Factory en Azure CLI",
        "tags": "azure, az-cli, data-factory",
        "date": "September 23, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionLe tutorial de copie de données d&#8217;un compte destockage vers Azure SQL nécessite quelques prérequis.Récemment, j&#8217;ai voulu également tester les points de terminaison privés (Private Endpoint) avec Data Factory avec le tutorial de Microsoft  qui a les mêmes prérequis que le précédent tutorial.J&#8217;ai donc écrit les quelques lignes nécessaires en Azure CLI (pour varier les plaisirs avec les gabarits ARM).Il n&#8217;est pas nécessaire d&#8217;installer Azure CLI sur son poste pour exécuter les commandes. On peut utiliser le Bash d&#8217;Azure Cloud Shell.Les commandes sont données pour du Bash. Elles sont à adapter si vous utilisez PowerShell.Les variablesLes commandes suivantes s&#8217;appuient sur des variables pour contextualiser la création des ressources.Certains noms de ressource doivent être global unique&#8201;&#8212;&#8201;c&#8217;est-à-dire unique sur l&#8217;ensemble des clients Microsoft&#8201;&#8212;&#8201;comme le nom du compte de stockage et le nom du serveur SQL.D&#8217;autres, comme le nom de la base sont plus flexibles.# Nom du groupe de ressourcesrg=\"rg-dfy\"# Localisation du groupe de ressources et des ressources associéeslocation=\"francecentral\"# Compte de stockagesa=\"monstorage\"# Data Factorydfy=\"mondfy\"# Nom du serveur SQLsqlserver=\"monserveur\"# Mot de passe du serveur SQLsqlpwd=\"MonMotdePasseComplexe!\"# Nom de la base de donnéessqldb=\"mydb\"Et tout commença&#8230;&#8203; par un groupe de ressourcesaz group create -n $rg -l francecentralCréation des ressourcesServeur SQLOn crée ici une base en «&nbsp;Basic&nbsp;». Il faudra adapter en fonction de la taille souhaitée.az sql server create -l $location -g $rg -n $sqlserver -u myadminuser -p $sqlpwdaz sql db create -g $rg -s $sqlserver -n mydb --service-objective BasicCompte de stockage et conteneursLes commandes ci-dessous permettent de créer le compte de stockage et le conteneur.az storage account create --name $sa \\                          -g $rg \\                          --access-tier Hot \\                          --sku Standard_LRScn=`az storage account show-connection-string -g $rg -n $sa -o tsv`az storage container create \\    --account-name $sa \\    --name data \\    --public-access off \\    --connection-string $cnData Factoryaz extension add --name datafactoryaz datafactory factory create --name $dfy \\                              --resource-group $rgConclusionUne fois les variables définies, il est possible de contruire le lab en moins de 2min30.On voit à quel point Azure CLI est performant dans la création d&#8217;un environnement, bien plus quePowerShell dont les cmdlets sont puissantes mais très proches de l&#8217;implémentation ARM et donc assez complexe.A ma connaissance, il n&#8217;est pas possible de créer une VM en une ligne avec PowerShell alors que c&#8217;est possible en Azure CLI.Personnellement, pour des petits projets, je vais favoriser Azure CLI à ARM, qui malgré tout, reste assez coûteux à écrire et tester.",
        "url": "//2020/09/23/lab-data-factory/"
      }
      ,
    
      "2020-09-21-sql-server-sur-docker": {
        "title": "SQL Server sur docker et création de base",
        "tags": "docker, sql-server, kubernetes, acr",
        "date": "September 21, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionIl est possible d&#8217;exécuter des images de conteneur SQL Server avec Docker.Malheureusement, cette image ne permet pas créer de base de données par défaut.Au contraire, MySQL, par le truchement de la variable MYSQL_DATABASE, permet de créer une base de données au démarrage.C&#8217;est un point qui a été relevé assez puisque ce point est tracé dans le ticket n°2 du projet GitHub.La seule solution possible est donc de passer par la personnalisation de l&#8217;image. Les scripts ont été pris du ticket GitHub.Le DockerfileLe Dockerfile va se charger de modifier la commande de démarrage afin de pouvoir initialiser la base de données.Dockerfile# Choose exact tag (not 'latest'), to be sure that new version will not break creating imageFROM mcr.microsoft.com/mssql/server:2019-latest# Copy initialization scriptsCOPY *.sh ./USER root (1)RUN chmod +x *.shUSER mssql# Set environment variables, not to have to write them with docker run commandENV ACCEPT_EULA YENV MSSQL_PID Developer# Run Microsoft SQl Server and initialization script (at the same time)# Note: If you want to start MsSQL only (without initialization script) you can comment bellow line out, CMD entry from base image will be takenCMD /bin/bash ./entrypoint.sh1Par défaut, l&#8217;image s&#8217;exécute avec un utilisateur non root. De fait, dans la construction de l&#8217;image, je bascule temporairement en tant que root. A noter que sudo n&#8217;est pas disponible dans l&#8217;image de base.Le script entrypoint.sh lance init-db.sh en tâche de fond (d&#8217;où le &amp;) et démarre le serveur.entrypoint.sh# Run Microsoft SQl Server and initialization script (at the same time)./init-db.sh &amp; /opt/mssql/bin/sqlservrLe script init-db.sh va attendre le démarrage du serveur en scrutant les logs.init-db.sh#!/bin/bash# (see https://github.com/microsoft/mssql-docker/issues/2 )echo \"Container initialization: waiting for the server to come up\"while [ ! -f /var/opt/mssql/log/errorlog ]do  sleep 1doneFOUND=0i=0while [[ $FOUND -ne 1 ]] &amp;&amp; [[ $i -lt 60 ]]; do  i=$i+1  FOUND=$(grep -cim1 \"Service Broker manager has started\" /var/opt/mssql/log/errorlog)  if [[ $FOUND -ne 1 ]]; then    sleep 1  fidoneif [[ $FOUND -ne 1 ]]; then  echo \"Container initialization: Error: waited for more than 60 seconds for the server to start. Trying to create the database now...\"fisleep 10echo \"Container initialization: creating the database if needed\"/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P $SA_PASSWORD -Q \"CREATE DATABASE $DB_NAME\"echo \"Container initialization: done\"TestPas de surprise sur la construction de l&#8217;image&nbsp;:docker build -t mssql:latest .Il est ensuite possible de lancer l&#8217;imagedocker run --rm -e SA_PASSWORD=yourStrong(!)Password -e DB_NAME=mydb -p 1444:1433 mssql:latestJ&#8217;utilise ici un prompt Windows. Les variables d&#8217;environnement ne doivent pas être encadrées d&#8217;apostrophe comme décrit dans les exemples de la page DockerHub de SQL Server. Egalement, le prompt Windows accepte sans broncher les points d&#8217;exclamation&nbsp;!Puisque l&#8217;option -d n&#8217;a pas été utilisée, les logs apparaissent dans la console.On peut alors voir à la fin le message suivant, indiquant la création de la base&nbsp;:2020-09-21 16:44:53.70 spid51      Starting up database 'mydb'.2020-09-21 16:44:53.94 spid51      Parallel redo is started for database 'mydb' with worker pool size [4].2020-09-21 16:44:53.98 spid51      Parallel redo is shutdown for database 'mydb' with worker pool size [4].Container initialization: doneGrâce au mapping de port, il est alors possible d&#8217;utiliser son outil préféré pour se connecter à la base.Par exemple, avec Azure Data Studio, il est possible de préciser les paramètres suivants&nbsp;:Connection Type: Microsoft SQL ServerServer Name: localhost, 1444 (dans ma commande docker, j&#8217;ai utilisé un mapping du port 1444 vers le port 1433 du serveur)Authentication Type: SQL LoginUser name: saPassword: yourStrong(!)PasswordOn peut alors vérifier la version de SQL Server ou vérifier que la base a bien été créée en listant les bases de données&nbsp;:ConclusionMême si l&#8217;on peut regretter que l&#8217;image Docker de SQL Server ne crée pas automatiquement une base de données au démarrage, force est de constater qu&#8217;il est très facile de créer une base, que le support de SQL Server est excellent.Cela ouvre donc la porte à des scénarios intéressants de développement avec une forte réduction des contraintes sur le poste du développeur car même la base peut être «&nbsp;dockerisée&nbsp;».Finalement, on notera que Microsoft documente même un déploiement sur Kubernetes.",
        "url": "//2020/09/21/sql-server-sur-docker/"
      }
      ,
    
      "2020-09-18-form-recognizer-powershell": {
        "title": "Fun avec PowerShell et Azure Form Recognizer",
        "tags": "powershell, azure",
        "date": "September 18, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionAzure Form Recognizer est un service cognitif permettant d&#8217;extraire du texte d&#8217;images.C&#8217;est un service assez jeune d&#8217;Azure et ne dispose pas d&#8217;interface comme un Custom Vision hormis un client qu&#8217;on peut déployer soi-même.Azure Form Recognizer propose aujourd&#8217;hui des SDK pour .NET, Python, Java et JavaScript ainsi qu&#8217;une API REST.Pour le fun, j&#8217;ai donc utilisé PowerShell pour faire des appels à l&#8217;API REST.Paramètres d&#8217;accèsDans le portail Azure, il est possible de récupérer les informations dont on a besoin pour accéder au service dans la section «&nbsp;Clés et point de terminaison&nbsp;» de l&#8217;instance Form Recognizer&nbsp;:2 clés d&#8217;accèsL&#8217;URL d&#8217;accèsUne fois, ces valeurs récupérées, on peut initialiser les variables&nbsp;:# One of the key as defined in the \"Keys and Endpoint\" blade of Form Recognizer$key=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"# Endpoint as defined in the \"Keys and Endpoint\" blade of Form Recognizer# Must start with https:// and must end with a trailing \"/\"$endpoint = \"https://&lt;Instance Form Recognizer&gt;.cognitiveservices.azure.com/\"Lister les modèlesChaque entrainement de Form Recognizer va créer un nouveau modèle.Comment retrouver le modèle&nbsp;?Voici comment lister les modèles disponibles&nbsp;:$url = \"{0}formrecognizer/v2.0/custom/models\" -f $endpoint$headers = @{    \"Content-Type\" = \"application/json\"    \"Ocp-Apim-Subscription-Key\" = $key} (1)$res = Invoke-RestMethod -Method Get -Uri $url -Headers $headers (2)Write-Host \"Number of models:\", $res.modelList.Count$res.modelList | sort lastUpdatedDateTime (3)1On prépare les entêtes à passer dans un simple tableau associatif (hashtable) pour passer en outre la clé. Les utilisateurs d&#8217;Azure API Management auront reconnu l&#8217;entête Ocp-Apim-Subscription-Key.2Pas de subtilité ici&nbsp;: on utilise la méthode Invoke-RestMethod qui se chargera de désérialisé le contenu retourné en JSON en un objet PowerShell.3Il est alors possible d&#8217;afficher la liste des modèles, ranger par date de dernière mise à jour par exemple.Exemple de sortie&nbsp;:Number of models: 23modelId                              status createdDateTime      lastUpdatedDateTime-------                              ------ ---------------      -------------------7147e795-7780-4dc6-85b6-e9da78cf0134 ready  2020-09-08T11:28:47Z 2020-09-08T11:28:49Z18f5dde0-f7bf-42fb-abb7-daed423d374e ready  2020-09-08T11:40:07Z 2020-09-08T11:40:07Zbbdce3a1-3768-4f27-8bca-a2ec15b85331 ready  2020-09-08T11:41:47Z 2020-09-08T11:41:47Z8124abd3-93b0-413f-b6d6-af1695ed9571 ready  2020-09-08T12:09:08Z 2020-09-08T12:09:10Zbecc3c6c-d161-4121-b79d-177c6359529c ready  2020-09-08T12:14:10Z 2020-09-08T12:14:12Z...Faire une analyse d&#8217;un modèle personnaliséIl existe des modèles intégrés au service pour les cartes de visite ou des tickets de caisse.Il est cependant possible d&#8217;entrainer son propre modèle. Pour l&#8217;évaluation du modèle, nous aurons besoin de l&#8217;identifiant du modèle que l&#8217;on aura pu récupérer à l&#8217;étape précédente.Nous allons voir ici comment faire l&#8217;analyse d&#8217;une image.L&#8217;image peut être disponible sur Internet, typiquement sur un compte de stockage. Dans l&#8217;exemple ci-dessous, nous allons directement transférer l&#8217;image présente sur le disque. L&#8217;image peut être un JPEG, un PNG, un TIFF ou un PDF.Dans l&#8217;exemple, il s&#8217;agira d&#8217;une image JPEG (cf. le Content-Type à image/jpeg).L&#8217;analyse d&#8217;une image se fait en 2 temps&nbsp;:On soumet l&#8217;image.On récupère l&#8217;analyse de l&#8217;image.# Id of the model (GUID)$modelId = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"$url = \"{0}formrecognizer/v2.0/custom/models/{1}/analyze\" -f $endpoint, $modelId$imagePath = \"...\\XXX.jpeg\"$webRequest = [System.Net.HttpWebRequest]::Create($url) (1)$webRequest.Method = \"POST\"$webRequest.ContentType = \"image/jpeg\"$webrequest.Headers.Add(\"Ocp-Apim-Subscription-Key\", $key)$requestStream = $webRequest.GetRequestStream()$buffer = [System.IO.File]::ReadAllBytes($imagePath)  (2)$requestStream = $webRequest.GetRequestStream()$requestStream.Write($buffer, 0, $buffer.Length)$requestStream.Flush()$requestStream.Close()[System.Net.HttpWebResponse] $webResponse = $webRequest.GetResponse()$nextUrl = $webResponse.Headers[\"Operation-Location\"] (3)Start-Sleep -s 4 (4)$res = Invoke-RestMethod -Method Get -Headers @{\"Ocp-Apim-Subscription-Key\" = $key} -Uri $nextUrl (5)$res.analyzeResult.documentResults[0].fields1Afin de récupérer les entêtes de la réponse, nous allons utiliser un objet .NET de type WebRequest. La cmdlet Invoke-RestMethod dispose d&#8217;un paramètre ResponseHeadersVariable mais qui n&#8217;est disponible qu&#8217;à partir de PowerShell 6 qui n&#8217;est pas la version disponible par défaut.2Ici, on ne fait pas dans la dentelle. On lit toute l&#8217;image et on pousse dans la requête. Pas d&#8217;optimisation de la mémoire car l&#8217;image est assez petite.3On soumet la requête pour récupérer un objet réponse. C&#8217;est l&#8217;entête Operation-Location qui contient le lien pour récupérer le résultat de l&#8217;analyse.4L&#8217;analyse prend plus de 3 secondes. On attend 4s.5La méthode Invoke-RestMethod est parfaite pour récupérer le résultat de l&#8217;analyse.Exemple de sortie&nbsp;:MonChamps------------@{type=string; valueString=XXX; text=XXX; page=1; boundingBox=System.Object[]; confidence=1,0; elements=System.Object[]}ConclusionPowerShell est disponible sur tous les postes Windows 10.En utilisant PowerShell, il est possible de facilement interroger les services d&#8217;Azure Form Recognizer sans dépendance à Python ou développement de programme en .NET ou même installer le client fourni par MS.Ultimement, on peut envisager le développement d&#8217;une Azure Function en PowerShell, s&#8217;il est nécessaire de surfacer l&#8217;API d&#8217;Azure Form Recognizer avec sa propre API (pour des raisons de sécurité, de découplage ou autre).Cet exercice est laissé à la discrétion du lecteur 😉.",
        "url": "//2020/09/18/form-recognizer-powershell/"
      }
      ,
    
      "2020-07-23-creer-arm-template": {
        "title": "Trucs et astuces pour la création d&amp;#8217;ARM template",
        "tags": "arm, azure, trucs",
        "date": "July 23, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionL'ARM template est l&#8217;arme de choix dans l&#8217;arsenal d'Infrastructure as Code pour Azure.De manière générale, il ne faut pas négliger le temps nécessaire pour la création des scripts, des fichiers de configuration pour l'Infrastructure as Code.Pour autant, grâce à la répétabilité, vous gagnerez du temps pourla création des environnements (passage en prod à l&#8217;arrache&nbsp;?),en documentation, en qualité et en confiance (chaque mise à jour ne générera pas un stress car le résultat est connu d&#8217;avance)Comme on va le voir, il existe plusieurs façons de créer des ARM templates. Chacune a ses avantages et inconvénients.Il sera donc parfois nécessaire de les combiner pour arriver à vos fins.Table des matièresIntroductionAutomatisation dans le portailCréation dans le portailQuickstart templatesLa référenceExploration des ressourcesDéploiementPowerShellBonus&nbsp;: ARMTemplateGeneratorConclusionAutomatisation dans le portailLes gens me posent souvent la question&nbsp;: &laquo;&nbsp;Une fois que l&#8217;on a créé les ressources dans le portail, il n&#8217;est pas possible de faire un copié/collé pour créer un nouvel environnement&nbsp;?&nbsp;&raquo;Oui et non.En effet, le portail a une fonction proche&nbsp;:&laquo;&nbsp;Exporter le modèle&nbsp;&raquo;.Cette fonctionnalité est présente au niveau d&#8217;un groupe de ressources ou au niveau de la plupart des ressources.Dans le portail&nbsp;:Puis, le contenu généré&nbsp;:Avantages&nbsp;:Solution simple.La qualité des ARM templates s&#8217;améliorent.Le portail génère également le fichier de paramètres.Inconvénients&nbsp;:Comme on peut le voir sur la copie d&#8217;écran ci-dessus, toutes les ressources ne sont pas exportables.Il n&#8217;est pas rare que des paramètres soient omis.En réalité, les ARM templates ainsi produits sont de qualité assez médiocre&nbsp;:Le nom des paramètres utilise le nom des ressources. Comme l&#8217;objectif est souvent de pouvoir créer plusieurs environnements, il est préférable de généraliser le nom des paramètres. Par exemple, pour un compte de stockage, le paramètre va être storageAccounts_nomducomptedestockage_name. Il est recommandé de le renommer storageAccountName par exemple pour le généraliser et conserver une convention de nommage en camelCase.Il n&#8217;y a pas d&#8217;intelligence dans ces templates. Il peut être intéressant de prévoir des boucles ou d&#8217;autres logiques.Création dans le portailLors de la création d&#8217;une ressource, il est possible, juste avant la créationd&#8217;exporter un ARM template.Avantages&nbsp;:Solution simple.ARM template plus propre que lors de l&#8217;export.Le portail génère également le fichier de paramètres.Inconvénients&nbsp;:Les ARM templates ainsi générés peuvent plus complexe que nécessaire et inclure un paramétrage non nécessaire.Ainsi, lors de la création d&#8217;une base, l'ARM template généré intègre la création d&#8217;un serveur SQL alors qu&#8217;il s&#8217;agissait de la création d&#8217;une base uniquement. Sans parler de toute la configuration réseau ou de sécurité avancée&#8230;&#8203;Les ARM templates ainsi générés sont parfois si complexe qu&#8217;ils ne sont pas valides (j&#8217;ai déjà eu le cas&nbsp;!).Quickstart templatesMicrosoft met à disposition des exemples pour la création de nombreuses ressources sur GitHub.On peut y retrouver des exemples de base (préfixés en 101) jusqu&#8217;à des architectures complexes (ferme RDS, infrastructure SAP, etc.).Avantages&nbsp;:Bon point de départ pour des cas de la vie réelle comme le chiffrement de disque de VM ou sa sauvegarde, des applications Web, etc.Pas mal d&#8217;astuces à reprendre pour l&#8217;écriture d'ARM templates sur les conditions, les boucles, le jeu des nested templates, etc.De nombreux template sur des composants non-Microsoft (Chef, SAP, Jenkins, Drupal, etc.).Inconvénients&nbsp;:Certains template ne sont pas mis à jour alors que le service évolue.Ainsi, certains templates utilisent des vieilles versions d&#8217;API.Je pense notamment aux App Services dont la gestion des piles technologies a évoluée et pour laquelle je n&#8217;ai pas trouvé d&#8217;exemple viableCela manque de cohérence&nbsp;:Sur le nommage des paramètres. Un réseau virtuel peut s&#8217;appeler vnet ou virtualNetworkName, ce qui nécessite un travail pour mettre en cohérence.La gestion de la localisation de la ressource: dans le cas général, comme ici, la localisation est traitée comme un paramètre qui a une valeur par défaut à celle du groupe de ressource, ici c&#8217;est une variable.La référenceMicrosoft publie la documentation des ressources disponibles, pour les différentes versions d&#8217;API.Malheureusement, ces pages ne sont pas irréprochables.Ainsi, le nommage est proche de l&#8217;implémentation et l&#8217;on va avoir quelques bizarreries comme par exemple pour les App Services&nbsp;: pour avoir la référence, inutile de chercher &laquo;&nbsp;App Service&nbsp;&raquo;. Il faut aller sur &laquo;&nbsp;Web&nbsp;&raquo; car le provider est Microsoft.Web.Ne cherchez pas non plus &laquo;&nbsp;App Insights&nbsp;&raquo;, etc.Vous voilà prévenu&nbsp;!Mais le principal reproche est que les valeurs sont rarement documentées.Par exemple, le paramètre type de la configuration git d&#8217;un DataFactory n&#8217;a pas de valeur décriteAvantages&nbsp;:Liste en théorie tous les paramètres disponiblesInconvénients&nbsp;:Il n&#8217;est pas rare qu&#8217;il manque des paramètresLes valeurs des enums sont souvent manquantesLe parcours du site n&#8217;est pas toujours aisé du fait d&#8217;une recherche médiocreExploration des ressourcesMicrosoft met à disposition une interface Web qui permet de parcourir les ressources de sa souscription en ARM&nbsp;: https://resources.azure.com.Cet outil est très utile pour justement récupérer les valeurs que la référence n&#8217;aura pu nous donner.Cela étant, comme il n&#8217;affiche pas un ARM template, il y a un travail certain pour convertir l&#8217;information dans un ARM template.A utiliser en dernier recours donc&nbsp;!Cet outil permet de parcourir les différentes souscriptions rattachées à différents tenants Azure AD.Avantages&nbsp;:Permet d&#8217;afficher les valeurs. Cela est intéressant quand on joue dans le portail pour voir les effets en ARM.Inconvénients&nbsp;:Ne fournit pas un ARM template à proprement parler.Il est nécessaire de faire le tri en les paramètres que l&#8217;on peut fixer et ceux qui sont des attributs systèmes, accessibles en lecture seule par exemple.Toutes les ressources ne sont pas affichages par ce biais.Tous les paramètres ne sont pas affichés, notamment les secrets.DéploiementChaque déploiement dans un groupe de ressources est tracé.C&#8217;est un bon moyen parfois pour avoir des détails sur les erreurs.Mais il est possible de récupérer l'ARM template utilisé lors de l&#8217;export.Dans le portail, il suffit d&#8217;aller dans le menu &laquo;&nbsp;Déploiement&nbsp;&raquo;&nbsp;:Il est alors possible d&#8217;accéder aux paramètres d&#8217;entrée, au template utilisé&nbsp;:Le template affiché ici est différent de l&#8217;export proposé à la création.Avantages&nbsp;:Récupération d'ARM template fonctionnel (dès lors que le déploiement est en succès).Très bonne méthode pour faire du reverse engineering si les templates ont été perdu.Inconvénients&nbsp;:Comme pour les autres méthodes à partir du portail Azure, la qualité du template n&#8217;est pas toujours excellente.PowerShellC&#8217;est une critique que l&#8217;on peut faire aux cmdlets PowerShell d&#8217;Azure&nbsp;: je trouve qu&#8217;on est souvent trop proche de l&#8217;implémentation ARM. Essayez de créer une VM en PowerShell&nbsp;! En Az cli, cela peut se faire en une ligne, pas en PowerShell.Pour autant, ici cela peut être un avantage.Je me suis servi de cette technique pour automatiser la création d&#8217;alerte. Il est facile de créer ou modifier une alerte ou un groupe d&#8217;actions dans le portail mais il n&#8217;existe pas les moyens de l&#8217;exporter.Les alertes sont aussi absentes d'Azure Resource Explorer.J&#8217;ai donc travaillé avec la cmdlet Get-AzMetricAlertRuleV2 qui m&#8217;a permis d&#8217;aller dans le détail des paramètresExemple pour avoir l&#8217;identifiant du groupe d&#8217;action&nbsp;:$alertes = Get-AzMetricAlertRuleV2$alerte = $alertes[0]$alerte.Actions[0].ActionGroupIdAvantages&nbsp;:Permet parfois d&#8217;accéder à des valeurs qui sont inaccessibles de l'explorateur de ressources.Inconvénients&nbsp;:Comme pour l'explorateur de ressources, cette méthode ne permet pas d&#8217;obtenir un ARM template directement exploitable.Cette méthode ne va pas fonctionner sur toutes les ressources car cela dépend à quel point la cmdlet est proche de l&#8217;implémentation ARMBonus&nbsp;: ARMTemplateGeneratorAfin de pallier les défauts rencontrés dans la création d'ARM templates, j&#8217;ai créé un outil permettant la création d'ARM templates &laquo;&nbsp;propre&nbsp;&raquo;&nbsp;: https://github.com/r3dlin3/ARMTemplateGenerator.Cet outil permet de&nbsp;:Assurer une cohérence dans le nommage des paramètresGénérer un template en fonction de son besoin&nbsp;: ainsi, lors de la création d&#8217;une base, le template généré contiendra la création d&#8217;un serveur que si cela est nécessaire.N&#8217;hésitez pas à contribuer pour ajouter des ressources ou des nouveaux paramètres, mettre à jour les API, etc.Avantages&nbsp;:Cohérence dans le nommage des paramètresTemplate adapté à son besoinInconvénients&nbsp;:Peu de ressources disponiblesConclusionL&#8217;écriture d'ARM templates n&#8217;est pas toujours compliqué heureusement.Parfois, cependant, pour arriver à ses fins, il peut être nécessairement d&#8217;ouvrir le truc au pied de biche, mais cela vaut souvent le coup.Chacune des techniques citées plus haut vous permettra d&#8217;arriver à vos fins, si tant est que soit possible.On se souvient par exemple qu&#8217;à l&#8217;époque, il n&#8217;était pas possible de créer un container sur un compte de stockage.Aujourd&#8217;hui, c&#8217;est possible de le faire en ARM template.",
        "url": "//2020/07/23/creer-arm-template/"
      }
      ,
    
      "2020-06-10-filtrer-sql-app-service": {
        "title": "Configurer automatiquement le firewall SQL/MySQL/PostgreSQL pour un App Service",
        "tags": "arm, azure, app-service, sql",
        "date": "June 10, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionApp Service et Azure SQL sont deux composants PaaS publiques. Cela veut dire qu&#8217;ils disposent d&#8217;adresses IP publiques.Azure SQL ou Azure Database pour MySQL ou Azure Database pour PostgreSQL dispose d&#8217;un mécanisme de firewall qui permet de filtrer les connexions entrantes.Ce firewall dispose d&#8217;une case à cocher permettant d&#8217;autoriser ou non le trafic Azure.Malheureusement, ce trafic Azure ne se limite pas au trafic de sa souscription.Ainsi n&#8217;importe quelle VM ou App service sera autorisée.Pour autant, App Service dispose d&#8217;une liste d&#8217;IP de sortie que l&#8217;on pourra utiliser pour restreindre l&#8217;accès à la base sans aller vers de l&#8217;App Service Environment.Autant il est possible de manuellement récupérer cette liste d&#8217;IP dans le portail Azure et ajouter ces IP au firewall de la base, autant on va essayer  d&#8217;automatiser au mieux la solution par l&#8217;utilisation d&#8217;ARM template.Il ne s&#8217;agit pas ici de se focaliser uniquement sur le firewall comme moyen unique de protection. Mais autant le configurer correctement pour agir comme première barrière.Organisation de l&#8217;ARM templateNous allons ici utiliser le mécanisme de modèle imbriqué ou nested templates.Ainsi, la création et la configuration des ressources vont se passer en 3 étapes comme montré sur la figure ci-dessous&nbsp;Les adresses IP d&#8217;un App ServiceIl est possible de récupérer les adresses IP d&#8217;un App Service et de les rendre disponible dans l'`output` de l'ARM Template comme suit&nbsp;:\"outputs\": {    \"possibleOutboundIps\": {        \"type\": \"array\",        \"value\": \"[split(reference(parameters('siteName'), variables('apiVersion')).possibleOutboundIpAddresses, ',')]\"    }}Grâce à la fonction split, on récupère directement un tableau des adresses IP.On peut aussi noter l&#8217;utilisation possibleOutboundIpAddresses, ce qui donne une liste assez large mais qui va empêcher des arrêts de service si l&#8217;App Service doit changer d&#8217;infrastructure pour une raison ou pour une autre.Formatage des règlesLa liste des IP peut être récupérer à partir du template parent grâce à la syntaxe suivante, avec appserviceNestedDeployment le nom du déploiement du nested template pour l&#8217;App Service&nbsp;:[reference('appserviceNestedDeployment').outputs.possibleOutboundIps.value]L&#8217;objectif de l&#8217;étape de formatage va être créer un nouveau tableau d&#8217;objet prêt à l&#8217;emploi pour la dernière étape. On va donc parcourir le tableau d&#8217;IP grâce à une boucle et créer un tableau d&#8217;objet avec le nom de la règle (sur la base d&#8217;un incrément) et une des IP (startIpAddress et endIpAddress sont égaux).{    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"inputArray\": {            \"type\": \"array\",            \"metadata\": {                \"description\": \"string array of ip addresses\"            }        },        \"ruleNamePrefix\": {            \"type\": \"string\",            \"maxLength\": 26,            \"metadata\": {                \"description\": \"prefix to use in the name of the rule\"            }        }    },    \"variables\": {        \"outputArray\": {            \"copy\": [                {                    \"name\": \"items\",                    \"count\": \"[length(parameters('inputArray'))]\",                    \"input\": {                        \"startIpAddress\": \"[parameters('inputArray')[copyIndex('items')]]\",                        \"endIpAddress\": \"[parameters('inputArray')[copyIndex('items')]]\",                        \"name\": \"[concat(parameters('ruleNamePrefix'), copyIndex('items'))]\"                    }                }            ]        }    },    \"resources\": [],    \"outputs\": {        \"firewallRules\": {            \"value\": \"[variables('outputArray').items]\",            \"type\": \"array\"        }    }}Le tableau ainsi généré est placé dans l'output pour être récupérer dans l&#8217;étape finale.Configuration du firewallDans le cas de MySQL (le cas est similaire pour Azure SQL), on va donc parcourir le tableau d&#8217;objet précédemment créé pour créer la règle de firewall.{    \"name\": \"[concat(parameters('mysqlServerName'),'/',parameters('firewallrules')[copyIndex()].name)]\",    \"type\": \"Microsoft.DBforMySQL/servers/firewallRules\",    \"apiVersion\": \"2017-12-01\",    \"location\": \"[parameters('location')]\",    \"dependsOn\": [        \"[concat('Microsoft.DBforMySQL/servers/', parameters('mysqlServerName'))]\"    ],    \"copy\": {        \"name\": \"firewallRulesCopy\",        \"count\": \"[length(parameters('firewallrules'))]\"    },    \"properties\": {        \"StartIpAddress\": \"[parameters('firewallrules')[copyIndex()].startIpAddress]\",        \"EndIpAddress\": \"[parameters('firewallrules')[copyIndex()].endIpAddress]\"    }}ARM templatesCette mécanique a été utilisée pour les templates de phpOIDC.On peut donc retrouver un exemple complet sur GitHub.Il existe certainement plein de façons d&#8217;arriver au même résultat.L&#8217;utilisation des nested templates permet d&#8217;assurer une certaine flexibilité.Ainsi, la liste des IP aurait pu être concaténée avec une autre liste, grâce à la fonction union.Également, cette méthode peut être conservée pour Azure SQL ou Azure Database pour MySQL ou Azure Database pour PostgreSQL.Je recommande l&#8217;utilisation du script deploy.ps1 qui facilite grandement l&#8217;utilisation des modèles imbriqués.Il permet de&nbsp;:Créer un compte de stockage s&#8217;il n&#8217;existe pasCopier les ARM templates.Générer un token SASDéployer l&#8217;ARM",
        "url": "//2020/06/10/filtrer-sql-app-service/"
      }
      ,
    
      "2020-05-29-aci-grafana-influxdb-en": {
        "title": "Grafana and InfluxDB on Azure Container Instances",
        "tags": "docker, aci, azure, influxdb, grafana, english, arm",
        "date": "May 29, 2020",
        "author": "",
        "category": "",
        "content": "This the translation of a previous articlepublished in French.Azure Container Instances (ACI) is one of many ways to run containers on Azure. One of the advantages of ACI over App Service (presented in a previous article (in French)) is the ability to expose multiple ports.So we&#8217;re going to expose a Grafana instance and an InfluxDB database.Grafana is an open source solution for creating dashboard. InfluxDB is its companion of choice for time series storage.In this article, for simplicity sake, I will not expose Grafana over HTTPS.You will have to refer to my previous article Certificat Let&#8217;s Encrypt sur Azure Container Instances et NGINX (in French) for the implementation of HTTPS.The solutionAs mentioned, the solution will run on Azure Container Instances.Grafana needs a database for its configuration. Grafana supports  3 kind of databases:SqliteMysqlPostgresqlTo avoid losing the configuration if the container restarts, the data is persistently stored on Azure Files.Unfortunately, due to some limitations, it was not possible to persist on Azure Files the SQLite database (embarked by default in Grafana) (a dark story about locks) or to use the Docker image provided by PostgreSQL (a dark  story about files and their owner).We will therefore use MySQL and its Docker image.MySQL will not be published on the Internet.Grafana data sourcesIt is  possible to provide a list of data sources per YAML file.We will use this mechanism to automatically set up InfluxDB as a data source.So, the configuration of the data source in YAML will be:influxdb.yamlapiVersion: 1deleteDatasources:  - name: InfluxDB    orgId: 1datasources:  - name: InfluxDB    type: influxdb    access: proxy    orgId: 1    database: PERF    user: influxadmin    password: influxadmin    url: http://localhost:8086This file will be passed as a secret. The base64 function of ARM template will be used to encode the content and pass it as a secret.Note about container groups in Azure Container InstancesAzure Container Instances use a \"proprietary\" format that is neither Docker Compose nor a Kubernetes deployment file.The important point to keep in mind is that we will declare each port expose by a container, and then which of them are exposed by the container group. It is not possible to translate ports, as recall in the FAQ.Also, beware that communication between containers is not using the name of the container (as in Docker Compose) but localhost!Thus, Grafana will point in its configuration to localhost:3036 for its database and localhost:8086 for the case of InfluxDB.Automated deploiementIt is possible to use YAML or ARM template. As mentioned in my previous article (in French),I highly recommend the use of ARM template that will allow to have some dynamic settings that can be changed during deployment.However, I will limit the number of parameters.Environment variablesThe environment variables we will use are described below.Table 1. MySQLNameDescriptionMYSQL_DATABASEThe name of a database to be created on image startup.MYSQL_USER, MYSQL_PASSWORDUsername and password of a user created that has superuser permissions on the databaseMYSQL_RANDOM_ROOT_PASSWORDWill generate a random password for the root userOther environment variables are available and are described on MySQL&#8217;s Docker image page.Table 2. InfluxDBNameDescriptionINFLUXDB_DBThe name of a database to be created on image startup.INFLUXDB_ADMIN_USER, INFLUXDB_ADMIN_PASSWORDUsername and password of database admin.Other environment variables are available and are described on InfluxDB&#8217;s Docker image page.Grafana has a very extensible mechanism that allows to define any parameter from environment variables.We will use the following environment variable.Table 3. GrafanaNameDescriptionGF_DATABASE_URLConnection URL to MySQLGF_SECURITY_ADMIN_PASSWORDPassword for admin (this will avoid going through the configuration assistant)In my previous article, I also used the variable GF_SERVER_DOMAIN to set up Grafana behind NGINX.ARM templateThe ARM template and settings are shown below.grafana.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"type\": \"securestring\",            \"metadata\": {                \"description\": \"Password for Grafana admin.\"            }        },        \"containerGroupName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Container Group name.\"            }        },        \"dnsLabel\": {            \"type\": \"string\",            \"defaultValue\": \"\",            \"metadata\": {                \"description\": \"DNS label used to by the container group. The FQDN is &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io\"            }        },        \"storageAccountName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Name of the Storage Account\"            }        },        \"storageAccountType\": {            \"type\": \"string\",            \"defaultValue\": \"Standard_LRS\",            \"allowedValues\": [                \"Standard_LRS\",                \"Standard_GRS\",                \"Standard_ZRS\",                \"Premium_LRS\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"accessTier\": {            \"type\": \"string\",            \"defaultValue\": \"Hot\",            \"allowedValues\": [                \"Hot\",                \"Cool\"            ],            \"metadata\": {                \"description\": \"The access tier used for billing.\"            }        },        \"storageAccountKind\": {            \"type\": \"string\",            \"defaultValue\": \"StorageV2\",            \"allowedValues\": [                \"StorageV2\",                \"Storage\",                \"BlobStorage\",                \"FileStorage\",                \"BlockBlobStorage\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"advancedThreatProtectionEnabled\": {            \"type\": \"bool\",            \"defaultValue\": false,            \"metadata\": {                \"description\": \"Enable or disable Advanced Threat Protection.\"            }        },        \"shares\": {            \"type\": \"array\",            \"metadata\": {                \"description\": \"List of the file share names.\"            }        },        \"location\": {            \"type\": \"string\",            \"defaultValue\": \"[resourceGroup().location]\",            \"metadata\": {                \"description\": \"The region to deploy the resources into\"            }        },        \"tagValues\": {            \"type\": \"object\",            \"defaultValue\": {            }        }    },    \"variables\": {        \"dnsLabel\": \"[if(empty(parameters('dnsLabel')), parameters('containerGroupName'), parameters('dnsLabel'))]\",        \"fqdn\": \"[toLower(concat(variables('dnsLabel'),'.',replace(parameters('location'), ' ', ''),'.azurecontainer.io'))]\"    },    \"resources\": [        {            \"type\": \"Microsoft.Storage/storageAccounts\",            \"name\": \"[parameters('storageAccountName')]\",            \"location\": \"[parameters('location')]\",            \"apiVersion\": \"2018-07-01\",            \"sku\": {                \"name\": \"[parameters('storageAccountType')]\"            },            \"kind\": \"[parameters('storageAccountKind')]\",            \"properties\": {                \"accessTier\": \"[parameters('accessTier')]\",                \"encryption\": {                    \"keySource\": \"Microsoft.Storage\",                    \"services\": {                        \"blob\": {                            \"enabled\": true                        },                        \"file\": {                            \"enabled\": true                        }                    }                },                \"supportsHttpsTrafficOnly\": true            },            \"resources\": [                {                    \"condition\": \"[parameters('advancedThreatProtectionEnabled')]\",                    \"type\": \"providers/advancedThreatProtectionSettings\",                    \"name\": \"Microsoft.Security/current\",                    \"apiVersion\": \"2017-08-01-preview\",                    \"dependsOn\": [                        \"[resourceId('Microsoft.Storage/storageAccounts/', parameters('storageAccountName'))]\"                    ],                    \"properties\": {                        \"isEnabled\": true                    }                }            ]        },        {            \"type\": \"Microsoft.Storage/storageAccounts/fileServices/shares\",            \"apiVersion\": \"2019-04-01\",            \"name\": \"[concat(parameters('storageAccountName'), '/default/', parameters('shares')[copyIndex()])]\",            \"copy\": {                \"name\": \"sharecopy\",                \"count\": \"[length(parameters('shares'))]\"            },            \"dependsOn\": [                \"[parameters('storageAccountName')]\"            ]        },        {            \"name\": \"[parameters('containerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"dependsOn\": [                \"sharecopy\"            ],            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"properties\": {                \"containers\": [                    {                        \"name\": \"mysql\",                        \"properties\": {                            \"image\": \"mysql\",                            \"environmentVariables\": [                                {                                    \"name\": \"MYSQL_USER\",                                    \"value\": \"grafana\"                                },                                {                                    \"name\": \"MYSQL_PASSWORD\",                                    \"secureValue\": \"grafana\"                                },                                {                                    \"name\": \"MYSQL_RANDOM_ROOT_PASSWORD\",                                    \"value\": \"yes\"                                },                                {                                    \"name\": \"MYSQL_DATABASE\",                                    \"value\": \"grafana\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 3306                                },                                {                                    \"port\": 443                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"mysql-data\",                                    \"mountPath\": \"/var/lib/mysql\"                                }                            ]                        }                    },                                        {                        \"name\": \"influxdb\",                        \"properties\": {                            \"image\": \"influxdb\",                            \"environmentVariables\": [                                {                                    \"name\": \"INFLUXDB_DB\",                                    \"value\": \"PERF\"                                },                                {                                    \"name\": \"INFLUXDB_ADMIN_USER\",                                    \"value\": \"influxadmin\"                                },                                {                                    \"name\": \"INFLUXDB_ADMIN_PASSWORD\",                                    \"secureValue\": \"influxadmin\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 8086                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"influxdb-volume\",                                    \"mountPath\": \"/var/lib/influxdb\"                                }                            ]                        }                    },                    {                        \"name\": \"grafana\",                        \"properties\": {                            \"image\": \"grafana/grafana\",                            \"ports\": [                                {                                    \"port\": 3000                                }                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"GF_SECURITY_ADMIN_PASSWORD\",                                    \"secureValue\": \"[parameters('grafanaAdminPassword')]\"                                },                                {                                    \"name\": \"GF_DATABASE_URL\",                                    \"secureValue\": \"mysql://grafana:grafana@localhost:3306/grafana\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 1,                                    \"memoryInGb\": 0.5                                }                            },                            \"volumeMounts\": [                                {                                    \"name\": \"grafana-volume\",                                    \"mountPath\": \"/var/lib/grafana\"                                },                                {                                    \"name\": \"grafana-provisioning\",                                    \"mountPath\": \"/etc/grafana/provisioning/datasources\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"OnFailure\",                \"ipAddress\": {                    \"type\": \"Public\",                    \"ports\": [                        {                            \"port\": 3000                        },                        {                            \"port\": 8086                        }                    ],                    \"dnsNameLabel\": \"[variables('dnsLabel')]\"                },                \"volumes\": [                    {                        \"name\": \"mysql-data\",                        \"azureFile\": {                            \"shareName\": \"mysql-data\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"influxdb-volume\",                        \"azureFile\": {                            \"shareName\": \"influxdb-volume\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"grafana-volume\",                        \"azureFile\": {                            \"shareName\": \"grafana-volume\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"grafana-provisioning\",                        \"secret\": {                            \"influxdb.yaml\": \"[base64('apiVersion: 1deleteDatasources:  - name: InfluxDB    orgId: 1datasources:  - name: InfluxDB    type: influxdb    access: proxy    orgId: 1    database: PERF    user: influxadmin    password: influxadmin    url: http://localhost:8086                            ')]\"                        }                    }                ]            }        }    ],    \"outputs\": {    }}grafana.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"value\": \"grafanapwd\"        },        \"containerGroupName\": {            \"value\": \"test-grafana-influxdb\"        },        \"storageAccountName\": {            \"value\": \"stotestacmenginx\"        },        \"shares\": {            \"value\": [                \"mysql-data\",                \"influxdb-volume\",                \"grafana-volume\"            ]        },        \"location\": {            \"value\": \"West Europe\"        }    }}It is possible to deploy by using the following PowerShell command: New-AzResourceGroupDeployment -ResourceGroupName $rg -TemplateFile .\\influxdb-grafana.json -TemplateParameterFile .\\influxdb-grafana.parameters.json -VerboseAlso, by using Az CLI:az group deployment create --resource-group $rg --template-file ./influxdb-grafana.json --parameters @influxdb-grafana.parameters.json --handle-extended-json-formatYou will have to use the setting --handle-extended-json-format that provides support for multiline in JSON.ConclusionWithin a few minutes, it is possible to assemble a Grafana and an InfluxDB database.There is a lot of use cases that might benefits for an InfluxDB and Grafana: IoT, application monitoring, etc. A use case could also be load tests with Locust. To be continued&#8230;&#8203;",
        "url": "//2020/05/29/aci-grafana-influxdb-en/"
      }
      ,
    
      "2020-05-19-moteur-template-php-i18n": {
        "title": "Moteur de template PHP et internationalisation",
        "tags": "php, i18n, blade",
        "date": "May 19, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionLes frameworks PHP comme Laravel, Symfony ou Phalcondispose tous d&#8217;un moteur de template propre, respectivement Blade,Twig ou Volt.Reprenant un projet PHP qui n&#8217;utilisait aucun framework, il me fallait une solution qui tourne sans framework imposé.Et pourquoi pas Twig ?Mon choix s&#8217;est d&#8217;abord porté sur Twig, qui existe en autonome en principe.J&#8217;ai dû m&#8217;en détourner pour les raisons suivantes&nbsp;:La toute dernière version (3.x) ne supporte plus l&#8217;extensions d&#8217;internalisation mais requiert symfony/twig-bridge pour le tag trans. Or, symfony/twig-bridge. Il n&#8217;y a pas de documentation pour l&#8217;intégration dans un projet sans SymfonyCes extensions d&#8217;internationalisation reposent sur gettext.gettext est une solution très préformante, cependant&nbsp;:Il n&#8217;y a pas d&#8217;outil gratuit qui permette une extraction des chaînes de caractères&nbsp;:Poedit est certainement une très bonne solution mais l&#8217;extraction des chaînes d&#8217;un fichier Twig requiert la licence pro.Toute autre solution est vouée à générée les pages de Twig en fichier PHP et utiliser xgettext. Malheureusement, on perd le fichier d&#8217;origine.Les fichiers de traduction sont mis en cache par le serveur. La mise à jour d&#8217;un fichier compilé (i.e. .mo) peut requérir un redémarrage.Le comportement est différent entre Windows et Linux. Par exemple, Windows ne définit la constante LC_MESSAGES, ce qui impose de forcer la locale pour LC_ALL ce qui peut avoir des conséquences importantes (dans la gestion des nombres, etc.).Il faut que la locale soit présente sur le serveur, ce qui est rédhibitoire pour un serveur partagé.Le sauveur&nbsp;?Pour toute ces raisons, je me suis donc intéressé au projet BladeOne, une implémentation autonome et légère de Blade.Elle supporte un module d&#8217;internationalisation intégré au moteur&nbsp;: BladeOneLang.Il est clair que la gestion des traductions ne pourrait convenir à un projet d&#8217;envergure mais pour un projet sans Framework comme le mien, c&#8217;est parfait&nbsp;!InstallationL&#8217;installation se fait le plus simplement du monde grâce à composer&nbsp;:composer require eftec/bladeoneIl existe d&#8217;autres méthodes documentées dans le README.Il faut ensuite prévoir la création de 3 répertoires&nbsp;:cachePour le cacheviewsPour les vuesUtilisationCet exemple ultrasimple va se décomposer en 3 fichiers&nbsp;:La vueLa traductionLe fichier PHP exécutéCommençons par la vue. BladeOneLang définit 3 méthodes pour aider à la traduction&nbsp;:@_eVa rechercher la chaîne à partir de la clé@_efVa permettre d&#8217;avoir des paramètres@_nVa permettre de mettre au plurielL&#8217;exemple ci-dessous est un exemple de remplacement&nbsp;:views\\translation.blade.php&lt;h1&gt;Translation&lt;/h1&gt;Hat:&lt;br&gt;@_e('Hat')&lt;br&gt;&lt;br&gt;&lt;hr&gt;Trust this site always :&lt;br&gt;@_e('Trust this site always')&lt;br&gt;&lt;br&gt;&lt;hr&gt;'%s is a nice cat' with '{{$variable1}}' :&lt;br&gt;@_ef('%s is a nice cat', $variable1)&lt;br&gt;&lt;br&gt;La traduction se fait simplement dans un tableau associatif. Le tableau statique BladeOne::$dictionary sera utilisé pour la traduction&nbsp;:locales\\fr.php&lt;?phpuse eftec\\bladeone\\BladeOne;BladeOne::$dictionary=array(    'Hat'=&gt;'Chapeau',    'Cat'=&gt;'Chat',    '%s is a nice cat'=&gt;'%s est un bon chat',    \"Trust this site always\" =&gt; \"Toujours faire confiance à ce site\",    \"Deny\" =&gt; \"Refuser\");Finalement, le bout de code d&#8217;exécution&nbsp;:translation.php&lt;?phprequire \"vendor/autoload.php\";Use eftec\\bladeone\\BladeOne;$views = __DIR__ . '/views';$cache = __DIR__ . '/cache';$blade = new BladeOne($views,$cache,BladeOne::MODE_AUTO); (1)$lang='fr'; // try es,jp or frinclude './locales/'.$lang.'.php'; (2)$blade-&gt;missingLog='./missingkey.txt'; // (optional) if a traduction is missing the it will be saved here.echo $blade-&gt;run(\"translation\",array(\"variable1\"=&gt;\"value1\")); (3)1Initialisation du moteur avec les répertoires de cache et de vue.2Chargement du dictionnaire (statique) pour les traductions3Génération du contenu à partir de la vueUn petit coup de php -S localhost:8000, on saute sur http://localhost:8000/translation.php et voilà&nbsp;:ConclusionBladeOne n&#8217;est probablement pas le projet du siècle mais propose une réponse simple et élégante pour celui ou celle qui ne veut pas s&#8217;imposer un framework complet mais souhaite tout de même séparer la vue du reste de l&#8217;application tout en conservant des capacités d&#8217;internationalisation.Ce projet offre des avantages comme&nbsp;:L&#8217;indépendance par rapport aux locales du serveurL&#8217;indépendance par rapport au système d&#8217;exploitation du serveurLa rapidité et flexibilité de BladeA conserver en tête donc pour des petits projets requérant de l&#8217;internationalisation.",
        "url": "//2020/05/19/moteur-template-php-i18n/"
      }
      ,
    
      "2020-05-03-vuejs-bulma": {
        "title": "Intégrer Bulma CSS et Vue.js",
        "tags": "typescript, vue.js, css",
        "date": "May 3, 2020",
        "author": "",
        "category": "",
        "content": "Vue.js est un framework de développement Web très intéressant. J&#8217;avais également envie de voir autre chose que Bootstrap. J&#8217;ai donc donné un coup d&#8217;essai à Bulma.Comme j&#8217;ai dû combiner 3 articles et quelques résultats sur Stack Overflow pour avoir une bonne intégration entre les deux, voici un article pour décrire le modus operandi avec un projet utilisant TypeScript.Création du projetLors de la création du projet, pensez à prévoir un préprocesseur CSS. J&#8217;utilise node-sass mais je n&#8217;ai pas fait de comparaison avec dart-sass.InstallationL&#8217;installation se fait simplement avec la commande suivante&nbsp;:yarn add bulmaPersonnalisationCréer un fichier `.sass dans le répertoire assets avec le contenu suivant&nbsp;:./assets/main.sass@charset \"utf-8\"$rouge: #DF776D$primary: $rouge@import \"../../node_modules/bulma/bulma.sass\"Importer la feuille de styleOuvrir le fichier src\\main.ts et ajouter la ligne suivante&nbsp;:import \"./assets/main.sass\";Les icônesBulma s&#8217;appuie sur Font Awesome 5 pour afficher des icônes. Pour pouvoir les utiliser, il faut donc penser à charger le fichier de Font Awesome.Pour ce faire, ouvrir public\\index.html et ajouter dans la balise head la ligne suivante&nbsp;:&lt;script defer src=\"https://use.fontawesome.com/releases/v5.3.1/js/all.js\"&gt;&lt;/script&gt;Comme Font Awesome va continuer à évoluer, vous pouvez vous référer à la page de démarrage de Bulma ou de Font Awesome pour avoir la dernière version disponible.ConclusionEt voilà 5 étapes pour démarrer du bon pied avec Vue.js et Bulma&nbsp;!",
        "url": "//2020/05/03/vuejs-bulma/"
      }
      ,
    
      "2020-04-30-programmation-enfant": {
        "title": "Exercices de programmation pour enfant",
        "tags": "enfants, programmation",
        "date": "April 30, 2020",
        "author": "",
        "category": "",
        "content": "Quand on recherche des éléments pour enseigner la programmation, on tombe souvent sur la question des outils, voire du langage à choisir.Ainsi, on peut tomber sur ce repo GitHub qui recense une liste impressionnante d&#8217;outils.Mes enfants ont déjà appréhendé la programmation au travers des heures de code de code.org.Je voulais sortir du mode \"programmation par bloc\" à la Scratch pour aller vers un vrai langage de programmation.Quels exercices peut-on donner à des enfants de 8-10 ans pour appréhender la programmation sans être trop rébarbatif ?Cet article se veut agnostique par rapport au langage.Sachez cependant que mon choix s&#8217;est porté sur Python, ce qui va aussi me permettre de me dérouiller sur ce langage.Il existe probablement des tonnes de vidéo pour présenter Python. Une rapide recherche m&#8217;a conduit vers cette liste de vidéos qui constitue une bonne introduction.Finalement, même si au début, j&#8217;étais que convaincu que IDLE, l&#8217;éditeur par défaut ferait bien l&#8217;affaire, j&#8217;ai finalement installé Code with Mu.J&#8217;ai le secret espoir qu&#8217;on pourra utiliser un de ses modes (PyGame Zero ou Adafruit par exemple).Leçon 1 - IntroCommençons par les basiques&nbsp;: la présentation d&#8217;un ordinateur.Rien de tel que d&#8217;ouvrir le capot de son ordinateur portable pour y voir un disque dur, la RAM, la carte mère et deviner le processeur sous son radiateur.Il faudra également insister sur les interfaces&nbsp;:Les interfaces homme-machine&nbsp;: clavier, écran, sourisLes ports USB, Ethernet, etc.Leçon 2 - le clavierEcrire avec un clavier n&#8217;a absolument rien de naturel&nbsp;!Il conviendra donc&nbsp;:D&#8217;avoir une vague réflexion sur l&#8217;ordre des lettres sur un clavierD&#8217;apprendre à faire des minuscules et des majuscules (la touche Caps Lock reste optionnelle)De comprendre comment faire le caractère du haut ou de droite, respectivement avec Shift et Alt Gr, en comprenant que l&#8217;on peut garder enfoncé ces touches de modification (quel bonheur de voir nos enfants tenter d&#8217;appuyer sur Shift et une touche simultanément pour un résultat aléatoire)D&#8217;apprendre quelques symboles utiles à la programmation comme \"accolade\", \"dièse\", \"barre oblique\", etc.En bonus&nbsp;: Ctrl+C et Ctrl+V pour faire de nos bambins des consultants émérites&nbsp;!Leçon 3 - Les variablesA ce stade, vous allez me dire : \"toujours pas d&#8217;exercice de programmation !\". J&#8217;y arrive&nbsp;!La première chose à voir est certainement ce qu&#8217;est une variable pour stocker un paramètre ou le résultat d&#8217;une fonction.ExerciceJ&#8217;ai 12 bonbons. Il y a 2 enfants. En partageant équitablement, combien de bonbons chaque enfant aura&nbsp;?Et s&#8217;il y avait 3 enfants&nbsp;?NotionsVariables, Fonction d&#8217;affichage (print), Utilisation du mode interactif (REPL) vs. Création d&#8217;un programme dans un fichierLeçon 4 - boucle for et fonctionsExerciceAfficher la table de multiplication de 5, d&#8217;abord sans boucle for, puis avec.En faire une fonction pour afficher n&#8217;importe quelle table de multiplication.Afficher toutes les tables de multiplication de 1 à 10.NotionsOpérateurs (+, *), boucle for, fonctions.Les enfants connaissent les boucles \"répéter n fois\" dans la programmation par bloc.Bonus : afficher une chaîne formatée pour afficher le résultat de la multiplicationLeçon 5 - conjuguer les verbes du premier groupeExerciceDemander un verbe du premier groupe et le conjuguer au présent de l&#8217;indicatif, au futur, etc.Bonus : remonter une erreur si verbe \"aller\" ou verbe qui ne se termine pas par \"-er\" ou afficher \"j'\" à la place de \"je\" si verbe commençant par une voyelle.NotionsInteraction avec l&#8217;utilisation (input), concaténation de chaîne de caractères. Eventuellement, introduction aux conditions.Leçon 5 - les conditionsExerciceDéfinir un nombre hasard et tenter de le deviner avec le minimum de tentativesNotionsBoucle while, conditions, utilisation de module (pour random).Les enfants connaissent les boucles \"répéter tant que\" dans la programmation par bloc.Leçon 6 - Le système de fichierExerciceA la façon de Raymond Queneau pour ses Cent mille milliards de poèmes, lire un fichier texte qui contiendrait des vers et essayer de générer aléatoirement des poèmes.INFO: On peut en voir une adaptation Web par Magnus Bodin.NotionsUtilisation de module (pour random), lecture de fichier.ConclusionVoici un premier ensemble d&#8217;exercices qui doivent permettre d&#8217;aborder la base&nbsp;:Les variablesLes boucles for et whileLes conditions ifLes accès aux fichiersC&#8217;est suffisant pour aborder d&#8217;autres exercices comme le lièvre et la tortue.Il reste bien d&#8217;autres choses à voir mais cela pourra faire l&#8217;objet d&#8217;un autre article.",
        "url": "//2020/04/30/programmation-enfant/"
      }
      ,
    
      "2020-04-15-docker-windows-2019": {
        "title": "Des containers Linux sur Windows Server 2019",
        "tags": "docker, 2019, WindowsServer2019",
        "date": "April 15, 2020",
        "author": "",
        "category": "",
        "content": "IntroductionMicrosoft fournit de la doc pour installer Docker sur Windows Server 2019.Dès que l&#8217;on parle Linux, on est renvoyé vers de la doc pour Windows 10, qui pousse vers l&#8217;utilisation de Docker Desktop.En outre, la doc de Docker est référencée.Pour autant, je voulais une solution qui fonctionne sans Docker Desktop, qui requiert aujourd&#8217;hui un compte, ce qui ne convient pas dans un contexte \"Serveur\".Cette page est TRES fortement inspirée d&#8217;un article de Ben Thomas.Il s&#8217;agit en premier lieu d&#8217;une traduction. J&#8217;ai cependant adapté quelques étapes car cela n&#8217;a pas fonctionné pour moi.La procédure a été testée sur Windows Server 2019 1809, qui bénéficie d&#8217;un support long terme.Pour faire ce test sur une VM Azure, il faut s&#8217;assurer que la VM supporte la virtualisation imbriquée. La liste des types de VM supportant la virtualisation imbriquée est disponible sur le site de Microsoft.On pourra faire des tests avec les VM de série D_v3 ou Ds_v3 par exemple.Toutes les commandes PowerShell données ci-dessous sont à exécuter dans un prompt PowerShell En tant qu&#8217;administrateur.Installation d&#8217;Hyper-VL&#8217;installation d&#8217;Hyper-V peut faire simplement en PowerShell grâce à la ligne de commande suivante&nbsp;:Install-WindowsFeature -Name Hyper-V,Containers -IncludeAllSubFeature -IncludeManagementToolsEn principe, un redémarrage est nécessaire. Ceci étant, on peut attendre la fin de la procédure.Installation de DockerToujours en PowerShell&nbsp;:Install-Module -Name DockerMsftProvider -Repository PSGallery -ForceInstall-Package -Name docker -ProviderName DockerMsftProvider -Update -ForcePour une raison que j&#8217;ignore, docker vient avec une version 17.0.En forçant la mise à jour, on obtient une version 19.03, beaucoup plus acceptable.Groupe de sécuritéPar défaut, il faut être administrateur de la machine pour pouvoir communiquer avec le démon Docker, pour construire ou exécuter une image par exemple.Il est cependant possible d&#8217;autoriser un groupe spécifique, qu&#8217;on appellera \"docker\".Les commandes PowerShell ci-dessous permettent de créer le groupe, s&#8217;il n&#8217;existe pas déjà&nbsp;:$dockerGroup = \"docker\"$g = Get-LocalGroup $dockerGroup -EA 0if ($g) {   Write-Host \"Group $dockerGroup already exists\"}else {   Write-Host \"Group $dockerGroup does not exist\"   New-LocalGroup -Name \"docker\"}Activer le support des containers LinuxL&#8217;activation des containers Linux peut se faire avec la commande PowerShell suivante&nbsp;:[Environment]::SetEnvironmentVariable(\"LCOW_SUPPORTED\", \"1\", \"Machine\")Le moteur Docker sous Windows 2019 peut gérer des images Windows ou Linux. Pour exécuter des images Linux il est nécessaire de préciser le paramètre --platform=linux.Il est cependant possible de définir la plateforme par défaut avec la commande suivante&nbsp;:[Environment]::SetEnvironmentVariable(\"LCOW_API_PLATFORM_IF_OMITTED\", \"linux\", \"Machine\")Configuration du moteurMicrosoftdécrit toutes les options disponibles.Nous aurons besoin de&nbsp;:Activer le mode expérimentalConfigurer le groupe de sécuritéEncore une fois, la commande PowerShell$configfile = @\"{    \"experimental\": true,    \"group\": \"docker\"}\"@$configfile | Out-File -FilePath C:\\ProgramData\\docker\\config\\daemon.json -Encoding ascii -ForceNoyauUn noyau LinuxKit est nécessaire. Les commandes suivantes vont télécharger le noyau à partir de la dernière release et le pousser dans le bon répertoire.Ecraser le contenu du répertoire C:\\Program Files\\Linux Containers\\, notamment le fichier initrd faisait que rien ne fonctionnait.$Archive = Join-Path $env:TEMP \"release.zip\"Invoke-WebRequest -Uri \"https://github.com/linuxkit/lcow/releases/download/v4.14.35-v0.3.9/release.zip\" -UseBasicParsing -OutFile $Archive$target = Join-Path $env:TEMP \"Linux Containers\"md $targetExpand-Archive $Archive -DestinationPath $target$kernel = Join-Path $target \"kernel\"Copy-Item $kernel \"$Env:ProgramFiles\\Linux Containers\\.\"TestAprès redémarrage, vous devriez être en mesure d&#8217;exécuter la commande ci-dessous (sans être administrateur) et obtenir un prompt bash&nbsp;:docker run --rm -it ubuntu bash",
        "url": "//2020/04/15/docker-windows-2019/"
      }
      ,
    
      "2020-02-01-aci-grafana-influxdb": {
        "title": "Grafana et InfluxDB sur Azure Container Instances",
        "tags": "docker, aci, azure, influxdb, grafana, arm",
        "date": "February 1, 2020",
        "author": "",
        "category": "",
        "content": "Azure Container Instances (ACI) fait partie des nombreuses façons d&#8217;exécuter des containers sur Azure.Un des avantages d&#8217;ACI par rapport à App Service (présenté dans un précédent article) est lacapacité à exposer plusieurs ports.Ainsi, nous allons exposer un Grafana et une base InfluxDB.Grafana est une solution open source pour la création de tableau de bord.InfluxDB est son compagnon de choix pour le stockage de série temporelle (time series).Dans cet article, pour des raisons de simplicité, je n&#8217;exposerai pas Grafana en HTTPS.Il faudra se référer à mon précédent article Certificat Let&#8217;s Encrypt sur Azure Container Instances et NGINX pour la mise en place de HTTPS.La solutionComme évoqué, la solution tournera sur Azure Container Instances.Grafana a besoin d&#8217;une base de données pour sa configuration. Grafana supporte 3 bases de données&nbsp;:SQLiteMySQLPostgreSQLPour éviter de perdre la configuration à chaque redémarrage, la persistance des données est assurée par Azure Files.Malheureusement, à cause de certaines limitations, il n&#8217;a pas été possible de faire persister SQLite (embarqué par défaut dans Grafana) (une sombre histoire de verrou) ou d&#8217;utiliser l&#8217;image de base de PostgreSQL (une sombre histoire de propriétaire sur des fichiers).On utilisera donc l&#8217;image docker de MySQL.MySQL ne sera pas exposé sur InternetLes sources de données GrafanaIl est possible de fournir une liste de sources de données par fichier YAML.Nous allons utiliser ce mécanisme pour configurer automatiquement InfluxDB.Ainsi la configuration de la source de données en YAML sera&nbsp;:influxdb.yamlapiVersion: 1deleteDatasources:  - name: InfluxDB    orgId: 1datasources:  - name: InfluxDB    type: influxdb    access: proxy    orgId: 1    database: PERF    user: influxadmin    password: influxadmin    url: http://localhost:8086Ce fichier sera passé comme secret.On utilisera la fonction base64 d&#8217;ARM template pour passer le fichier YAML en secret.Note sur les groupes de container dans Azure Container InstancesAzure Container Instances utilisent un format de données \"propriétaire\" qui n&#8217;est ni Docker Compose, ni un fichier de déploiement Kubernetes.Le point important à garder en tête est que l&#8217;on va déclarer chaque port exposé par un container, puis ensuite quels sont les ports exposés par le groupe de container. Il n&#8217;est pas possible de changer le port exposé par un container par rapport au port du groupe (par une translation), comme rappelé dans la FAQ.La communication entre les containers se fait non pas en utilisant le nom du container (comme dans Docker Compose) mais localhost&nbsp;!Ainsi Grafana pointera dans sa configuration vers localhost:3036 pour sa base de données et localhost:8086 pour le cas d&#8217;InfluxDB.Automatisation du déploiementIl est possible d&#8217;utiliser du YAML ou de l&#8217;ARM template.Comme évoqué dans mon précédent article, je recommande fortement l&#8217;utilisation d&#8217;ARM template qui va permettre de rendre dynamique certains paramètres de déploiement.Pour autant, je vais limiter les paramètres possibles.Variables d&#8217;environnementLes variables d&#8217;environnement que nous allons utiliser sont décrites ci-dessous.Table 1. MySQLNomDescriptionMYSQL_DATABASENom de la base crée au démarrageMYSQL_USER, MYSQL_PASSWORDNom de l&#8217;utilisateur et mot de passe propriétaire de la baseMYSQL_RANDOM_ROOT_PASSWORDVa générer un mot de passe aléatoire pour l&#8217;utilisateur rootD&#8217;autres variables d&#8217;environnement sont disponibles et sont décrites sur la page de l&#8217;image Docker de MySQL.Table 2. InfluxDBNomDescriptionINFLUXDB_DBNom de la base crée au démarrageINFLUXDB_ADMIN_USER, INFLUXDB_ADMIN_PASSWORDNom de l&#8217;utilisateur et mot de passe administrateur de la baseD&#8217;autres variables d&#8217;environnement sont disponibles et sont décrites sur la page de l&#8217;image Docker d&#8217;InfluxDB.Grafana dispose d&#8217;un mécanisme très extensible qui permet de définir n&#8217;importe quel paramètre à partir de variables d&#8217;environnement.Table 3. GrafanaNomDescriptionGF_DATABASE_URLURL de connexion à MySQLGF_SECURITY_ADMIN_PASSWORDMot de passe de l&#8217;utilisateur admin (cela évitera de passer dans l&#8217;assistant de configuration)Dans mon précédent article, j&#8217;avais également utilisé la variable GF_SERVER_DOMAIN pour configurer Grafana derrière NGINX.ARM templateL&#8217;ARM template et les paramètres sont définis ci-dessous.grafana.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"type\": \"securestring\",            \"metadata\": {                \"description\": \"Password for Grafana admin.\"            }        },        \"containerGroupName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Container Group name.\"            }        },        \"dnsLabel\": {            \"type\": \"string\",            \"defaultValue\": \"\",            \"metadata\": {                \"description\": \"DNS label used to by the container group. The FQDN is &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io\"            }        },        \"storageAccountName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Name of the Storage Account\"            }        },        \"storageAccountType\": {            \"type\": \"string\",            \"defaultValue\": \"Standard_LRS\",            \"allowedValues\": [                \"Standard_LRS\",                \"Standard_GRS\",                \"Standard_ZRS\",                \"Premium_LRS\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"accessTier\": {            \"type\": \"string\",            \"defaultValue\": \"Hot\",            \"allowedValues\": [                \"Hot\",                \"Cool\"            ],            \"metadata\": {                \"description\": \"The access tier used for billing.\"            }        },        \"storageAccountKind\": {            \"type\": \"string\",            \"defaultValue\": \"StorageV2\",            \"allowedValues\": [                \"StorageV2\",                \"Storage\",                \"BlobStorage\",                \"FileStorage\",                \"BlockBlobStorage\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"advancedThreatProtectionEnabled\": {            \"type\": \"bool\",            \"defaultValue\": false,            \"metadata\": {                \"description\": \"Enable or disable Advanced Threat Protection.\"            }        },        \"shares\": {            \"type\": \"array\",            \"metadata\": {                \"description\": \"List of the file share names.\"            }        },        \"location\": {            \"type\": \"string\",            \"defaultValue\": \"[resourceGroup().location]\",            \"metadata\": {                \"description\": \"The region to deploy the resources into\"            }        },        \"tagValues\": {            \"type\": \"object\",            \"defaultValue\": {            }        }    },    \"variables\": {        \"dnsLabel\": \"[if(empty(parameters('dnsLabel')), parameters('containerGroupName'), parameters('dnsLabel'))]\",        \"fqdn\": \"[toLower(concat(variables('dnsLabel'),'.',replace(parameters('location'), ' ', ''),'.azurecontainer.io'))]\"    },    \"resources\": [        {            \"type\": \"Microsoft.Storage/storageAccounts\",            \"name\": \"[parameters('storageAccountName')]\",            \"location\": \"[parameters('location')]\",            \"apiVersion\": \"2018-07-01\",            \"sku\": {                \"name\": \"[parameters('storageAccountType')]\"            },            \"kind\": \"[parameters('storageAccountKind')]\",            \"properties\": {                \"accessTier\": \"[parameters('accessTier')]\",                \"encryption\": {                    \"keySource\": \"Microsoft.Storage\",                    \"services\": {                        \"blob\": {                            \"enabled\": true                        },                        \"file\": {                            \"enabled\": true                        }                    }                },                \"supportsHttpsTrafficOnly\": true            },            \"resources\": [                {                    \"condition\": \"[parameters('advancedThreatProtectionEnabled')]\",                    \"type\": \"providers/advancedThreatProtectionSettings\",                    \"name\": \"Microsoft.Security/current\",                    \"apiVersion\": \"2017-08-01-preview\",                    \"dependsOn\": [                        \"[resourceId('Microsoft.Storage/storageAccounts/', parameters('storageAccountName'))]\"                    ],                    \"properties\": {                        \"isEnabled\": true                    }                }            ]        },        {            \"type\": \"Microsoft.Storage/storageAccounts/fileServices/shares\",            \"apiVersion\": \"2019-04-01\",            \"name\": \"[concat(parameters('storageAccountName'), '/default/', parameters('shares')[copyIndex()])]\",            \"copy\": {                \"name\": \"sharecopy\",                \"count\": \"[length(parameters('shares'))]\"            },            \"dependsOn\": [                \"[parameters('storageAccountName')]\"            ]        },        {            \"name\": \"[parameters('containerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"dependsOn\": [                \"sharecopy\"            ],            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"properties\": {                \"containers\": [                    {                        \"name\": \"mysql\",                        \"properties\": {                            \"image\": \"mysql\",                            \"environmentVariables\": [                                {                                    \"name\": \"MYSQL_USER\",                                    \"value\": \"grafana\"                                },                                {                                    \"name\": \"MYSQL_PASSWORD\",                                    \"secureValue\": \"grafana\"                                },                                {                                    \"name\": \"MYSQL_RANDOM_ROOT_PASSWORD\",                                    \"value\": \"yes\"                                },                                {                                    \"name\": \"MYSQL_DATABASE\",                                    \"value\": \"grafana\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 3306                                },                                {                                    \"port\": 443                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"mysql-data\",                                    \"mountPath\": \"/var/lib/mysql\"                                }                            ]                        }                    },                                        {                        \"name\": \"influxdb\",                        \"properties\": {                            \"image\": \"influxdb\",                            \"environmentVariables\": [                                {                                    \"name\": \"INFLUXDB_DB\",                                    \"value\": \"PERF\"                                },                                {                                    \"name\": \"INFLUXDB_ADMIN_USER\",                                    \"value\": \"influxadmin\"                                },                                {                                    \"name\": \"INFLUXDB_ADMIN_PASSWORD\",                                    \"secureValue\": \"influxadmin\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 8086                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"influxdb-volume\",                                    \"mountPath\": \"/var/lib/influxdb\"                                }                            ]                        }                    },                    {                        \"name\": \"grafana\",                        \"properties\": {                            \"image\": \"grafana/grafana\",                            \"ports\": [                                {                                    \"port\": 3000                                }                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"GF_SECURITY_ADMIN_PASSWORD\",                                    \"secureValue\": \"[parameters('grafanaAdminPassword')]\"                                },                                {                                    \"name\": \"GF_DATABASE_URL\",                                    \"secureValue\": \"mysql://grafana:grafana@localhost:3306/grafana\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 1,                                    \"memoryInGb\": 0.5                                }                            },                            \"volumeMounts\": [                                {                                    \"name\": \"grafana-volume\",                                    \"mountPath\": \"/var/lib/grafana\"                                },                                {                                    \"name\": \"grafana-provisioning\",                                    \"mountPath\": \"/etc/grafana/provisioning/datasources\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"OnFailure\",                \"ipAddress\": {                    \"type\": \"Public\",                    \"ports\": [                        {                            \"port\": 3000                        },                        {                            \"port\": 8086                        }                    ],                    \"dnsNameLabel\": \"[variables('dnsLabel')]\"                },                \"volumes\": [                    {                        \"name\": \"mysql-data\",                        \"azureFile\": {                            \"shareName\": \"mysql-data\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"influxdb-volume\",                        \"azureFile\": {                            \"shareName\": \"influxdb-volume\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"grafana-volume\",                        \"azureFile\": {                            \"shareName\": \"grafana-volume\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"grafana-provisioning\",                        \"secret\": {                            \"influxdb.yaml\": \"[base64('apiVersion: 1deleteDatasources:  - name: InfluxDB    orgId: 1datasources:  - name: InfluxDB    type: influxdb    access: proxy    orgId: 1    database: PERF    user: influxadmin    password: influxadmin    url: http://localhost:8086                            ')]\"                        }                    }                ]            }        }    ],    \"outputs\": {    }}grafana.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"value\": \"grafanapwd\"        },        \"containerGroupName\": {            \"value\": \"test-grafana-influxdb\"        },        \"storageAccountName\": {            \"value\": \"stotestacmenginx\"        },        \"shares\": {            \"value\": [                \"mysql-data\",                \"influxdb-volume\",                \"grafana-volume\"            ]        },        \"location\": {            \"value\": \"West Europe\"        }    }}Il est possible de déployer par PowerShell&nbsp;: New-AzResourceGroupDeployment -ResourceGroupName $rg -TemplateFile .\\influxdb-grafana.json -TemplateParameterFile .\\influxdb-grafana.parameters.json -VerboseEgalement, en Az CLI&nbsp;:az group deployment create --resource-group $rg --template-file ./influxdb-grafana.json --parameters @influxdb-grafana.parameters.json --handle-extended-json-formatIl faudra bien penser au paramètre --handle-extended-json-format qui apporte le support du multiligne en JSON.ConclusionEn quelques minutes, il est possible de monter un Grafana et une base InfluxDB.Les cas d&#8217;usage d&#8217;InfluxDB et Grafana ne manquent pas&nbsp;: IoT, surveillance applicative, etc.Un cas d&#8217;utilisation pourrait être aussi des tests de charge avec Locust.A suivre&#8230;&#8203;",
        "url": "//2020/02/01/aci-grafana-influxdb/"
      }
      ,
    
      "2020-01-30-aci-letsencrypt-nginx": {
        "title": "Certificat Let&amp;#8217;s Encrypt sur Azure Container Instances et NGINX",
        "tags": "docker, aci, azure, nginx, letsencrypt, arm",
        "date": "January 30, 2020",
        "author": "",
        "category": "",
        "content": "Azure Container Instances fait partie des nombreuses façons d&#8217;exécuter des containers sur Azure.J&#8217;ai déjà présenté dans un précédent article l&#8217;exécution de container sur App Service. Cette méthode expose automatiquement une URL en azurewebsites.net reconnue par les navigateurs. Malheureusement, on ne peut exposer qu&#8217;un port.Microsoft propose déjà une méthode à base de NGINX pour exposer un point de terminaison en SSL. Malheureusement, la méthode décrite se base sur des certificats générés au préalable, voire auto-signés si on suit la doc&nbsp;!Point d&#8217;attention sur Azure Files et client Let&#8217;s EncryptAzure Files est utilisé conjointant avec Azure Container Instances pour assurer la persistance des données. Les disques managés ne sont pas supportés.De fait, Azure Files souffre de quelques limitations comme le non-support des liens symboliques, la gestion des droits POSIX, etc.Mon premier choix pour l&#8217;enrôlement de certificat s&#8217;était porté sur certbot - le client recommandé par Let&#8217;s Encrypt - et son image Docker.Malheureusement, il s&#8217;est avéré que certbot utilise des liens symboliques pour gérer les certificats.Let&#8217;s Encrypt propose une longue liste de client.Je me suis donc tourné vers acme.sh qui propose égalementune image Docker.Les étapesLe processus complet va se découper en 2 grandes étapes&nbsp;:L&#8217;émission du certificatL&#8217;utilisation du certificatEtape 1&nbsp;: émission du certificatCette étape va consister en&nbsp;:La création du compte de stockage (Storage Account) et des partages associés (Files). Au moins 2 partages doivent être créés pour&nbsp;:La config d&#8217;acme.shLes certificats à utiliser avec NGINX ultérieurementLa création de 2 répertoires nécessaires à acme.shLa génération du certificat en utilisant le mode autonome d&#8217;acme.shL&#8217;installation des certificats pour l&#8217;utilisation par NGINXTout a été automatisé avec un ARM template.Ainsi, l&#8217;ARM template permet de&nbsp;:Créer les ressources AzureCréation d&#8217;un Azure Container Instance s&#8217;appuyant sur l&#8217;image microsoft/azure-cli pour créer les répertoires.Cela correspond à exécuter commande Az CLI az storage directory create --name certs --share-name acme-certCréation d&#8217;un Azure Container Instance avec l&#8217;image neilpang/acme.sh pour l&#8217;émission du certificat.Cela revient à exécuter la commande acme.sh --issue --standalone -d $FQDNCréation d&#8217;un Azure Container Instance avec l&#8217;image neilpang/acme.sh pour l&#8217;installation du certificat.Le FQDN utilisable dans ce contexte est de la forme &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io, dnsLabel étant un paramètre que l&#8217;on peut définir.Ci-dessous l&#8217;ARM template utilisé&nbsp;:certificate.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"containerGroupName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Container Group name.\"            }        },        \"dnsLabel\": {            \"type\": \"string\",            \"defaultValue\": \"\",            \"metadata\": {                \"description\": \"DNS label used to by the container group. The FQDN is &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io\"            }        },        \"storageAccountName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Name of the Storage Account\"            }        },        \"storageAccountType\": {            \"type\": \"string\",            \"defaultValue\": \"Standard_LRS\",            \"allowedValues\": [                \"Standard_LRS\",                \"Standard_GRS\",                \"Standard_ZRS\",                \"Premium_LRS\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"accessTier\": {            \"type\": \"string\",            \"defaultValue\": \"Hot\",            \"allowedValues\": [                \"Hot\",                \"Cool\"            ],            \"metadata\": {                \"description\": \"The access tier used for billing.\"            }        },        \"storageAccountKind\": {            \"type\": \"string\",            \"defaultValue\": \"StorageV2\",            \"allowedValues\": [                \"StorageV2\",                \"Storage\",                \"BlobStorage\",                \"FileStorage\",                \"BlockBlobStorage\"            ],            \"metadata\": {                \"description\": \"Storage Account type\"            }        },        \"advancedThreatProtectionEnabled\": {            \"type\": \"bool\",            \"defaultValue\": false,            \"metadata\": {                \"description\": \"Enable or disable Advanced Threat Protection.\"            }        },        \"shares\": {            \"type\": \"array\",            \"metadata\": {                \"description\": \"List of the file share names.\"            }        },        \"location\": {            \"type\": \"string\",            \"defaultValue\": \"[resourceGroup().location]\",            \"metadata\": {                \"description\": \"The region to deploy the resources into\"            }        },        \"tagValues\": {            \"type\": \"object\",            \"defaultValue\": {            }        }    },    \"variables\": {        \"createFolderPrivateContainerGroupName\": \"[concat(parameters('containerGroupName'),'-cli-private')]\",        \"createFolderCertsContainerGroupName\": \"[concat(parameters('containerGroupName'),'-cli-certs')]\",        \"installContainerGroupName\": \"[concat(parameters('containerGroupName'),'-install')]\",        \"dnsLabel\": \"[if(empty(parameters('dnsLabel')), parameters('containerGroupName'), parameters('dnsLabel'))]\",        \"fqdn\": \"[toLower(concat(variables('dnsLabel'),'.',replace(parameters('location'), ' ', ''),'.azurecontainer.io'))]\"    },    \"resources\": [        {            \"type\": \"Microsoft.Storage/storageAccounts\",            \"name\": \"[parameters('storageAccountName')]\",            \"location\": \"[parameters('location')]\",            \"apiVersion\": \"2018-07-01\",            \"sku\": {                \"name\": \"[parameters('storageAccountType')]\"            },            \"kind\": \"[parameters('storageAccountKind')]\",            \"properties\": {                \"accessTier\": \"[parameters('accessTier')]\",                \"encryption\": {                    \"keySource\": \"Microsoft.Storage\",                    \"services\": {                        \"blob\": {                            \"enabled\": true                        },                        \"file\": {                            \"enabled\": true                        }                    }                },                \"supportsHttpsTrafficOnly\": true            },            \"resources\": [                {                    \"condition\": \"[parameters('advancedThreatProtectionEnabled')]\",                    \"type\": \"providers/advancedThreatProtectionSettings\",                    \"name\": \"Microsoft.Security/current\",                    \"apiVersion\": \"2017-08-01-preview\",                    \"dependsOn\": [                        \"[resourceId('Microsoft.Storage/storageAccounts/', parameters('storageAccountName'))]\"                    ],                    \"properties\": {                        \"isEnabled\": true                    }                }            ]        },        {            \"type\": \"Microsoft.Storage/storageAccounts/fileServices/shares\",            \"apiVersion\": \"2019-04-01\",            \"name\": \"[concat(parameters('storageAccountName'), '/default/', parameters('shares')[copyIndex()])]\",            \"copy\": {                \"name\": \"sharecopy\",                \"count\": \"[length(parameters('shares'))]\"            },            \"dependsOn\": [                \"[parameters('storageAccountName')]\"            ]        },        {            \"name\": \"[variables('createFolderCertsContainerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"dependsOn\": [                \"sharecopy\"            ],            \"properties\": {                \"containers\": [                    {                        \"name\": \"create-folder-private\",                        \"properties\": {                            \"image\": \"microsoft/azure-cli\",                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.1,                                    \"memoryInGb\": 0.1                                }                            },                            \"command\": [                                \"az\",                                \"storage\",                                \"directory\",                                \"create\",                                \"--name\",                                \"certs\",                                \"--share-name\",                                \"acme-cert\"                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"AZURE_STORAGE_KEY\",                                    \"value\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                                },                                {                                    \"name\": \"AZURE_STORAGE_ACCOUNT\",                                    \"value\": \"[parameters('storageAccountName')]\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\"            }        },        {            \"name\": \"[variables('createFolderPrivateContainerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"dependsOn\": [                \"sharecopy\"            ],            \"properties\": {                \"containers\": [                    {                        \"name\": \"create-folder-private\",                        \"properties\": {                            \"image\": \"microsoft/azure-cli\",                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.1,                                    \"memoryInGb\": 0.1                                }                            },                            \"command\": [                                \"az\",                                \"storage\",                                \"directory\",                                \"create\",                                \"--name\",                                \"private\",                                \"--share-name\",                                \"acme-cert\"                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"AZURE_STORAGE_KEY\",                                    \"value\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                                },                                {                                    \"name\": \"AZURE_STORAGE_ACCOUNT\",                                    \"value\": \"[parameters('storageAccountName')]\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\"            }        },        {            \"name\": \"[parameters('containerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"dependsOn\": [                \"[variables('createFolderPrivateContainerGroupName')]\",                \"[variables('createFolderCertsContainerGroupName')]\"            ],            \"properties\": {                \"containers\": [                    {                        \"name\": \"acme-sh\",                        \"properties\": {                            \"image\": \"neilpang/acme.sh\",                            \"command\": [                                \"--issue\",                                \"--standalone\",                                \"-d\",                                \"[variables('fqdn')]\"                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.1,                                    \"memoryInGb\": 0.1                                }                            },                            \"ports\": [                                {                                    \"port\": 80                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"acme-config\",                                    \"mountPath\": \"/acme.sh/\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\",                \"ipAddress\": {                    \"type\": \"Public\",                    \"ports\": [                        {                            \"port\": 80                        }                    ],                    \"dnsNameLabel\": \"[variables('dnsLabel')]\"                },                \"volumes\": [                    {                        \"name\": \"acme-config\",                        \"azureFile\": {                            \"shareName\": \"acme-config\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                        }                    }                ]            }        },        {            \"name\": \"[variables('installContainerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"dependsOn\": [                \"[parameters('containerGroupName')]\"            ],            \"properties\": {                \"containers\": [                    {                        \"name\": \"acme-sh\",                        \"properties\": {                            \"image\": \"neilpang/acme.sh\",                            \"command\": [                                \"--install-cert\",                                \"--key-file\",                                \"/etc/pki/tls/private/key.pem\",                                \"--fullchain-file\",                                \"/etc/pki/tls/certs/fullchain.pem\",                                \"-d\",                                \"[variables('fqdn')]\"                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.1,                                    \"memoryInGb\": 0.1                                }                            },                            \"volumeMounts\": [                                {                                    \"name\": \"acme-config\",                                    \"mountPath\": \"/acme.sh/\"                                },                                {                                    \"name\": \"acme-cert\",                                    \"mountPath\": \"/etc/pki/tls/\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\",                \"volumes\": [                    {                        \"name\": \"acme-cert\",                        \"azureFile\": {                            \"shareName\": \"acme-cert\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"acme-config\",                        \"azureFile\": {                            \"shareName\": \"acme-config\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"                        }                    }                ]            }        }    ],    \"outputs\": {    }}Et les paramètres associés&nbsp;:certificate.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"containerGroupName\": {            \"value\": \"testacmenginx\"        },        \"storageAccountName\": {            \"value\": \"stotestacmenginx\"        },        \"storageAccountType\": {            \"value\": \"Standard_LRS\"        },        \"accessTier\": {            \"value\": \"Hot\"        },        \"storageAccountKind\": {            \"value\": \"StorageV2\"        },        \"advancedThreatProtectionEnabled\": {            \"value\": false        },        \"shares\": {            \"value\": [                \"acme-config\",                \"acme-cert\"            ]        },        \"tagValues\": {            \"value\": {}        },        \"location\": {            \"value\": \"West Europe\"        }    }}Au moment de la rédaction de cet article, Azure Container Instances n&#8217;est pas disponible en France. J&#8217;ai donc forcé l&#8217;utilisation d&#8217;Europe de l&#8217;Ouest.Il suffit alors de déployer cet ARM template et ses paramètres. Je recommande l&#8217;utilisation de la cmdlet PowerShell New-AzResourceGroupDeployment.Une fois le déploiement réalisé, il faut supprimer les ACI manuellement&nbsp;:rg=XXXcn=testacmenginxaz container delete -g $rg -y -n ${cn}az container delete -g $rg -y -n ${cn}-cli-privateaz container delete -g $rg -y -n ${cn}-cli-certsaz container delete -g $rg -y -n ${cn}-installEtape 2&nbsp;: utilisation des certificats par NGINXDans cette étape, nous allons déployer un NGINX avec SSL.La configuration SSL a été renforcée afin de viser un A+ sur SSL Labs.Voici ce que donne la configuration NGINX&nbsp;:site.templateserver {    listen 80;    server_name ${NGINX_HOST};    server_tokens off;    location / {        return 301 https://$host$request_uri;    }}server {    listen 443 ssl;    server_name ${NGINX_HOST};    server_tokens off;    ssl_certificate /etc/pki/tls/certs/fullchain.pem;    ssl_certificate_key /etc/pki/tls/private/key.pem;    ssl_session_cache shared:le_nginx_SSL:1m;    ssl_session_timeout 1d;    ssl_session_tickets off;    ssl_protocols TLSv1.3 TLSv1.2;    ssl_prefer_server_ciphers on;    #ssl_ciphers \"EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\";    ssl_ciphers EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA512:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:ECDH+AESGCM:ECDH+AES256:DH+AESGCM:DH+AES256:RSA+AESGCM:!aNULL:!eNULL:!LOW:!RC4:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS;    ssl_ecdh_curve secp384r1;    ssl_stapling on;    ssl_stapling_verify on;    add_header Strict-Transport-Security \"max-age=15768000; includeSubdomains; preload;\" ;    #add_header Content-Security-Policy \"default-src 'none'; frame-ancestors 'none'; script-src 'self'; img-src 'self'; style-src 'self'; base-uri 'self'; form-action 'self';\";    add_header Referrer-Policy \"no-referrer, strict-origin-when-cross-origin\";    add_header X-Frame-Options SAMEORIGIN;    add_header X-Content-Type-Options nosniff;    add_header X-XSS-Protection \"1; mode=block\";    location / {        proxy_pass  http://localhost:3000;        proxy_set_header    Host                $http_host;        proxy_set_header    X-Real-IP           $remote_addr;        proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;    }}Cette configuration sera passée comme un secret au container NGINX. Pour pouvoir le passer en secret, il faut alors l&#8217;encoder en base64. J&#8217;ai utilisé mon Windows Subsystem for Linux (WSL) mais il existe d&#8217;autres façons d&#8217;encoder en base64. Sous linux, la commande est&nbsp;:base64 -w 0 mysite.templateJ&#8217;ai introduit la variable ${NGINX_HOST} qui sera remplacée au démarrage. Pour ce faire, j&#8217;utilise la commande envsubst, que je n&#8217;ai pas inventée car donnée par la documentation de l&#8217;image Docker de NGINX.2 petites choses à noter cependant&nbsp;:Par défaut envsubst va substituer toutes les variables de la forme $VAR ou ${VAR}.Du coup, dans ma configuration, $http_host était remplacée&#8230;&#8203; par une chaîne vide. J&#8217;ai donc restreint la substitution à la seule variable ${NGINX_HOST}En Docker, il est possible de passer des commandes en Shell Form ou Exec Form. Je recommande cet article pour bien comprendre la différence.Azure Container Instances ne supporte que la forme Exec.Or, pour le démarrage de NGINX, j&#8217;avais besoin d&#8217;une séquence de programme pour réaliser la substitution et démarrer le démon.J&#8217;ai donc triché en utilisant la forme Exec et la commande sh -c&nbsp;:\"command\": [    \"sh\",    \"-c\",    \"envsubst '$NGINX_HOST' &lt; /tmp/nginx/mysite.template &gt; /etc/nginx/conf.d/default.conf &amp;&amp; exec nginx -g 'daemon off;'\"]Comme à l&#8217;étape 1, le déploiement se fait avec un ARM template.Derrière le NGINX, j&#8217;ai mis un grafana dont le mot de passe admin est fixé par paramètre.nginx.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"type\": \"securestring\",            \"metadata\": {                \"description\": \"Password for Grafana admin.\"            }        },        \"containerGroupName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Container Group name.\"            }        },        \"dnsLabel\": {            \"type\": \"string\",            \"defaultValue\": \"\",            \"metadata\": {                \"description\": \"DNS label used to by the container group. The FQDN is &lt;dnsLabel&gt;.&lt;region&gt;.azurecontainer.io\"            }        },        \"storageAccountName\": {            \"type\": \"string\",            \"metadata\": {                \"description\": \"Name of the Storage Account\"            }        },        \"location\": {            \"type\": \"string\",            \"defaultValue\": \"[resourceGroup().location]\",            \"metadata\": {                \"description\": \"The region to deploy the resources into\"            }        },        \"tagValues\": {            \"type\": \"object\",            \"defaultValue\": {            }        }    },    \"variables\": {        \"dnsLabel\": \"[if(empty(parameters('dnsLabel')), parameters('containerGroupName'), parameters('dnsLabel'))]\",        \"fqdn\": \"[toLower(concat(variables('dnsLabel'),'.',replace(parameters('location'), ' ', ''),'.azurecontainer.io'))]\"    },    \"resources\": [        {            \"name\": \"[parameters('containerGroupName')]\",            \"type\": \"Microsoft.ContainerInstance/containerGroups\",            \"apiVersion\": \"2018-10-01\",            \"location\": \"[parameters('location')]\",            \"properties\": {                \"containers\": [                    {                        \"name\": \"nginx\",                        \"properties\": {                            \"image\": \"nginx:alpine\",                            \"command\": [                                \"sh\",                                \"-c\",                                \"envsubst '$NGINX_HOST' &lt; /tmp/nginx/mysite.template &gt; /etc/nginx/conf.d/default.conf &amp;&amp; exec nginx -g 'daemon off;'\"                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"NGINX_HOST\",                                    \"value\": \"[variables('fqdn')]\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 0.5,                                    \"memoryInGb\": 0.5                                }                            },                            \"ports\": [                                {                                    \"port\": 80                                },                                {                                    \"port\": 443                                }                            ],                            \"volumeMounts\": [                                {                                    \"name\": \"acme-cert\",                                    \"mountPath\": \"/etc/pki/tls/\"                                },                                {                                    \"name\": \"nginx-config\",                                    \"mountPath\": \"/tmp/nginx/\"                                }                            ]                        }                    },                    {                        \"name\": \"grafana\",                        \"properties\": {                            \"image\": \"grafana/grafana\",                            \"ports\": [                                {                                    \"port\": 3000                                }                            ],                            \"environmentVariables\": [                                {                                    \"name\": \"GF_SECURITY_ADMIN_PASSWORD\",                                    \"value\": \"[parameters('grafanaAdminPassword')]\"                                },                                {                                    \"name\": \"GF_SERVER_DOMAIN\",                                    \"value\": \"[variables('fqdn')]\"                                }                            ],                            \"resources\": {                                \"requests\": {                                    \"cpu\": 1,                                    \"memoryInGb\": 1                                }                            },                            \"volumeMounts\": [                                {                                    \"name\": \"acme-cert\",                                    \"mountPath\": \"/etc/pki/tls/\"                                },                                {                                    \"name\": \"nginx-config\",                                    \"mountPath\": \"/etc/nginx/conf.d/\"                                }                            ]                        }                    }                ],                \"osType\": \"Linux\",                \"restartPolicy\": \"Never\",                \"ipAddress\": {                    \"type\": \"Public\",                    \"ports\": [                        {                            \"port\": 80                        },                        {                            \"port\": 443                        }                    ],                    \"dnsNameLabel\": \"[variables('dnsLabel')]\"                },                \"volumes\": [                    {                        \"name\": \"acme-cert\",                        \"azureFile\": {                            \"shareName\": \"acme-cert\",                            \"storageAccountName\": \"[parameters('storageAccountName')]\",                            \"storageAccountKey\": \"[listKeys(resourceId('Microsoft.Storage/storageAccounts',parameters('storageAccountName')),'2017-10-01').keys[0].value]\"                        }                    },                    {                        \"name\": \"nginx-config\",                        \"secret\": {                            \"mysite.template\": \"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\"                        }                    }                ]            }        }    ],    \"outputs\": {    }}nginx.parameters.json{    \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",    \"contentVersion\": \"1.0.0.0\",    \"parameters\": {        \"grafanaAdminPassword\": {            \"value\": \"secretPwd\"        },        \"containerGroupName\": {            \"value\": \"testacmenginx\"        },        \"storageAccountName\": {            \"value\": \"stotestacmenginx\"        },        \"tagValues\": {            \"value\": {}        },        \"location\": {            \"value\": \"West Europe\"        }    }}Un nouveau, l&#8217;on peut déployer avec la cmdlet PowerShell New-AzResourceGroupDeployment.Et voilà&nbsp;:ConclusionL&#8217;utilisation d&#8217;acme.sh m&#8217;a permis de récupérer un certificat Let&#8217;s Encrypt et l&#8217;utiliser dans NGINX qui agit comme reverse-proxy pour d&#8217;autres applications (grafana dans mon exemple).Je n&#8217;ai pas abordé la problématique de renouvellement du certificat.Les certificats Let&#8217;s Encrypt n&#8217;ont une durée de vie que de 90 jours.Cela étant, Azure Container Instances n&#8217;est probablement pas fait pour des programmes \"permanents\", donc 90 jours est largement suffisant.Il est possible de s&#8217;appuyer sur des fichiers YAML pour le déploiement d&#8217;Azure Container Instances.Cela s&#8217;avère très utile en phase de déploiement mais complétement inutile en phase d&#8217;industrialisation.En effet, il n&#8217;est pas possible d&#8217;utiliser des variables, des paramètres ou faire référence à d&#8217;autres ressources comme j&#8217;ai pu le faire dans l&#8217;ARM template.Ainsi, dans l&#8217;ARM template, l&#8217;utilisation de l&#8217;image microsoft/azure-cli se fait avec une référence aux clés du compte de stockage:{    \"name\": \"AZURE_STORAGE_KEY\",    \"value\": \"[listKeys(parameters('storageAccountName'),'2017-10-01').keys[0].value]\"}Ou même, la commande de génération de certificat avec l&#8217;image neilpang/acme.sh qui utilise une variable de mon ARM template:\"command\": [    \"--issue\",    \"--standalone\",    \"-d\",    \"[variables('fqdn')]\"]La référence ARM est relativement bien documentée.Il ne faut donc pas hésiter à l&#8217;utiliser&nbsp;!",
        "url": "//2020/01/30/aci-letsencrypt-nginx/"
      }
      ,
    
      "2020-01-12-acr-repositories-devops": {
        "title": "Utilisation des autorisations d&amp;#8217;étendue de référentiel dans ACR avec Azure DevOps",
        "tags": "docker, azure-devops, azure, acr, pipeline, yaml",
        "date": "January 12, 2020",
        "author": "",
        "category": "",
        "content": "Dans un précédent article, j&#8217;expliquais comment créer une autorisation d&#8217;étendue de référentiel dans ACR. Nous allons voir comment l&#8217;utiliser dans Azure DevOps.Création d&#8217;une jeton d&#8217;accèsComme nous l&#8217;avions vu, nous pouvons créer un jeton d&#8217;accès à partir d&#8217;une scope map existante ou en un créer directement avec la scope map.Suivant la deuxième option, voici la commande&nbsp;:az acr token create -n test-azure-devops -r testscopemap --repository samples/go content/write content/readCréation d&#8217;une connexion de service dans Azure DevOpsDans Azure DevOps, dans votre projet, aller dans les settings en cliquant sur la route dentée en bas à droite .Dans le menu, choisir \"Service Connections\"&nbsp;:.Si vous êtes comme moi et qu&#8217;il s&#8217;agit de votre premier Service Connection, cliquer sur \"Create service connection\"&nbsp;:.Chercher les connexions de type \"Docker\" et choisir \"Docker Registry\"&nbsp;:.Renseigner les informations&nbsp;:Docker Registry&nbsp;: de la forme https://&lt;nom de l&#8217;ACR&gt;.azurecr.ioDocker ID&nbsp;: le nom du jeton d&#8217;accès précédemment crééDocker Password&nbsp;: Un des 2 mots de passe du  jeton d&#8217;accès précédemment crééService connection name&nbsp;: A noter pour la suite. J&#8217;ai donné le nom du jeton d&#8217;accès mais ce n&#8217;est pas obligatoire.Après avoir cliquer sur \"Save\", la page des connexions d&#8217;affiche&nbsp;:.Création du pipeline dans Azure DevOpsDans le menu de gauche, dans le menu \"Pipelines\"&nbsp;:.Si comme moi, vous créez le premier pipeline, alors cliquer sur \"Create Pipeline\"&nbsp;:.Mon projet est dans Azure Repos Git, adosser à mon projet.Si vous êtes comme dans mon cas, choisir \"Azure Repos Git YAML\"&nbsp;:.Choisir votre repository git&nbsp;:.Choisir un \"starter pipeline\"&nbsp;:.Il est alors possible de renseigner son pipelineazure-pipelines.ymltrigger:- masterpool:  vmImage: 'ubuntu-latest'variables:  imageName: 'samples/go'  dockerRegistryServiceConnection: test-azure-devopssteps:- task: Docker@2  displayName: Login to ACR  inputs:    command: login    containerRegistry: $(dockerRegistryServiceConnection)- task: Docker@2  displayName: Build and push an image to container registry  inputs:    command: buildAndPush    repository: $(imageName)    containerRegistry: $(dockerRegistryServiceConnection)La première tâche va permettre de se connecter vis-à-vis de l&#8217;ACR en utilisant le jeton d&#8217;accès précédemment créé et les droits associés.La deuxième tâche construit l&#8217;image et pousse l&#8217;image dans l&#8217;ACR.Cliquer sur \"Save and Run\".Tout est vert&nbsp;!Après exécution, on peut voir que la connexion s&#8217;est bien passée ainsi que la construction de l&#8217;image et le transfert vers l&#8217;ACR&nbsp;:.On peut vérifier dans l&#8217;ACR le référentiel ainsi créé&nbsp;:.",
        "url": "//2020/01/12/acr-repositories-devops/"
      }
      ,
    
      "2020-01-10-acr-repositories": {
        "title": "Utilisation des autorisations d&amp;#8217;étendue de référentiel dans ACR",
        "tags": "docker, azure, acr",
        "date": "January 10, 2020",
        "author": "",
        "category": "",
        "content": "Jusqu&#8217;à aujourd&#8217;hui, on pouvait gérer les droits Azure Container Registry grâce aux mécanismes RBAC standards.Par exemple&nbsp;:AcrPull pour pouvoir récupérer (pull) une imageAcrPush pour pouvoir envoyer (push) une imageAvec les autorisations d&#8217;étendu de référentiel (pas sûr de la traduction&#8230;&#8203;), il est possible de de restreindre les droits à un ou des référentiels (repositories).Cette fonctionnalité n&#8217;est disponible qu&#8217;avec un ACR Premium.Nous allons voir comment&nbsp;:Créer un ACRCréer des autorisations d&#8217;étendue de référentielUtiliser ces autorisations d&#8217;étendue de référentielAu moment de la rédaction de cet article, cette fonctionnalité est récente et toujours en prévisualisation.Conceptsréférentiels/repositories/espace de noms/namespaceLes référentiels sont des collections d&#8217;images ayant le même nom, mais des étiquettes différentes.Par exemple, les trois images suivantes se trouvent dans le référentiel \"acr-helloworld\"&nbsp;:acr-helloworld:latestacr-helloworld:v1acr-helloworld:v2Les noms des référentiels peuvent également comprendre des espaces de noms.Par exemple, avec l&#8217;espace de nom samples :samples/hello-world:v1samples/nginx:v1Carte d&#8217;étendue/mappage d&#8217;étendue/scope mapUne scope map (les traductions françaises sont peu satisfaisantes&#8230;&#8203;) permet de lister des référentiels (repository) et des droits associés.Les droits possibles sont&nbsp;:content/write&nbsp;: droit d&#8217;envoyer une image (push)content/read&nbsp;: droit de récupérer une image (pull)metadata/read&nbsp;: droit de lire les métadonnées comme les balises (tags)metadata/write&nbsp;: droit de mettre à jour les métadonnées d&#8217;une imagecontent/delete&nbsp;: droit de supprimer une imagePour pouvoir pousser une image, le droit content/read est nécessaire en même temps que le droit content/write.Jeton d’accèsOn remerciera ici Microsoft d&#8217;apporter ici un peu de confusion dans un monde informatique qui n&#8217;en manque pas.Bien évidemment, on dissociera d&#8217;emblée ce terme avec les standards OAuth2.0/OpenID Connect.Ici, le terme \"jeton d&#8217;accès\" est la correspondance entre un jeu de crédentiels (1 login de connexion et 2 mots de passe) et une scope map.Création d&#8217;un ACRLes commandes seront données en Azure CLI exécutées sous un prompt PowerShell.Commençons par créer le groupe de ressources&nbsp;:az group create -l francecentral -n rg-test-acrCréons maintenant l&#8217;ACR en premiumaz acr create -n testscopemap -g rg-test-acr --sku Premiumle nom de l&#8217;ACR doit être unique globalement, c&#8217;est-à-dire pour tous les clients de MicrosoftCréation d&#8217;une scope map et du jeton d&#8217;accèsPar la suite, je vais construire une image en Go.Je vais donc créer un référentiel pour cette image&nbsp;: samples/go. Il me faudra les droits de lecture et écriture pour pouvoir pousser l&#8217;image.az acr scope-map create -n GoSampleScopeMap -r testscopemap --repository samples/go content/write content/read --description \"Scope map for go samples\"Le résultat de la commande est comme suit&nbsp;:{  \"actions\": [    \"repositories/samples/go/content/write\",    \"repositories/samples/go/content/read\"  ],  \"creationDate\": \"2020-01-12T15:52:01.191235+00:00\",  \"description\": \"Scope map for go samples\",  \"id\": \"/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/rg-test-acr/providers/Microsoft.ContainerRegistry/registries/testscopemap/scopeMaps/GoSampleScopeMap\",  \"name\": \"GoSampleScopeMap\",  \"provisioningState\": \"Succeeded\",  \"resourceGroup\": \"rg-test-acr\",  \"scopeMapType\": \"UserDefined\",  \"type\": \"Microsoft.ContainerRegistry/registries/scopeMaps\"}Les scope maps peuvent être mis à jour ultérieurement pour ajouter ou supprimer d&#8217;autres référentiels avec la commande az acr scope-map update.Pour créer un jeton d&#8217;accès pour la scope map créé précédemment, exécuter la commande suivante&nbsp;:az acr token create -n TestDocker -r testscopemap --scope-map GoSampleScopeMapLe retour est alors&nbsp;:{  \"creationDate\": \"2020-01-12T15:56:42.673384+00:00\",  \"credentials\": {    \"certificates\": [],    \"passwords\": [      {        \"creationTime\": \"2020-01-12T15:56:54.807783+00:00\",        \"expiry\": null,        \"name\": \"password1\",        \"value\": \"/qY1exMos...GNGYp43iPMe\"      },      {        \"creationTime\": \"2020-01-12T15:56:54.807783+00:00\",        \"expiry\": null,        \"name\": \"password2\",        \"value\": \"bODh6ePvNXK...E25POt+ba\"      }    ],    \"username\": \"TestDocker\"  },  \"id\": \"/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/rg-test-acr/providers/Microsoft.ContainerRegistry/registries/testscopemap/tokens/TestDocker\",  \"name\": \"TestDocker\",  \"objectId\": null,  \"provisioningState\": \"Succeeded\",  \"resourceGroup\": \"rg-test-acr\",  \"scopeMapId\": \"/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/rg-test-acr/providers/Microsoft.ContainerRegistry/registries/testscopemap/scopeMaps/GoSampleScopeMap\",  \"status\": \"enabled\",  \"type\": \"Microsoft.ContainerRegistry/registries/tokens\"}2 mots de passe sont générés. Bien les conserver pour la suite.Il est possible de créer la scope map et le jeton d&#8217;accès en une seule commande&nbsp;:az acr token create -n TestDocker2 -r testscopemap --repository samples/go content/write content/readDans ce cas, le nom de la scope map est générée automatiquement, de la forme &lt;NomToken&gt;-scope-mapFinalement, il est possible de regénérer un mot de passe et lui assigner une durée de validité (par défaut, la durée du mot de passe est infinie).La commande suivante regénère le premier mot de passe pour une durée de validité de 30 jours&nbsp;:az acr token credential generate --name TestDocker2 --registry testscopemap --days 30 --password1 --query 'passwords[0].value' --output tsvUtiliser les autorisations d&#8217;étendue de référentielLes autorisations d&#8217;étendue de référentiel sont utilisées au moment de la connexion à l&#8217;ACR.J&#8217;ai une image locale hello-go:latest à pousser dans le référentiel défini précédemment.La première étape consiste à donner le bon label à l&#8217;image.Pour rappel, dans mon exemple testscopemap est le nom de l&#8217;ACR.docker tag hello-go:latest testscopemap.azurecr.io/samples/go:1Pour se connecter, dans un prompt PowerShell&nbsp;:$TOKEN_NAME=\"TestDocker\"$TOKEN_PWD=\"/qY1exMos...GNGYp43iPMe\"$ACR=\"testscopemap\"docker login --username $TOKEN_NAME -p $TOKEN_PWD \"$ACR.azurecr.io\"Il ne reste plus qu&#8217;à pousser&nbsp;docker push testscopemap.azurecr.io/samples/go:1Et voilà&nbsp;!",
        "url": "//2020/01/10/acr-repositories/"
      }
      ,
    
      "2020-01-01-sonarqube-app-service": {
        "title": "SonarQube sur App Service",
        "tags": "docker, sonarqube, azure, app-service",
        "date": "January 1, 2020",
        "author": "",
        "category": "",
        "content": "SonarQube sur son poste, c&#8217;est top&nbsp;!Mais il peut être nécessaire de le rendre accessible depuis Internet, depuis Azure DevOps ou simplement partager l&#8217;instance entre plusieurs personnes et plusieurs projets.Il existe différentes stratégies pour héberger SonarQube sur Azure et le rendre accessible&nbsp;:Utiliser App Service et le tomcat intégréHéberger SonarQube sur une machine virtuelleetc.J&#8217;ai choisi ici d&#8217;utiliser Docker pour les raisons déjà évoquées&nbsp;:Simplicité&nbsp;: en utilisant l&#8217;image officielle de Docker, on peut démarrer sans passer de temps à installer le logicielPortabilité&nbsp;: je peux utiliser le même genre de configuration sur mon poste ou dans AzureIl n&#8217;existe pas moins de 6 façons d&#8217;exécuter Docker dans Azure. J&#8217;ai donc retenu d&#8217;utiliser App Service dont les coûts pour un App Service Plan Linux ont diminué. Ainsi, nous allons pouvoir faire tourner App Service sur une instance B2 à ~€21.547/mois (offre promotionnelle visiblement).Azure Container Instance nous permettrait de régler plus finement la mémoire et le CPU alloués ainsi que d&#8217;arrêter le container au besoin mais App Service intègre une connexion HTTPS par défaut avec un certificat reconnu, ce qui particulièrement intéressant pour des raisons de sécurité évidentes.Table des matièresArchitectureVersion simpleDocker ComposeImage DockerConstruction de l&#8217;imagePréparation du Docker ComposeCréation de l&#8217;App Service avec Docker ComposeAccès SSHArchitectureL&#8217;architecture se composera simplement de&nbsp;:Un App Service Plan LinuxUn App Service s&#8217;appuyant sur une image DockerPas de base de données externe.Version simpleDans un premier temps, nous allons procéder à la création d&#8217;un container sur la base de l&#8217;image officielle seule.Pour ce faire, ouvrir un prompt PowerShell et exécuter les commandes AZ CLI suivantes&nbsp;:# Variables à adapter$rg=\"&lt;resource-group-name&gt;\" # Nom du groupe de ressources$ASP=\"&lt;app-service-plan&gt;\" # Nom de l'App Service Plan$appName=\"&lt;app-name&gt;\" # Nom de l'App Service (va déterminer l'URL d'accès)# Création du groupe de ressources. La localisation est à adapter. Ici \"France Central\"az group create --location \"France Central\" --name $rg#Création de l'App Service Plan.az appservice plan create --name $ASP --resource-group $rg --sku B2 --is-linux# Création de L'App Service sur la base de l'image officielleaz webapp create --resource-group $rg --plan $ASP --name $appName --deployment-container-image-name sonarqube:8.1-community-beta# Publication du port 9000az webapp config appsettings set  --resource-group $rg --name $appName --settings WEBSITES_PORT=9000# Configuration du stockage permanentaz webapp config appsettings set --resource-group $rg --name $appName --settings WEBSITES_ENABLE_APP_SERVICE_STORAGE=true# Configuration des logsaz webapp log config --resource-group $rg --name $appName --docker-container-logging filesystem# Petit redémarrageaz webapp restart --resource-group $rg --name $appName# Accès à SonarQubestart \"https://$appName.azurewebsites.net\"# Récupération des logsaz webapp log tail --resource-group $rg --name $appNameSans l&#8217;accès à l&#8217;URL, le déploiement de l&#8217;image ne semble pas se faireLe premier démarrage, incluant le téléchargement de l&#8217;image est assez long.Docker ComposeLe support de Docker Compose est encore en preview mais il permet de&nbsp;:Contrôler les variables d&#8217;environnementsDéclarer des volumesAjouter une base de données externe telle que postgreMalheureusement, plusieurs problèmes se sont posés, nécessitant la création d&#8217;une image personnalisée (mais héritée de l&#8217;image officielle).L&#8217;utilisation d&#8217;une image personnalisée a pu apporter le support de SSH dans App Service.Les problèmes étaient, par ordre d&#8217;apparition&nbsp;:Erreur \"max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\". C&#8217;est erreur est remontée par Elastic Search.Sachant qu&#8217;il n&#8217;est pas possible de modifier cette valeur sur un App Service, plusieurs solutions sont possibles&nbsp;:Modifier les paramètres d&#8217;Elastic Search (cf. https://jira.sonarsource.com/browse/SONAR-12264)Empêcher SonarQube de forcer la vérification. Cette vérification est forcée lorsqu&#8217;une base autre que H2 est utilisée.App Service remplace les \".\" des variables d&#8217;environnement par des \"_\", ce qui ne m&#8217;a pas permis de facilement surchargé les paramètres de SonarQubeLe container s&#8217;exécute en tant que l&#8217;utilisateur \"sonarqube\" par défaut, ce qui est une bonne chose d&#8217;un point de vue sécurité, mais ce qui ne permet pas de démarrer le service SSH simplementLe projet est disponible sur GitHubCommençons donc par la création d&#8217;une image Docker.Image DockerL&#8217;image est préparée à partir de l&#8217;image officielle sonarqube:8.1-community-beta.DockerfileFROM sonarqube:8.1-community-beta# sshENV SSH_PASSWD \"root:Docker!\"USER rootRUN apt-get update \\     &amp;&amp; apt-get install -y openssh-server dialog --no-install-recommends \\     &amp;&amp; rm -rf /var/lib/apt/lists/* \\     &amp;&amp; echo \"$SSH_PASSWD\" | chpasswdADD sshd_config /etc/ssh/EXPOSE 9000 2222COPY --chown=sonarqube:sonarqube run.sh \"$SONARQUBE_HOME/bin/\"Il consiste en&nbsp;:Devenir root pour pouvoir installer le serveur OpenSSH et exécuter le container en tant que rootPersonnaliser la configuration d&#8217;OpenSSH à partir d&#8217;un fichier d&#8217;exempleDéfinir le mot de passe de rootModifier la directive EXPOSE pour exposer le serveur OpenSSH en plus de SonarQubeLa copie du fichier personnalisé run.shLe fichier run.sh reprend quasiment entièrement le fichier de l&#8217;image officielle, à quelques détails près.run.shwhile IFS='=' read -r envvar_key envvar_valuedo    if [[ \"$envvar_key\" =~ sonar.* ]] || [[ \"$envvar_key\" =~ ldap.* ]]; then        sq_opts+=(\"-D${envvar_key}=${envvar_value}\")    fi    if [[ \"$envvar_key\" =~ sonar_* ]]; then        # Replacing '_' by '.'        envvar_key=\"$(sed s/_/./g &lt;&lt;&lt;$envvar_key)\"        sq_opts+=(\"-D${envvar_key}=${envvar_value}\")    fidone &lt; &lt;(env)...if [ \"$init_only\" = false ]; then  echo \"Starting SSH ...\"  service ssh start  su sonarqube -c 'java -jar \"lib/sonar-application-$SONAR_VERSION.jar\" -Dsonar.log.console=true \"$@\"' -- \"run.sh\" \"${sq_opts[@]}\" \"$@\"fiLa première partie se charge de restaurer le \".\" sur les variables d&#8217;environnement.La deuxième partie se charge de&nbsp;:Démarrer le service SSHExécuter SonarQube en tant qu&#8217;utilisateur sonarqube. En effet, Elastic Search ne démarre pas s&#8217;il est exécuté en tant que root. Peut-être existait-il un flag à chercher au fin fond d&#8217;une doc mais cela semblait une bonne pratique de ne pas l&#8217;exécuter en tant que root.Construction de l&#8217;imageL&#8217;image va être construite et poussée sur un Azure Container Registry.Pour ce faire, dans un prompt PowerShell&nbsp;:Création d&#8217;un Azure Container Registry$acr=\"myregistry\"$rg=\"&lt;resource-group-name&gt;\"az acr create -n $acr -g $rg --sku Basic --admin-enabled trueLoginaz acr login -n $acrRécupération des credentialsaz acr credential show -n $acr --password-name passwordConstruction de l&#8217;image et publication$tag=\"8\"$image=\"sonarqubeonazure\"docker build  -t $image:$tag -f \".\\8.Dockerfile\" .docker tag $image:$tag $acr.azurecr.io/$image:$tagdocker push $acr.azurecr.io/$image:$tagPréparation du Docker ComposeSonarQube fournit un exemple assez proche de la cibledocker-compose.ymlversion: '3.3'services:  sonarqube:    depends_on:      - db    image: myregistry.azurecr.io/sonarqubeonazure:7    ports:      - \"7000:9000\"    networks:      - sonarnet    environment:      - sonar.forceAuthentication=true      - sonar.telemetry.enable=false      - sonar.es.bootstrap.checks.disable=true      - SONARQUBE_JDBC_URL=jdbc:postgresql://db:5432/sonar      - SONARQUBE_JDBC_USERNAME=sonar      - SONARQUBE_JDBC_PASSWORD=sonar    volumes:      - sonarqube_conf:/opt/sonarqube/conf      - sonarqube_data:/opt/sonarqube/data      - sonarqube_extensions:/opt/sonarqube/extensions  db:    image: postgres    networks:      - sonarnet    environment:      - POSTGRES_USER=sonar      - POSTGRES_PASSWORD=sonar    volumes:      - postgresql:/var/lib/postgresql      # This needs explicit mapping due to https://github.com/docker-library/postgres/blob/4e48e3228a30763913ece952c611e5e9b95c8759/Dockerfile.template#L52      - postgresql_data:/var/lib/postgresql/datanetworks:  sonarnet:    driver: bridgevolumes:  sonarqube_conf:  sonarqube_data:  sonarqube_extensions:  postgresql:  postgresql_data:Les différences avec l&#8217;exemple concernent&nbsp;:L&#8217;utilisation des variables d&#8217;environnement SONARQUBE_JDBC_USERNAME et SONARQUBE_JDBC_PASSWORDAjout de la directive depends_onEt bien sûr, ajout de la variable d&#8217;environnement sonar.es.bootstrap.checks.disable pour désactiver le checkOn peut alors tester le fichier docker compose à l&#8217;aide de la commande&nbsp;:docker-compose upLes containers peuvent être supprimés, ainsi que les volumes avec la commandedocker-compose down -vCréation de l&#8217;App Service avec Docker ComposeLe déploiement d&#8217;un App Service avec Docker Compose est assez proche de la version simple.Ouvrir un prompt PowerShell et exécuter les commandes suivantes&nbsp;:# Variables à adapter$rg=\"&lt;resource-group-name&gt;\" # Nom du groupe de ressources$ASP=\"&lt;app-service-plan&gt;\" # Nom de l'App Service Plan$appName=\"&lt;app-name&gt;\" # Nom de l'App Service (va déterminer l'URL d'accès)$dockerComposePath=\".\\docker-compose.yml\" # Chemin vers le fichier Docker Compose# Création du groupe de ressources. La localisation est à adapter. Ici \"France Central\"az group create --location \"France Central\" --name $rg# Création de l'App Service Plan.az appservice plan create --name $ASP --resource-group $rg --sku B2 --is-linux# Création de L'App Service à partir du fichier Docker Composeaz webapp create --resource-group $rg --plan $ASP --name $appName --multicontainer-config-type compose --multicontainer-config-file $dockerComposePath --docker-registry-server-user $acr --docker-registry-server-password \"3...9bHTFzFd\"# Publication du port 7000az webapp config appsettings set  --resource-group $rg --name $appName --settings WEBSITES_PORT=7000# Configuration du stockage permanentaz webapp config appsettings set --resource-group $rg --name $appName --settings WEBSITES_ENABLE_APP_SERVICE_STORAGE=trueaz webapp config appsettings set --resource-group $rg --name $appName --settings DOCKER_REGISTRY_SERVER_URL=https://$acr.azurecr.ioaz webapp config appsettings set --resource-group $rg --name $appName --settings DOCKER_REGISTRY_SERVER_USERNAME=$acraz webapp config appsettings set --resource-group $rg --name $appName --settings DOCKER_REGISTRY_SERVER_PASSWORD=3...9bHTFzFd# Configuration des logsaz webapp log config --resource-group $rg --name $appName --docker-container-logging filesystem# Petit redémarrageaz webapp restart --resource-group $rg --name $appName# Accès à SonarQubestart \"https://$appName.azurewebsites.net\"# Récupération des logsaz webapp log tail --resource-group $rg --name $appNameLe téléchargement de l&#8217;image, le démarrage de l&#8217;application sont toujours aussi long. Mais éventuellement, cela marchera&#8230;&#8203;Accès SSHComme évoqué précédemment, si nécessaire, il est possible d&#8217;accéder à SonarQube en SSH en allant à l&#8217;adresse https://$appName.scm.azurewebsites.net/webssh/host",
        "url": "//2020/01/01/sonarqube-app-service/"
      }
      ,
    
      "2019-12-31-sonarqube-dotnet": {
        "title": "Analyse de .NET Core avec SonarQube sur Windows",
        "tags": "docker, sonarqube, windows, dotnet-core",
        "date": "December 31, 2019",
        "author": "",
        "category": "",
        "content": "Un SonarScanner est disponible pour .Net Core. Nous allons voir comment l&#8217;installer puis l&#8217;utiliser.Tout d&#8217;abord, créons un nouveau projet. Si vous avez suivi leprécédent tutoriel, se connecter à http://localhost:8000.Même si l&#8217;on va analyser un code .Net Core, Java est requis&nbsp;!Création du projetDans l&#8217;interface, cliquer sur le \"+\" en haut à droite, puis \"Create new project\"&nbsp;:Renseigner un identifiant du projet et un nom d&#8217;affichage et cliquer sur \"Set Up\"&nbsp;:Il faut alors créer un token si vous n&#8217;en disposez pas déjà d&#8217;un. Si l&#8217;on fait l&#8217;hypothèse qu&#8217;il s&#8217;agit du premier projet, nous n&#8217;avons pas de token, donc créons-en un.Choisir \"Generate a token\", choisir un nom et cliquer \"Generate\".Noter précieusement la valeur du token et cliquer sur \"Continue\".Installation du SonarScannerSonarQube fournit un scanner .Net Core. L&#8217;installation se fait simplement par la commande suivante&nbsp;:dotnet tool install --global dotnet-sonarscannerConfiguration du SonarScannerPour éviter de taper systématiquement l&#8217;URL de SonarQube et le token, il est possible de configurer le scanner.La documentation précise qu&#8217;il faut mettre le fichier SonarQube.Analysis.xml dans le répertoire d&#8217;installation mais on ne sait pas exactement où a été installé l&#8217;utilitaire avec la commande précédente.La commande where dotnet-sonarscanner retourne alors C:\\Users\\&lt;username&gt;\\.dotnet\\tools\\dotnet-sonarscanner.exe. C&#8217;est presque ça.Ouvrir l&#8217;explorateur et aller dans C:\\Users\\&lt;username&gt;\\.dotnet\\tools\\.store\\dotnet-sonarscanner\\4.8.0\\dotnet-sonarscanner\\4.8.0\\tools\\netcoreapp3.0\\any\\. Le chemin est à adapter en fonction de la version .Net Core à utiliser.Editer le fichier SonarQube.Analysis.xml pour y mettre l&#8217;URL et le token généré précédemment&nbsp;:&lt;SonarQubeAnalysisProperties xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"    xmlns=\"http://www.sonarsource.com/msbuild/integration/2015/1\"&gt;    &lt;Property Name=\"sonar.host.url\"&gt;http://localhost:8000&lt;/Property&gt;    &lt;Property Name=\"sonar.login\"&gt;[my-user-token]&lt;/Property&gt;&lt;/SonarQubeAnalysisProperties&gt;ScannerUne fois le scanner configuré, le scan s&#8217;effectue en 3 étapes&nbsp;:Démarrer le scan avec la commande dotnet sonarscanner begin /k:\"project-key\"Construire le projet, tester, etc. avec la commande dotnet buildAnalyser et envoyer à SonarQube avec la commande dotnet sonarscanner end",
        "url": "//2019/12/31/sonarqube-dotnet/"
      }
      ,
    
      "2019-12-30-sonarqube-docker-windows": {
        "title": "SonarQube sur Windows avec Docker",
        "tags": "docker, sonarqube, windows",
        "date": "December 30, 2019",
        "author": "",
        "category": "",
        "content": "Il existe différente façon de faire tourner SonarQube sur Windows.Mon choix s&#8217;est porté sur Docker pour sa simplicité et sa portabilité.SonarQube fournit une image officielle, autant en profiter.Cet article fait l&#8217;hypothèse que vous avez un environnement Docker fonctionnel.PrérequisPour assurer la persistance  de l&#8217;installation, nous allons créer des répertoires sur le disque.Ces répertoires contiendront&nbsp;:La base de donnéesLa configurationLes pluginsLes logsetc.Pour ce faire, ouvrir un prompt PowerShell et exécuter les commandes suivantes&nbsp;:$SONARQUBE_HOME=\"C:\\temp\\sonarqube\"mkdir $SONARQUBE_HOMEmkdir $SONARQUBE_HOME/confmkdir $SONARQUBE_HOME/extensionsmkdir $SONARQUBE_HOME/logsmkdir $SONARQUBE_HOME/dataRécupérer SonarQubeRécupérons maintenant SonarQube.Il existe différentes versions disponibles sur Docker Hub mais nous allons utiliser l&#8217;image officielle et la version 8.1 community.docker pull sonarqube:8.1-community-betaExécuter SonarQubeUne seule ligne de commande est nécessaire pour faire tourner SonarQube. Toujours dans le prompt PowerShell (noter les ` ci-dessous), exécuter&nbsp;:docker run -d --name sonarqube `  -p 8000:9000 ` (1)  -v $SONARQUBE_HOME/conf:/opt/sonarqube/conf ` (2)  -v $SONARQUBE_HOME/extensions:/opt/sonarqube/extensions `  -v $SONARQUBE_HOME/logs:/opt/sonarqube/logs `  -v $SONARQUBE_HOME/data:/opt/sonarqube/data `  -e sonar.forceAuthentication=true ` (3)  -e sonar.telemetry.enable=false `  sonarqube:8.1-community-beta (4)1Sur mon poste, le port 9000 étant déjà pris, j&#8217;ai fait correspondre le port 9000 de SonarQube avec mon port 8000. Avec cette commande, SonarQube sera donc accessible à l&#8217;adresse http://localhost:80002Suis une série de ligne pour créer des volumes, c&#8217;est-à-dire faire correspondre un répertoire local avec un répertoire dans le container3Il est possible de configurer SonarQube en passant des paramètres au démarrage4On retrouve ici la version 8.1 CommunityComme le container est présent sur le poste, il démarre rapidement.Après quelques minutes, en accédant à http://localhost:8000, vous aurez l&#8217;écran de login. Il ne restera plus qu&#8217;à saisir admin/admin&nbsp;:cette version 8.1 vient avec tous les analyseurs de code standard (C#, JS, etc.). Des profils de base sont créés, il est donc possible de passer directement à la création d&#8217;un projet)Arrêter SonarQubeLorsque SonarQube n&#8217;est plus nécessaire, il est possible de l&#8217;arrêter&nbsp;:docker stop sonarqubeEt pour reprendre ultérieurement&nbsp;:docker start sonarqubeNettoyageEt si vous voulez nettoyer, 2 commandes pour supprimer le container et l&#8217;image&nbsp;:docker rm sonarqubedocker image rm sonarqube",
        "url": "//2019/12/30/sonarqube-docker-windows/"
      }
      ,
    
      "2019-10-13-tp-docker": {
        "title": "Petit TP Docker",
        "tags": "docker, python",
        "date": "October 13, 2019",
        "author": "",
        "category": "",
        "content": "Introcavote est une application de vote en ligne open source développée par la fédération FDN.L&#8217;installation paraissait simple (pip install -r requirements.txt, etc.) mais je me suis rapidement rendu compte que la petite mention \"testé avec python 2.7\" allait rapidement me bloquer avec mon python 3.6 et 3.7 si je ne voulais pas réécrire l&#8217;application.C&#8217;est là que rentre Docker en jeu avec ses capacités à supporter des systèmes hétérogènes, voire ancien comme dans mon cas. En effet, je ne tenais pas à installer un 2.7 sur mon Windows 10 dernier cri.Même si le fichier Docker ne fait qu&#8217;une dizaine de ligne, c&#8217;est l&#8217;occasion de rappeler quelques pratiques.Le fichier complet est disponible à la finImageL&#8217;image de départ est extrêmement importante. L&#8217;objectif est d&#8217;avoir une image de départ&nbsp;:Qui soit fiable, d&#8217;un point de vue sécurité&nbsp;: pour ce faire préférer les images officiellesQui soit la plus petite possible&nbsp;: pour ce faire, préférer les versions à base d&#8217;alpine plutôt qu&#8217;à base d&#8217;Ubuntu ou DebianFROM python:2.7-alpineComme on peut le voir ci-dessous, l&#8217;image python:2.7-alpine ne fait que 61,68MB.&gt; docker system df -vImages space usage:REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE                SHARED SIZE         UNIQUE SIZE         CONTAINERS...python                2.7-alpine          df73112425b5        6 weeks ago         61.68MB             61.68MB             0B                  0...Installation des dépendancesAfin de pouvoir générer le plus rapidement possible une image, tout en profitant du mécanisme de couche, il est recommandé de&nbsp;:Copier en premier le fichier de dépendance pip requirements.txt et exécuter la commande pip installCopier les fichiers python de l&#8217;application à la finAinsi, tant que le fichier de dépendance n&#8217;est pas mis à jour, la construction de l&#8217;image pourra se faire en repartant de l&#8217;ancienne image.Flask dans DockerFlask est un framework Web python répandu.Par défaut, Flask écoute sur l&#8217;interface 127.0.0.1. Le port n&#8217;est donc pas accessible quand publie le port avec Docker.Il faut donc modifier la ligne suivante    app.run()par    app.run(host= '0.0.0.0')Ignorer des fichiersIl est possible d&#8217;ignorer des fichiers&#8201;&#8212;&#8201;à la manière de git avec .gitignore&#8201;&#8212;&#8201;avec le fichier .dockerignore.J&#8217;ai donc ignoré le répertoire git et la configuration d&#8217;exemple avec le fichier suivant&nbsp;:Dockerfile de développementLe fichier Docker pour la version \"développement\" complète est disponible ci-dessous&nbsp;:Construction d&#8217;une imageLors de la construction d&#8217;une image, il est très fortement recommandé de la tagué&nbsp;:docker build . -t cavote:latestEt c&#8217;est parti!docker run -d --rm -p 5000:5000 cavote:latest-dva automatiquement rendre la main et transformer le docker en démon--rmsupprimera le container à la fin-pva mapper le port 5000 du container sur le port 5000 de l&#8217;hôte (donc en local)La commande suivante va donner la liste des containers en cours d&#8217;exécution&nbsp;:&gt; docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMESb08233412e9b        cavote:latest       \"gunicorn -w 4 --bin…\"   11 minutes ago      Up 11 minutes       0.0.0.0:5000-&gt;5000/tcp   elastic_kellerLa commande suivante va l&#8217;arrêter (et le supprimer si l&#8217;option --rm avait été précisé initialement)&nbsp;:docker stop b08233412e9bMise en production avec gunicornLa documentation précise que, pour une installation en production, on peut utiliser un serveur comme gunicorn.Pour ce faire, j&#8217;ai donc ajouté gunicorn dans les dépendances&nbsp;:La commande à exécuter dans docker est modifiée pour démarrer gunicorn&nbsp;:CMD [\"gunicorn\", \"-w\", \"4\", \"--bind\", \"0.0.0.0:5000\",\"main:app\"]Ce qui donne&nbsp;:ConclusionIl s&#8217;agissait d&#8217;une petite application et d&#8217;un fichier Docker pour la tester mais il convient de respecter certaines bonnes pratiques pour accélérer la construction des images, leurs tests et leurs déploiements.Ainsi, dans mon exemple, la configuration est chargée directement dans l&#8217;image.Il s&#8217;agit évidemment d&#8217;une mauvaise pratique.Il faudra donc s&#8217;intéresser aux volumes pour s&#8217;assurer que les fichiers de configuration ne fassent pas partie de l&#8217;image.Egalement, gunicorn est \"exposé\" directement.L&#8217;application est accessible en HTTP, ce qui est bien suffisant pour un test local.Pour une mise en production, on pourrait s&#8217;appuyer sur un reverse-proxy comme NGINX qui assurerait la terminaison SSL.On pourrait donc imaginer embarquer NGINX et cavote ensemble grâce à Docker Compose.",
        "url": "//2019/10/13/TP-docker/"
      }
      ,
    
      "2019-07-04-dotnet-core-datalakestorage": {
        "title": "Charger des fichiers sur un Data Lake Storage Gen 2 en .Net Core",
        "tags": "azure, dotnet-core, rest",
        "date": "July 4, 2019",
        "author": "",
        "category": "",
        "content": "IntroAzure Data Lake Gen2 est maintenant mon composant de stockage Azure favori pour des gros volumes de données et qui requiert du contrôle d&#8217;accès suivant une arborescence, grâce aux espaces de noms hiérarchique.Comme présenté dans un précédent article,  Microsoft ne fournit pas de SDK à ce jour, juste une API REST.Cette API REST est conçue pour s&#8217;adapter à Azure Storage Blob mais aussi être compatible avec un FileSystem Hadoop.On verra que cela peut complexifier certaines choses. Dans tous les cas, cette API se rapproche d&#8217;un de l&#8217;API High-Throughput Block Blob (HTBB) et permet donc un transfert par bloc optimisé.En l&#8217;absence d&#8217;API .Net Core, j&#8217;ai donc démarré un petit projet sur GitHub. Ce projet est sans prétention et ne vise pas à implémenter l&#8217;ensemble des services de la REST API. Il n&#8217;implémente pas de transfert optimisé, de gestion des appels concurrents, etc. En outre, pour des transferts optimisés, pour le moment, seul AzCopy peut vous aider.Vous trouverez cependant quelques perles que j&#8217;ai récupérées en chemin&#8230;&#8203;Charger un fichierLe chargement de fichier va en réalité nécessiter 3 opérations&nbsp;:Créer&#8201;&#8212;&#8201;ou plutôt déclarer&#8201;&#8212;&#8201;le fichierTransférer les octets par blocFinaliser le transfert&#8201;&#8212;&#8201;autrement dit, fermer le fichier.Au-delà du côté non naturel de ces 3 appels, il est à noter que chaque appel REST va compter comme une opération. Cela peut avoir des conséquences au niveau de la facturation Azure si vous avez beaucoup de petits fichiers.La déclaration du fichier se fait avec la méthode Create pour une resource file.Par défaut, l&#8217;écrasement de fichier est autorisé. Si vous voulez empêcher l&#8217;écrasement d&#8217;un fichier, il faut ajouter If-None-Match avec la valeur \"*\".En .Net Core, il est possible de fixer cet entête sur l&#8217;objet HttpRequestMessage comme suit&nbsp;:req.Headers.IfNoneMatch.Add(EntityTagHeaderValue.Any)Le transfert se fait grâce à la méthode Update avec le paramètre action=append.Le transfert se faisant par bloc, il faut donner l&#8217;emplacement de ce bloc. Le premier commence à 0. Cette position est à mettre dans le paramètre d&#8217;URL position.Finalement, le fichier doit être fermé. On fait donc appel à la méthode Update avec le paramètre action=flush. Cette fois-ci, le paramètre position prend comme valeur la taille du fichier complet.Projet .Net CoreLa documentation Microsoft est bien faite mais à toutes fins utiles, je rappelle ici quelques commandes.Créer un projet console dans le répertoire Ma.Super.Appli avec un namespace par défaut Ma.Super.Appli&nbsp;:dotnet new console -n Ma.Super.AppliCréer un projet NUnit dans le répertoire Ma.Super.Appli.Tests&nbsp;:dotnet new nunit -n Ma.Super.Appli.TestsFaire une référence à un autre projet:dotnet add reference ../Ma.Super.Appli/Ma.Super.Appli.csprojCréer un fichier de solution&nbsp;:dotnet new sln -n monsuperprojet.slnAjouter les projets précédemment créés au fichier solution&nbsp;:dotnet sln monsuperprojet.sln.sln add Ma.Super.Appli\\Ma.Super.Appli.csprojou si vous êtes déjà dans le bon répertoire&nbsp;:dotnet sln add Ma.Super.Appli\\Ma.Super.Appli.csprojQuelques références:Unit testing C# with NUnit and .NET Core.gitignoreSignaturePour le moment, je n&#8217;ai expérimenté que l&#8217;authentification par Shared Key. D&#8217;après la page du driver ABFS, l&#8217;API devrait supporter également l&#8217;authentification Azure AD.L&#8217;authentification par Shared Key est expliquée sur la doc Microsoft.Je me suis appuyé sur les appels d&#8217;Azure Storage Explorer et d&#8217;AzCopy (cf. l&#8217;article Comment capturer les appels REST vers Azure Data Lake gen2 avec Storage Explorer) pour établir un jeu de test.Cela a permis de gérer quelque \"bizarrerie\" comme la gestion de l&#8217;entête Content-Length qui doit être omis dans la signature s&#8217;il est à 0.",
        "url": "//2019/07/04/dotnet-core-datalakestorage/"
      }
      ,
    
      "2019-07-02-comment-capturer-appels-rest-adls-gen2-storage-calls-avec-azure-using-azure-storage-explorer": {
        "title": "Comment capturer les appels REST vers Azure Data Lake gen2 avec Storage Explorer",
        "tags": "azure, fiddler, rest",
        "date": "July 2, 2019",
        "author": "",
        "category": "",
        "content": "IntroAzure Data Lake gen2, qui n&#8217;est autre qu&#8217;un Storage Account avec un espace de noms hiérarchique, est disponible depuis quelque temps.Pour autant, Microsoft ne fournit pas de SDK, juste une API REST. Et cette documentation peut s&#8217;avérer sibylline&#8230;&#8203;Mes recherches m&#8217;ont mené sur cette page mais malheureusement, elle n&#8217;est plus à jour avec les dernières versions.Nous allons voir comment capturer des appels avec Microsoft Azure Storage Explorer version 1.8.1.Ceci permettra d&#8217;apporter un nouvel éclairage sur la doc&nbsp;: l&#8217;implémentation n&#8217;est-elle pas la doc&nbsp;?Le mode développeur du Microsoft Azure Storage ExplorerLe plus simple est d&#8217;ouvrir le mode développeur en appuyant sur F12 ou aller dans le menu Help &gt; Toggle Developer Tools&nbsp;:En allant dans l&#8217;onglet \"Network\", on peut ainsi voir les URL, les entêtes des requêtes et des réponses.Malheureusement, comme l&#8217;indique Microsoft Azure Storage Explorer, pour tout ce qui concerne le téléchargement, Microsoft Azure Storage Explorer s&#8217;appuie sur AzCopy&nbsp;:Commandes AzCopyEn réalisant un transfert, Microsoft Azure Storage Explorer nous propose de copier la commande AzCopy associée&nbsp;:Ceci nous donne des commandes PowerShell, comme&nbsp;:$env:AZCOPY_CRED_TYPE = \"SharedKey\";$env:ACCOUNT_NAME = \"XXX\";$env:ACCOUNT_KEY = \"xbDE/...0isig==\";./azcopy.exe copy \"c:\\path\\to\\test.png\" \"https://XXX.dfs.core.windows.net/root/test.png\" --overwrite=false  --follow-symlinks --recursive --from-to=LocalBlobFS --put-md5;$env:AZCOPY_CRED_TYPE = \"\";$env:ACCOUNT_NAME = \"\";$env:ACCOUNT_KEY = \"\";Microsoft Azure Storage Explorer vient avec des binaires d&#8217;AzCopy, présent par défaut dans C:\\Program Files (x86)\\Microsoft Azure Storage Explorer\\resources\\app\\node_modules\\se-az-copy-exe-win\\dist\\bin.Pour tracer les requêtes, nous allons nous appuyer sur Fiddler.FiddlerFiddler est un excellent proxy Web gratuit proposé par Telerik. Vous pouvez le télécharger et l&#8217;installer simplement.Le point important est de configurer Fiddler pour déchiffrer les flux HTTPS. Pour ce faire, après avoir démarré Fiddler, aller dans le menu Tools &gt; Options&#8230;&#8203;.Aller dans l&#8217;onglet HTTPS et cocher la case Decrypt HTTPS traffic. Des fenêtres vont inviter à faire confiance à un certificat&nbsp;: répondre \"oui\".De retour sur la fenêtre Options, cliquer sur OK.Capturer le trafic d&#8217;AzCopyUne fois Fiddler démarré et configuré, démarrez un prompt PowerShell et taper les commandes ci-dessous. Il faut penser à renseigner le nom du compte et la clé primaire. La ligne de commande a été adaptée pour prendre en compte le nom complet du binaire AzCopy et autoriser un écrasement (--overwrite=true).cd \"C:\\Program Files (x86)\\Microsoft Azure Storage Explorer\\resources\\app\\node_modules\\se-az-copy-exe-win\\dist\\bin\"$env:HTTPS_PROXY=\"http://localhost:8888\"$env:AZCOPY_CRED_TYPE = \"SharedKey\";$env:ACCOUNT_NAME = \"XXX\";$env:ACCOUNT_KEY = \"xbDE/...sig==\";./azcopy_windows_amd64.exe copy \"C:\\path\\to\\test1.png\" \"https://pocdlgen2.dfs.core.windows.net/root/test1.png\" --overwrite=true --follow-symlinks --recursive --from-to=LocalBlobFS --put-md5;$env:AZCOPY_CRED_TYPE = \"\";$env:ACCOUNT_NAME = \"\";$env:ACCOUNT_KEY = \"\";Si tout se passe bien, dans Fiddler, en allant dans Inspector, vous verrez le détail des requêtes et des réponses&nbsp;:Il est possible de récupérer la clé primaire directement dans Microsoft Azure Storage Explorer à partir du panneau Actions en bas à gauche simplement en cliquant sur \"Copy Primary Key\"&nbsp;:Si on vous ne voyez que des \"tunnel to\", c&#8217;est que Fiddler n&#8217;est pas correctement configuré pour déchiffrer le flux HTTPS&nbsp;:",
        "url": "//2019/07/02/comment-capturer-appels-rest-adls-gen2-storage-calls-avec-azure-using-azure-storage-explorer/"
      }
      ,
    
      "2018-11-27-trucs-powershell": {
        "title": "Quelques trucs et astuces PowerShell",
        "tags": "powershell, trucs",
        "date": "November 27, 2018",
        "author": "",
        "category": "",
        "content": "IntroPowerShell est aujourd&#8217;hui un langage largement utilisé et mature : la version 5.1 est embarquée dans Windows Server 2016 et Windows 10 tandis que PowerShell Core 6.0 est disponible depuis janvier 2018 en GA.Il existe une littérature dithyrambique sur le sujet. J&#8217;ai cependant voulu écrire cet article pour partager mes (bonnes ?) pratiques.Table des matièresIntroUtiliser des paramètresAfficher les infos d&#8217;un objet complexe$ErrorActionPreferenceValidation de paramètreParameterSetNameArgument splattingWrite-Output vs. Write-Host vs. Write-Verbose etc.Switch caseStrict#RequiresCmdletBindingCommentairesConvention de nommageUtiliser des paramètresOn démarre sur les chapeaux de roue avec celle-là !Il est très facile d&#8217;utiliser des paramètres. Pas de raison de s&#8217;en priver !Donc pas de chaîne de caractère en dur (genre le nom d&#8217;un Storage Account) : on le passe en paramètre avec une valeur par défaut et ça pourra toujours resservir.Afficher les infos d&#8217;un objet complexeIl est possible de mettre une variable dans une string pour en obtenir la valeur$name = Read-Host \"Quel est ton nom ?\"Write-Host \"Hello $name\"Ainsi, après avoir répondu à la question (disons \"World\"), on obtiendra bien le fameux \"Hello World\".Mais quid d&#8217;objet plus complexe ? Admettons que je veuille afficher les infos d&#8217;un process.$a = Get-Process | select -First 1Write-Host \"Le nom du process est $a.ProcessName\"Le résultat peut paraître surprenant :Le nom du process est System.Diagnostics.Process (ApplicationFrameHost).ProcessNamePour obtenir la valeur de la propriété ProcessName, il faut \"échapper\" avec $()Write-Host \"Le nom du process est $($a.ProcessName)\"Et voilà!Le nom du process est ApplicationFrameHost AppVShNotif$ErrorActionPreference$ErrorActionPreference fait partie des ces variables qui permettent de modifier le comportement de PowerShell. $ErrorActionPreference détermine le comportement en cas d&#8217;erreur.Par défaut, la valeur est continue, c&#8217;est-à-dire que PowerShell affiche l&#8217;erreur et continue.Personnellement, je ne comprends pas ce comportement par défaut. Quand une cmdlet plante, je n&#8217;ai pas envie que mon script continue&#8230;&#8203; C&#8217;est pourquoi, dans tous mes scripts j&#8217;ajoute la ligne suivante :$ErrorActionPreference = \"stop\"Validation de paramètreLa validation de paramètre est un mécanisme simple qui permet de gagner du temps en évitant :L&#8217;écriture de code pour testerL&#8217;affichage de message d&#8217;erreurAinsi, au lieu de :param(    $ComputerName)if (-not $ComputerName) {    Write-Error \"ComputerName is mandatory\"    Exit 1}(...)Il est possible déclarer :param(    [Parameter(Mandatory)]    $ComputerName)(...)Le résultat est différent :D&#8217;un point de vue \"Expérience Utilisateur\", la valeur est demandée interactivement : c&#8217;est pas plus mal.D&#8217;un point de vue code, les contrôles sont déclaratifs. Rien à faire de particulier et en plus Visual Studio Code gère parfaitement la complétion.Ceci n&#8217;est qu&#8217;un exemple et d&#8217;autres contrôles peuvent être utiliser :[ValidateLength(1,15)]S&#8217;assure que la chaîne a entre 1 et 15 caractères[ValidatePattern(\"[a-z]{6}\\d{4}\")]Permet de valider une chaîne de caractère par rapport à une expression régulière[ValidateCount(1,3)]Permet de garantir la taille du tableau[ValidateRange(1,12)]Permet de donner un intervalle pour des entiers[ValidateSet[(\"Start\",\"Stop\")]Permet de définir un ensemble de valeurs possibles. L&#8217;avantage est que PowerShell peut faire de la complétion ![ValidateScript({Test-Path -Path $_ -PathType Leaf})]Il est possible de coder son propre test. Intéressant pour tester l&#8217;existence d&#8217;un fichier ou au contraire, s&#8217;assurer que le fichier n&#8217;existe pasParameterSetNameUne classique des bonnes pratiques : le ParameterSetName !Pour rentre les cmdlets plus flexibles, il est intéressant de définir des jeux de paramètres. Ainsi la cmdlet pourrait accueillir le nom d&#8217;une souscription ou l&#8217;identifiant d&#8217;une souscription. Inutile de faire 2 cmdlets pour autant, il suffit d&#8217;utiliser un ParameterSetName.Exemple :param(    [Parameter(ParameterSetName=\"subname\", Mandatory)]    [string]    $subname,    [Parameter(ParameterSetName=\"subid\", Mandatory)]    [string]    $subid,    [Parameter(Mandatory)]    $inputFile)if ($PsCmdlet.ParameterSetName -eq \"subname\") {    Write-Host \"Nom de la souscription : $subname\"} else {    Write-Host \"Identifiant de la souscription : $subid\"}Write-Host $inputFileArgument splattingArgument splatting (Désolé, je n&#8217;ai pas de traduction pour ce terme) est une fonctionnalité souvent méconnue de PowerShell.Basiquement, il est possible de \"construire\" les arguments à passer à une cmdlet. Ainsi, on construit une hashtable avec les paramètres à passer ou non.C&#8217;est très intéressant avec les `ParameterSetName`s car on peut appeler la même cmdlet mais avec des arguments différents en fonction du ParameterSetName.Ci-dessous un exemple. Mon script prend un paramètre optionnel SubscriptionName. Si une valeur est renseignée, je récupère LA souscription souhaitée, sinon j&#8217;appelle ma cmdlet Get-AzureRmSubscription sans paramètre et récupère ainsi toutes les souscriptions.param(    [string]$SubscriptionName,    (...))(...)$subSplat=@{}if (-not [string]::IsNullOrEmpty($SubscriptionName)) {    $subSplat.Add(\"SubscriptionName\", $SubscriptionName)}$subs = Get-AzureRmSubscription @subSplat(...)Write-Output vs. Write-Host vs. Write-Verbose etc.Pour faire simple :Write-Host à utiliser et à abuser pour affiche des infos sur l&#8217;état d&#8217;avancement du scriptWrite-Output à proscrire pour afficher des infos. L&#8217;objectif de Write-Output est d&#8217;ajouter un objet dans le pipeline. Utiliser Write-Output peut avoir des effets indésirables. Il a l&#8217;avantage de signifier que l&#8217;on veut mettre un objet dans le pipeline. Un peu comme un return : ça sert à rien mais c&#8217;est plus lisibleWrite-Verbose à utiliser et à abuser! Pour afficher des infos de debug/plus verbeuses (cf. CmdletBinding)Prenons l&#8217;exemple suivant :param()function Get-Output {    [CmdletBinding()]    param (    )    Write-Host \"Hello1\"    \"Hello2\"    Write-Output \"Hello3\"    return \"Hello4\"}$a = Get-OutputWrite-Host \"Contenu de `$a :\"$aA votre avis, qu&#8217;est-ce qui sera affiché dans la console ? Avant et après \"Contenu de `$a :\" ? \"Hello4\"?RésultatHello1Contenu de $a :Hello2Hello3Hello4\"Hello2\", \"Hello3\" et \"Hello4\" ont été ajouté au pipeline et assigné à $a.Seul Hello1 est afficher \"correctement dans la fonction.Switch caseLa directive switch a une syntaxe toute particulière en PowerShell. Ce qui est tout autant particulier (et méconnu) est l&#8217;existence de flag à cette directive comme -regexp ou -wildcard.Il existe un article exhaustif sur le sujet :https://kevinmarquette.github.io/2018-01-12-Powershell-switch-statement/StrictUne bonne pratique est d&#8217;utiliser un mode stricte en ajoutant la ligne suivante :Set-StrictMode -Version latestCeci va garantir que :Les meilleures pratiques sont respectéesUne variable qui n&#8217;existe pas ne sera pas utiliséeSouvent dans des cas de refactoring du code, de mauvais copié/collé, des noms de variable qui n&#8217;auraient jamais dû être là sont utilisés malencontreusement. Avec le mode stricte, PowerShell va générer une erreur et sortir.Le principal inconvénient est pour le test de présence de certaines propriétés dans un objet.J&#8217;ai donc une petite fonction en stock qui permet d&#8217;éviter une erreur en mode strictefunction Test-HasProperty($object, $propertyName) {    &lt;#    .SYNOPSIS        Utility function to check if an object has a property. Useful in strict mode    #&gt;    $propertyName -in $object.PSobject.Properties.Name}#RequiresJe ne vois quasiment jamais la directive #Requires utilisée, pourtant elle est très intéressante pour documenter:La version PowerShellLes modules nécessaires, notamment pour des dépendances particulièresLa nécessité d&#8217;exécuter le script en tant qu&#8217;administrateur (UAC a parfois des comportements et des messages bizarres. Si des droits administrateurs sont requis, autant le préciser#Requires -Version 6.0#Requires -Modules ActiveDirectory#Requires -RunAsAdministratorCmdletBindingCmdletBinding est un attribut de cmdlet très puissant.Personnellement, je l&#8217;utilise systématiquement pour pouvoir interpréter automatiquement le flag -verbose. Ainsi, dans l&#8217;exemple ci-dessous, ex4.ps1 a l&#8217;attribut CmdletBinding et non ex5.ps1.CommentairesLes commentaires sont extrêmement importants dans le code. PowerShell n&#8217;échappe pas à cette règle !Rappelons qu&#8217;il est possible de faire des commentaires de bloque grâce à &lt;# &#8230;&#8203; #&gt;.Sinon, inutile de réinventer la roue pour documenter ses cmdlets ou ses fonctions, PowerShell dispose déjà de ses propres mécanismes (cf. About Comment Based Help)L&#8217;avantage est que le Get-Help du script fonctionnera et pourra ainsi les infos nécessaires, des exemples, etc.J&#8217;utilise principalement les mots-clés suivants :.SYNOPSISBrève description de la fonction ou du script.DESCRIPTIONDescription plus détaillée si nécessaire.PARAMETER &lt;Parameter-Name&gt;Permet de documenter un paramètre.EXAMPLEPermet de donner un exemple d&#8217;usage avec la sortieA noter que pour une fonction, il est possible de mettre le bloc de commentaire avant la fonction, au début de la fonction (ou après).Convention de nommageIl faut favoriser la convention VERB-NOUN en utilisant les verbes préconisés.",
        "url": "//2018/11/27/trucs-powershell/"
      }
      ,
    
      "2018-09-04-az-cli-ml": {
        "title": "Gérer les certificats d&amp;#8217;Azure CLI",
        "tags": "azure, windows, az-cli",
        "date": "September 4, 2018",
        "author": "",
        "category": "",
        "content": "IntroductionL&#8217;outil de ligne de commande Azure CLI permet aussi de gérer Machine Learning Server.Cela permet notamment de :Configurer les nœuds Web et computeChiffrer les mots de passeRedémarrer les nœudsExécuter des tests de diagnosticEtc.Or, dans mon cas, le Machine Learning Server utilise un certificat émis par une autorité de certification interne.Cela générait l&#8217;erreur suivante :&gt;az login --mls --mls-endpoint https://monendpoint/The behavior of this command has been altered by the following extension: azure-ml-admin-cliUsername: XXX@XXX.comPassword:2018-09-04 09:05:19,307 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': //login2018-09-04 09:05:19,323 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': //login2018-09-04 09:05:19,354 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': //loginAssert that [--mls-endpoint https://monendpoint/] is correct.HTTPSConnectionPool(host='monendpoint', port=443): Max retries exceeded with url: //login (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))A noter la syntaxe de la commande az login pour ML Server, qui est un peu différente de la doc.RésolutionAzure CLI s&#8217;appuie sur python. Malgré mes tentatives pour ajouter les variables classiques (CA_BUNDLE, CURL_CA_BUNDLE, REQUESTS_CA_BUNDLE, SSL_CERT_FILE) mais rien n&#8217;y fait : la vérification de certificat échoue lamentablement.Un peu de recherche pointe vers le projet Requests.Il s&#8217;appuie sur le projet sur Certifi.Pour s&#8217;en convaincre, il suffit de lancer python et les quelques lignes suivantes :cd C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2&gt;python.exeC:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2&gt;python.exePython 3.6.1 (v3.6.1:69c0db5, Mar 21 2017, 17:54:52) [MSC v.1900 32 bit (Intel)] on win32Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import requests.adapters&gt;&gt;&gt; print(requests.adapters.DEFAULT_CA_BUNDLE_PATH)C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\lib\\site-packages\\certifi\\cacert.pemIl ne reste plus qu&#8217;à éditer C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\lib\\site-packages\\certifi\\cacert.pem.A noter qu&#8217;il faut ajouter ses autorités de certification au fichier et ne pas remplacer le contenu.",
        "url": "//2018/09/04/az-cli-ml/"
      }
      ,
    
      "2018-07-11-maj-powershell-azurerm": {
        "title": "Astuce du jour : mettre à jour tous ses modules AzureRm",
        "tags": "azure, truc, powershell",
        "date": "July 11, 2018",
        "author": "",
        "category": "",
        "content": "La ligne de commandeLa commande magique pour mettre à jour tous les modules AzureRM :Get-Module -ListAvailable | ?{$_.Name -like \"AzureRM.*\"} | group Name | Update-ModuleUpdate-Module AzureRMÇa peut prendre très longtempsNote pour plus tard: comment nettoyer les vieilles versions ?Pour éviter les demandes de confirmationPar défaut, PowerShell Gallery n&#8217;est pas considéré comme une source sûre.Ainsi, à chaque installation ou mise à jour, la commande Install-Module ou Update-Module demande une confirmation.Il est possible de lister les sources avec la commande Get-PSRepository :PS &gt; Get-PSRepositoryName                      InstallationPolicy   SourceLocation----                      ------------------   --------------PSGallery                 Untrusted            https://www.powershellgallery.com/api/v2/En pratique, on accepte tout module en provenance de PSGallery.Autant lui faire confiance et se poser des vraies questions quand la gestion des modules demande confirmation.Pour ce faire, après vérification de l&#8217;URL de PSGallery, exécuter la commande ci-dessous :Set-PSRepository -Name PSGallery -InstallationPolicy Trusted",
        "url": "//2018/07/11/maj-powershell-azurerm/"
      }
      ,
    
      "2018-07-10-debug-packer-windows": {
        "title": "Débuguer la création d&amp;#8217;image Packer pour Windows sur Azure",
        "tags": "packer, azure, windows",
        "date": "July 10, 2018",
        "author": "",
        "category": "",
        "content": "IntroductionPacker est un outil très adapté à la création d&#8217;images personnalisées sur Azure.Packer va être responsable de créer bon nombre de ressources :Un Key VaultUn VNETUne interface réseau et son IP publiqueUne VMTout ça c&#8217;est très bien mais c&#8217;est relativement long à déployer et en phase de développement, cela revient à beaucoup de temps de perdu&#8230;&#8203;Voici donc quelques trucs.Tester le scriptJ&#8217;ai perdu un peu de temps à mes débuts avec ça.Ça parait bête mais aujourd&#8217;hui j&#8217;ai toujours une machine virtuelle démarrée pour copier et tester le script en live.C&#8217;est très TRES efficace.Je n&#8217;utilise jamais de \"inline\" pour les provisioners Windows Shell ou PowerShell.Cela me permet de tester plus facilement le script, de le réutiliser ou même d&#8217;enchaîner les scripts de même nature avec l&#8217;utilisation du paramètre \"scripts\"Du debug dans le scriptLà aussi ça parait évident, mais il est possible d&#8217;afficher des commentaires qui seront retournés par Packer.Rien d&#8217;exceptionnel ici : un Write-Host dans un script PowerShell fera l&#8217;affaire et pourra remonter des informations en cours d&#8217;exécution ou savoir à quel moment exactement le script échoue.La construction d&#8217;image échoueSi la construction de l&#8217;image échoue, par défaut, packer supprime les ressources créées.Si vous souhaitez accéder à la machine pour récupérer des logs ou simplement exécuter manuellement le script à des fins de debug, il est possible d&#8217;utiliser le paramètre -on-error=abort ou -on-error=ask.abort sortira dès l&#8217;échec tandis que ask demandera la procédure à suivre.En condition réelleSi malgré tout ça, le script échoue sans raison apparente, il va falloir remonter les manches !Packer s&#8217;appuie sur WinRM pour passer les scripts et les exécuter.Packer configure déjà WinRM sur la machine, ce qui n&#8217;est pas une mince affaire !Nous allons voir comment exécuter des commandes WinRM avec une image construite par Packer.Le pied de bichePour se connecter à la machine, il va certainement falloir à réinitialiser le mot de passe administrateur dans le portail Azure, car packer définit un mot de passe aléatoire par défaut.Ceci permet de réinitialiser le mot de passe du compte packer (compte créé par défaut).Une fois le login/mot de passe connu, il est possible de se connecter en RDP à la machine, le portail Azure donnant le FQDN du serveur au format &lt;nom VM aléatoire&gt;.&lt;localisation&gt;.cloudapp.azure.com (ex: pkrvmq69gzbq1tn.westeurope.cloudapp.azure.com). Penser à noter l&#8217;IP par la même occasion.CertificatL&#8217;utilisation de SSL est obligatoire dans la configuration réalisée par Packer pour WinRM.Le certificat est cependant :Auto-signéPour un FQDN différent de celui de donné par AzureDans un premier temps, il nous faut extraire le certificat utilisé par WinRM.2 possibilités :Se connecter à la machine virtuelle, ouvrir le magasin de certificat de la machine, exporter le certificat et copier le certificat sur sa machineUtiliser opensslCommme la première méthode est plus longue à détailler, je vais détailler la deuxième. Exécuter la commande openssl suivante en remplacement avec votre FQDN&gt; c:\\apps\\OpenSSL\\bin\\openssl.exe s_client -connect pkrvmq69gzbq1tn.westeurope.cloudapp.azure.com:5986 -showcertsCONNECTED(0000021C)depth=0 CN = pkrvmq69gzbq1tn.cloudapp.netverify error:num=20:unable to get local issuer certificateverify return:1depth=0 CN = pkrvmq69gzbq1tn.cloudapp.netverify error:num=21:unable to verify the first certificateverify return:1---Certificate chain 0 s:/CN=pkrvmq69gzbq1tn.cloudapp.net (1)   i:/CN=pkrvmq69gzbq1tn.cloudapp.net-----BEGIN CERTIFICATE---(2)MIIDDjCCAfagAwIBAgIRAOAE4qOtV3FeMAKd0/F4U4EwDQYJKoZIhvcNAQELBQAwJzElMCMGA1UEAxMccGtydm1xNjlnemJxMXRuLmNsb3VkYXBwLm5ldDAeFw0xODA3MTAyMTE2NTdaFw0xODA3MTEyMTE2NTdaMCcxJTAjBgNVBAMTHHBrcnZtcTY5Z3picTF0bi5jbG91ZGFwcC5uZXQwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCxnTGBTMq0jxbdVNRC1kPRTVyPquIvEbZGDZ64L+NB34vrHa3FlFkGVVzv0uG35z/lgrbgjNdr5pj6LUJ1QS23TLVAeZgrMe1VCly36d7FIu/X+U4vFE2UKKIA/Cftmyp7vPkzN8v7hye4kM2mQhNw9/k7DSkx+scLhrk1+7qZXl1DebcgpTzOdjM1WtACpu3ZI0F7/qtLaoIRdaBBMVNfsZGasqu+QqpXKG+WVHLkC2VDDwwBC8U6haN6XKFHEIcoTyLfDvcDHDBrFwtGVsrBB9I5kHXNDyGgiJZCx7EGpk0uobF+5lQJo7c/z6lWWurqu83U1XrESpp0zsPhDAh1AgMBAAGjNTAzMA4GA1UdDwEB/wQEAwIFoDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMBAf8EAjAAMA0GCSqGSIb3DQEBCwUAA4IBAQCky/mY+BlCA3RTSPy8Bxa8yewdhEL8ENS9UEX7fgrCDTVeiqxSgvYjQqhzVu7vZ9nYXttpXhLyi6l56iV3DEs5uBktnOdQZnds3zwfI/e53gqQC82lCGMDskE9kAagppFuNO27K9bXs0szIYUY8yJJdc2QR3xF7l3aLXfF6J42aD9Kw3Q9Iss28BUSu/TmRy59MZMs5XfSgw9SZGRave2S2c4yPZBUQ67CDL3Ng7Axnl2EBSpT5uQTvXbgxHV115pJ+kIoYqz0iL3rmprlzOLEohlIUn46gVqr+LNHlO1FuvfMx0e2io7lsLvJ933KG0QWqNVHvz2hEhi6u3KIqL64-----END CERTIFICATE--------Server certificatesubject=/CN=pkrvmq69gzbq1tn.cloudapp.netissuer=/CN=pkrvmq69gzbq1tn.cloudapp.net---No client certificate CA names sentPeer signing digest: SHA1Server Temp Key: ECDH, P-256, 256 bits---SSL handshake has read 1270 bytes and written 433 bytes---New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES256-GCM-SHA384Server public key is 2048 bitSecure Renegotiation IS supportedCompression: NONEExpansion: NONENo ALPN negotiatedSSL-Session:    Protocol  : TLSv1.2    Cipher    : ECDHE-RSA-AES256-GCM-SHA384    Session-ID: D820000035CA3984027AC8D13B4C4BDF4D73C0C63091B3DE510EAF06E2FABDA5    Session-ID-ctx:    Master-Key: 85504F679F0ABA212F87E25A0C3C68B5843B5990EE23523BD56702FBBC736F10C35F26253D795D1804A473620EECA2BE    Key-Arg   : None    PSK identity: None    PSK identity hint: None    SRP username: None    Start Time: 1531286527    Timeout   : 300 (sec)    Verify return code: 21 (unable to verify the first certificate)---read:errno=100931Notez le FQDN inclus dans le certificat auto-signé2Copier dans le contenu entre les balises \"-----BEGIN CERTIFICATE-----\" et \"-----END CERTIFICATE-----\" en incluant ces mêmes balises dans un fichier avec une extension .cer par exemple : vous avez votre certificat !Il ne vous reste plus qu&#8217;à installer le certificat. Sous Windows, en cliquant-droit sur le fichier, vous avez dans le menu \"Installer le certificat\".En suivant le wizard, il est nécessaire de choisir manuellement le magasin de certificat \"Autorités de certification racine de confiance\"hostsVous l&#8217;aurez remarqué : le FQDN contenu dans le certificat auto-signé est différent de celui utilisé pour se connecter. Et malgré le fait que vous fassiez confiance à ce certificat, l&#8217;établissement de la connexion SSL échouera car le nom inclut dans le certificat est différent de celui utilisé pour la résolution DNS.Il est reste donc une dernière étape pour feinter Windows.Sur votre machine, éditer le fichier C:\\Windows\\System32\\drivers\\etc\\hosts et y ajouter l&#8217;entrée :&lt;Adresse IP publique&gt; &lt;nom VM aléatoire&gt;.cloudapp.netEx:40.91.194.154 pkrvmq69gzbq1tn.cloudapp.netTout est bon ?&gt; $cred = Get-Credential&gt; Test-WSMan pkrvmq69gzbq1tn.westeurope.cloudapp.azure.com -Credential $cred -UseSSL -Authentication Defaultwsmid           : http://schemas.dmtf.org/wbem/wsman/identity/1/wsmanidentity.xsdProtocolVersion : http://schemas.dmtf.org/wbem/wsman/1/wsman.xsdProductVendor   : Microsoft CorporationProductVersion  : OS: 10.0.14393 SP: 0.0 Stack: 3.0C&#8217;est partiInvoke-Command -ComputerName pkrvmq69gzbq1tn.cloudapp.net -ScriptBlock { ipconfig } -credential $cred -UseSSLIl ne reste plus qu&#8217;à remplacer ipconfig par la commande de votre choix.ConclusionLe dernier recours à base de commande WinRM est probablement exagéré.Je ne l&#8217;ai utilisé qu&#8217;une fois, mais il m&#8217;a permis d&#8217;en savoir plus sur WinRM.Certainement une bonne base pour d&#8217;autres outils s&#8217;appuyant sur WinRM comme ansible&#8230;&#8203;Bonus : vider mon groupe de ressourceDans le cas où packer ne nettoierait pas tout, il est possible de vider le groupe de ressource avec la commande suivante :Get-AzureRmResource -ResourceGroupName &lt;mon groupe de resource&gt; | Remove-AzureRmResource -ForceC&#8217;est l&#8217;équivalent d&#8217;un rm -f sur Linux donc attention à passer le bon groupe de ressource !",
        "url": "//2018/07/10/debug-packer-windows/"
      }
      ,
    
      "2018-05-23-vscode-extensions": {
        "title": "Mes extensions Visual Studio Code",
        "tags": "vscode",
        "date": "May 23, 2018",
        "author": "",
        "category": "",
        "content": "J&#8217;utilise Visual Studio Code depuis un moment.Cette page recense les extensions que j&#8217;utilise pour éviter les \"c&#8217;est quoi déjà l&#8217;extension que j&#8217;utilise pour faire ce truc ?\". Je compléterai au fur et à mesure.Mise à jour 2018-09-05: Ajout extension pour AsciiDocMise à jour 2018-11-27: Ajout de quelques extensions (Bracket Pair Colorizer, ARM Params Generator, .NET Core Test Explorer, C# Extensions) et promotion de C# &amp; AsciiDocAzureAzure Resource Manager ToolsAzure Resource Manager Snippets: Des snippets intéressants. Mes préférées : arm-parameter et arm-paramvalue.expand-region: excellente extension qui me permet de sélectionner des régions: très pratiques pour sélectionner rapidement une ressource dans un ARM templatePowerShellPas trop de débat :Powershell: l&#8217;extension s&#8217;est clairement bonifiée et je n&#8217;ai presque plus recours à PowerShell ISEWebBeautifyC#C#AsciiDocAsciiDocXMLXML Tools: juste pour le \"Format\"En cours de testC#.NET Core Test ExplorerC# ExtensionsAzureBracket Pair Colorizer: Intéressant quand on a des JSON à rallongeARM Params Generator: très sympatique extension qui génère des fichiers de paramètres à partir de template ARM",
        "url": "//2018/05/23/vscode-extensions/"
      }
      ,
    
      "2018-05-22-azure-rbac": {
        "title": "Gestion des rôles dans Azure",
        "tags": "azure, rbac, role",
        "date": "May 22, 2018",
        "author": "",
        "category": "",
        "content": "Je m&#8217;étais posé la question. On m&#8217;a posé la question. Voici donc quelques commandes que j&#8217;ai glanées sur la gestion des rôles dans Azure.Rappelons qu&#8217;il est possible d&#8217;affecter un rôle sur 3 niveaux :La souscription (donc l&#8217;ensemble des ressources de la souscription)Un groupe de ressourcesDirectement sur une ressourceIl existe par défaut de nombreux rôles (cf. Built-in roles for Azure role-based access control).Certains rôles sont spécialisés sur un type de ressource mais très souvent les ressources n&#8217;utilisent que les rôles de base : owner/propriétaire, contributor/conntributeur et reader/lecteur.En plus de la page de référence de Microsoft, voici quelques éléments pour construire vos rôles.Liste des rôlesGet-AzureRmRoleDefinition | Format-Table Name, Description(Get-AzureRmRoleDefinition \"Virtual Machine Contributor\").Actions(Get-AzureRmRoleDefinition \"Virtual Machine Contributor\").NotActionsComment obtenir la liste des actions possiblesUn fournisseur correspond plus ou moins à un type de sous-ressource.Pour obtenir une liste de fournisseurs:Get-AzureRmResourceProvider -ListAvailable | Select-Object ProviderNamespace, RegistrationStatePour répertorier les opérations possibles d&#8217;un fournisseur :Get-AzureRmProviderOperation Microsoft.Compute/virtualMachines/* |  select -ExpandProperty operationOn notera l&#8217;utilisation du caractère '*' dans la commande précédente pour lister les opérationsCréer un rôle personnalisé basé sur un JSONNew-AzureRmRoleDefinition -InputFile C:\\MycustomRole.jsonExporter un rôle au format JSONGet-AzureRmRoleDefinition &lt;nom du rôle&gt; | ConvertTo-JsonIl sera alors possible stocker/versionner un rôle dans un gestionnaire de source.Mettre à jour un rôle personnaliséMettez à jour la définition du rôle avec :$ role = Get-AzureRmRoleDefinition -Name \"ROLE_DEFINITION_NAME\"$ role.AssignableScopes.Add (\"/ abonnements / NEW_SUBSCRIPTION_ID_GOES_HERE\") ## [[Répétez cette étape pour ajouter tous les abonnements que vous souhaitez ajouter]]$ role.Actions.Remove (\"Microsoft.Compute / virtualMachines / write\") # Ajouter une autorisation à un rôle$ role.Actions.Add (\"Microsoft.Compute / virtualMachines / write\") # Supprimer l'autorisation d'un rôleSet-AzureRmRoleDefinition -Role $ roleTrouver où un rôle est utiliséGet-AzureRmRoleAssignment -RoleDefinitionName \"ROLE_DEFINITION_NAME\"Affecter un rôle à un groupe sur un groupe de ressources$AADGroup = Get-AzureRmADGroup -SearchString \"GROUP_NAME\"New-AzureRmRoleAssignment -ObjectID $AADGroup.ID `    -RoleDefinitionName \"ROLE_DEFINITION_NAME\" `    -ResourceGroupName \"RG_NAME\"Supprimer un rôle personnaliséUn rôle ne peut être supprimé s&#8217;il est affectéPour supprimer un rôle personnalisé existant, exécutez la commande suivante :Remove-AzureRmRoleDefinition -Id ROLE_DEFINITION_ID```powershellOu```powershellRemove-AzureRmRoleDefinition -Name \"ROLE_DEFINITION_Name\"",
        "url": "//2018/05/22/azure-rbac/"
      }
      ,
    
      "2018-04-30-github-pages-jekyll-travisci": {
        "title": "Faire un blog avec Jekyll, GitHub Pages et TravisCI",
        "tags": "github, jekyll, travisci, blog",
        "date": "April 30, 2018",
        "author": "",
        "category": "",
        "content": "Pourquoi déjà ?Jekyll est un moteur puissant de générateur de site statique développé en Ruby. Il offre de nombreux plugins, thèmes ainsi que le support d&#8217;AsciiDoc au travers d&#8217;un plugin particulier.GitHub Pages est un bon moyen d&#8217;héberger son site statique. GitHub Pages supporte même Jekyll mais sans le plugin AsciiDoc.Bien sûr, il aurait été possible de générer son site statique sur son poste et de le pousser sur GitHub pour publication, mais cela aurait dû être fait à chaque fois.J&#8217;ai donc préféré automatiser complètement la génération du site grâce à TravisCI.Je ne suis ni un expert Jekyll ni Ruby.Cet article regroupe donc quelques points sur la configuration de la chaîne complète.Base du siteComme préconisé par le  plugin, je suis parti d&#8217;un fork du démarrage rapide.Ceci a permis de :Installer les prérequisActiver TravisCIJeton d&#8217;accèsPour générer le jeton, ne pas à se référer à la doc du site, mais plutôt à celle de TravisCI.Branche GitHubDans le cas d&#8217;un site perso, par opposition à un site projet, il est obligatoire de publier dans la branche master.J&#8217;ai donc créé et mis le code du site dans une branche dev. Pour ma part, j&#8217;ai utilisé :git checkout -b devConfiguration de TravisCITravisCI permet d&#8217;automatiser tout pipeline de livraison.Il propose même un déploiement pour GitHub Pages, ce qui évite la création de scripts spécifiques devant gérer les git clone, push, etc.Le premier élément concerne le fichier .travis.yml.Celui-ci se compose de la sorte :language: rubyrvm: 2.2install: bundle installscript: bundle exec jekyll builddeploy:  provider: pages  skip_cleanup: true  github_token: $GITHUB_TOKEN # Set in travis-ci.org dashboard (1)  local-dir: _site (2)  target-branch: master (3)  on:    branch: dev1Il existe plusieurs façons de sécuriser son jeton GitHub.Ici, j&#8217;utilise les variables d&#8217;environnement. J&#8217;ai donc créer une variable GITHUB_TOKEN avec mon jeton (cf. doc). Par défaut, la valeur de la variable n&#8217;est pas affichée (\"Display value in build log\" à \"Off\")2Jekyll génère les pages dans le répertoire _site3Il faut pousser les modifications dans la branche masterNe pas construireLorsque je poussais mes modifications sur la branche dev, cela résultait en des modifications poussées sur la branche master : le site en lui-même.TravisCI essayait de construire le site sur master ce qui donnait inexorablement une erreur.En cochant la case \"Build only if .travis.yml is present\", cela a empêché la construction de la branche master.ConclusionAprès tous ces efforts, quelle fierté d&#8217;avoir son petit build au vert :",
        "url": "//2018/04/30/github-pages-jekyll-travisci/"
      }
      ,
    
      "2017-12-23-udacity-with-azure-part2": {
        "title": "Suivre le tutorial d&amp;#8217;Udacity sur Kubernetes avec Azure (2e partie)",
        "tags": "kubernetes, azure, aks, docker, microservices",
        "date": "December 23, 2017",
        "author": "",
        "category": "",
        "content": "IntroductionNous prenons ici la suite du cours gratuit d&#8217;Udacity sur Docker, les microservices et Kubernetes.Vous pouvez trouver la première partie iciLesson 3: KubernetesStep 4: Setting up Kubernetes for this courseSi l&#8217;on reprend là où on en était resté, vous devriez avoir:Une souscription AzureUn Azure Cloud Shell ouvert sous BashUn resource group rg-udacity-test. Pour rappel, pour en créer un :az group create --name rg-udacity-test --location westeuropeA ce stade, vous pouvez instancier un Kubernetes sur AKS grâce à la commande:az aks create --resource-group rg-udacity-test --name myK8sCluster --node-count 1 --generate-ssh-keysaz aks get-credentials --resource-group rg-udacity-test --name myK8sClusterEtant sur Azure Cloud Shell, il n&#8217;est pas nécessaire d&#8217;installer kubectl.Il est déjà présent.Tester la commande:kubectl get nodesEn exécutant la commande ci-dessous, on peut s&#8217;apercevoir que le cluster est en 1.7.7 et que la dernière version disponible est la 1.8.2:az aks get-versions --resource-group rg-udacity-test --name myK8sCluster -o tableTaper la commande suivante pour automatiquement mettre à jour le cluster vers la 1.8.2:az aks upgrade --resource-group rg-udacity-test --name myK8sCluster -k 1.8.2Step 5: Kubernetes Intro DemoPas de spécificité sur les commandes. Nginx se déploie correctement.Step 7: Creating PodsEditer le fichier pods/monolith.yaml et modifier la ligneimage: udacity/example-monolith:1.0.0parimage: &lt;acrLoginServer&gt;/example-monolith:1.0.0où: &lt;acrLoginServer&gt; est le \"Login Server (cf. partie 1).vim est présent sur Azure Cloud ShellLe reste des commande est inchangé.Step 8: Interacting With PodsPas de spécificité. Bien penser qu&#8217;il est possible d&#8217;ouvrir plusieurs Azure Cloud Shell.Step 12: Creating SecretsPas de spécificité.Step 13: Accessing A Secure HTTPS EndpointEditer le fichier pods/secure-monolith.yaml et modifier la ligneimage: udacity/example-monolith:1.0.0parimage: &lt;acrLoginServer&gt;/example-monolith:1.0.0Lesson 4: Deploying Microservices",
        "url": "//2017/12/23/udacity-with-azure-part2/"
      }
      ,
    
      "2017-12-15-udacity-with-azure": {
        "title": "Suivre le tutorial d&amp;#8217;Udacity sur Kubernetes avec Azure (1ère partie)",
        "tags": "kubernetes, azure, aks, docker, microservices",
        "date": "December 15, 2017",
        "author": "",
        "category": "",
        "content": "IntroductionUdacity propose un cours gratuit sur Docker, les microservices et Kubernetes (en anglais). Tout est très bien décrit, y compris les commandes mais cela se base (naturellement) sur Google Container Engine (GKE).Disposant déjà d&#8217;une souscription Azure et Azure proposant également une offre managée sur Kubernetes : Azure Container Service (AKS).Azure disposant également d&#8217;un Registry privé (Azure Container Registry), ce sera l&#8217;occasion de l&#8217;utiliser!Le tutorial fait également largement usage de Google Cloud Shell. Azure dispose également d&#8217;un shell: Azure Cloud Shell. Il est même proposé \"en plein écran\" depuis peu et propose un raccourci vers bash ou PowerShell. Il dispose de nombreuses fonctionnalités et language par défaut.L&#8217;Azure Cloud Shell permet une persistance a un espace de stockage en étant lié à un Storage Account. Ce sera donc parfait pour créer une image, la publier et autre.La suite de cet article présente par leçon, étape par étape les adaptationsLesson 1: Introduction to MicroservicesEtape 5: Get the Source CodeJe fais l&#8217;hypothèse que vous avez une souscription Azure et que vous avez démarré un Bash dans Azure Cloud Shell.Sous Windows, utilisez Ctrl+Insert pour copier and Shift+Insert pour coller.Go étant déjà installé, rien à faire ici:$ go versiongo version go1.7 linux/amd64Donc, hormis l&#8217;installation de Go, vous pouvez procéder comme indiqué et extraire directement le code source:$ echo \"export GOPATH=~/go\" &gt;&gt; ~/.bashrc$ source ~/.bashrc$ mkdir -p $GOPATH/src/github.com/udacity$ git clone https://github.com/udacity/ud615$ cd ud615/app/Etape 6: Build And Interact With MonolithLa compilation se passe comme un charge mais pour tester l&#8217;application, cela devient légèrement plus rusé.Pour exécuter le programme monolith, j&#8217;utilise le port 10081 au lieu de 81 car la commande sudo n&#8217;est pas disponible.Pour ouvrir une \"deuxième console\", ouvrez un nouvel onglet dans votre navigateur sur le Cloud Shell../bin/monolith -http :10080 -health :10081Les tests à base de curl s&#8217;exécute corretement.Pour tuer le programme, il suffira de le ramener en avant-plan (commande fg puis Ctrl+C).Etape 9: Refactor To MSAPas de difficultés ici. Les commandes passent (compilations et tests).Lesson 2: Building the Containers with DockerEtape 3: Installing Apps With Native OS ToolsLes festivités commencent&#8230;&#8203;Le \"démarrage rapide\" donne en réalité toutes les indications. Dans les grosses mailles:Choisir sa souscription (az account list puis az account set --subscription my-subscription-name)Créer un resource group (unité de base dans Azure)Créer la VM (configuration de base)Se connecter à la VMCe qui donne:az group create --name rg-udacity-test --location westeuropeaz vm create -n ubuntu -g rg-udacity-test --image UbuntuLTS --generate-ssh-keysssh username@ipaddressNe pas oublier d&#8217;éteindre la VM pour éviter d&#8217;exploser le forfait!Pour connaitre l&#8217;adresse IP de la VM: az vm list-ip-addresses -g rg-udacity-test -n ubuntu --output tableUne fois connecté, les autres commandes ne changent pas:sudo apt-get updatesudo apt-get install nginxnginx -v...Etape 7 : Intalling Images With DockerPas de spécificité.Etape 8 : Running Images With DockerPas de spécificité.Etape 9 : Talking To Docker InstancesPas de spécificité.Etape 11 : Create An ImagePas de spécificité.Etape 12 : Create docker images for the remaining microservices - auth and helloPas de spécificité.Etape 14 : Push ImagesNous allons ici utilisé l&#8217;Azure Container Registry.az group create --name rg-common-docker --location westeuropeaz acr create --resource-group rg-common-docker --name &lt;acrName&gt; --sku BasicLa commande va retourner une structure. Bien noter la ligne:\"loginServer\": \"&lt;acrLoginServer&gt;\"Sur la VM Ubuntu, installer Azure CLI 2.0 en suivant la procédure:echo \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ wheezy main\" | \\     sudo tee /etc/apt/sources.list.d/azure-cli.listsudo apt-key adv --keyserver packages.microsoft.com --recv-keys 52E16F86FEE04B979B07E28DB02C46DF417A0893sudo apt-get install apt-transport-httpssudo apt-get update &amp;&amp; sudo apt-get install azure-cliPuis se logguer sur Azure puis l&#8217;ACR avant de publier l&#8217;imagesudo az loginsudo az acr login --name &lt;acrName&gt;La commande de publication ('push') doit être adapté:docker tag monolith:1.0.0 &lt;acrLoginServer&gt;/example-monolith:1.0.0docker push &lt;acrLoginServer&gt;/example-monolith:1.0.0On peut ensuite vérifier le travail:$ sudo az acr repository list --name &lt;acrName&gt; --output tableResult----------------example-authexample-helloexample-monolithA ce stade, il est possible d&#8217;arrêter la VM: az vm deallocate -g rg-udacity-test -n ubuntuUn peu de nettoyageComme d&#8217;habitude, ne pas oublier de nettoyer. Le plus simple: supprimer le resource group.az group delete --name rg-udacity-test",
        "url": "//2017/12/15/udacity-with-azure/"
      }
      ,
    
      "2017-10-27-hello-world": {
        "title": "Hello World!",
        "tags": "",
        "date": "October 27, 2017",
        "author": "",
        "category": "",
        "content": "Finally!After giving a lot of thought, here I am!I hope to contribute a little to this computer science world and that you will find usefull information.See you soon",
        "url": "//2017/10/27/hello-world/"
      }
      
    
  };
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/0.7.1/lunr.min.js"></script>
<script src="/assets/js/search.js"></script>
</section>
</article>

    </div>
    


<footer class="site-footer">
	<nav class="site-nav">
		<ul>
			
<li>
	<a href="/feed.xml" title="Suivre sur RSS">
		<i class="fa fa-fw fa-rss"></i>
	</a>
</li>















<li>
	<a href="https://github.com/r3dlin3" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>




























		</ul>
	</nav>
	<p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <i class="fa fa-heart" aria-hidden="true" style="color:Tomato"></i>
</p>
</footer>

  </body>
</html>
